# =============================================================================
# FKS CI/CD Pipeline
# =============================================================================
# Streamlined pipeline using reusable composite actions from nuniesmith/actions.
#
# Pipeline Flow:
#   1. Setup     ‚Äî Determine environment, build strategy, test eligibility
#   2. Lint      ‚Äî rustfmt + clippy (fast gate, blocks all test jobs)
#   3. Tests     ‚Äî 4 parallel test groups split by domain:
#                  ‚îú‚îÄ Core & Libraries   (~680 tests)  ‚Äî foundational crates
#                  ‚îú‚îÄ Neuromorphic       (~5200 tests) ‚Äî brain-region modules
#                  ‚îú‚îÄ Services           (~2100 tests) ‚Äî forward, execution, data, etc.
#                  ‚îî‚îÄ Trading & ML       (~1900 tests) ‚Äî strategies, backtest, ML, audit
#   4. KMP Tests ‚Äî Kotlin Multiplatform (separate runner)
#   5. Docker    ‚Äî Multi-service matrix build (gated by tests)
#   6. Deploy    ‚Äî Tailscale ‚Üí DNS ‚Üí SSL ‚Üí SSH Deploy ‚Üí Health Checks
#   7. Summary   ‚Äî Pipeline results
#
# Build Strategies:
#   - server-build: Build Docker images directly on the prod server
#   - dockerhub:    Build in CI, push to DockerHub, pull on server (default)
#
# Required Secrets:
#   - PROD_TAILSCALE_IP, PROD_SSH_KEY, PROD_SSH_USER, PROD_SSH_PORT
#   - PROD_ROOT_SSH_KEY (root SSH key for SSL cert deployment)
#   - STAGING_TAILSCALE_IP (optional ‚Äî falls back to PROD_TAILSCALE_IP)
#   - TAILSCALE_OAUTH_CLIENT_ID, TAILSCALE_OAUTH_SECRET
#   - DOCKER_USERNAME, DOCKER_TOKEN
#   - DOCKER_IMAGE_NAME (optional, default: nuniesmith/fks)
#   - CLOUDFLARE_API_KEY, CLOUDFLARE_ZONE_ID
#   - SSL_EMAIL
#   - SSL_VOLUME_NAME (optional, default: fks_ssl_certs)
#   - PROD_DOMAIN (optional, default: fkstrading.xyz)
#   - STAGING_DOMAIN (optional, default: staging.fkstrading.xyz)
#   - DISCORD_WEBHOOK_ACTIONS (optional ‚Äî deployment notifications)
#   - DISCORD_WEBHOOK_GENERAL (optional ‚Äî injected into .env for alertmanager)
#   - DISCORD_WEBHOOK_URL, DISCORD_BOT_TOKEN (optional ‚Äî injected into .env)
#   - KRAKEN_API_KEY, KRAKEN_API_SECRET (optional ‚Äî injected into .env)
#   - BYBIT_API_KEY, BYBIT_API_SECRET (optional ‚Äî injected into .env)
#   - BINANCE_API_KEY, BINANCE_API_SECRET (optional ‚Äî injected into .env)
# =============================================================================

name: üöÄ CI/CD Pipeline

on:
    push:
        branches: [main, develop]
        paths-ignore:
            - "**.md"
            - "docs/**"
            - ".github/workflows/llm-audit.yml"
    pull_request:
        branches: [main, develop]
    workflow_dispatch:
        inputs:
            skip_deploy:
                description: "Skip deployment"
                required: false
                type: boolean
                default: false
            skip_ssl:
                description: "Skip SSL certificate generation"
                required: false
                type: boolean
                default: false
            skip_tests:
                description: "Skip all Rust tests (faster deploys)"
                required: false
                type: boolean
                default: false
            build_strategy:
                description: "Docker build strategy"
                required: false
                type: choice
                options:
                    - dockerhub
                    - server-build
                default: dockerhub
            environment:
                description: "Target environment"
                required: false
                type: choice
                options:
                    - auto
                    - staging
                    - production
                default: auto

permissions:
    contents: write
    pull-requests: write
    packages: write
    checks: write
    actions: read

env:
    RUST_VERSION: "1.92.0"
    CARGO_TERM_COLOR: always
    REGISTRY: docker.io
    IMAGE_NAME: ${{ secrets.DOCKER_IMAGE_NAME || 'nuniesmith/fks' }}
    DOMAIN: ${{ secrets.PROD_DOMAIN || 'fkstrading.xyz' }}
    STAGING_DOMAIN: ${{ secrets.STAGING_DOMAIN || 'staging.fkstrading.xyz' }}
    SSL_VOLUME_NAME: ${{ secrets.SSL_VOLUME_NAME || 'fks_ssl_certs' }}

concurrency:
    group: ${{ github.workflow }}-${{ github.ref }}
    cancel-in-progress: true

defaults:
    run:
        shell: bash

jobs:
    # =========================================================================
    # STAGE 1: SETUP
    # =========================================================================
    setup:
        name: üìã Setup
        runs-on: ubuntu-latest
        timeout-minutes: 5
        outputs:
            deploy_env: ${{ steps.determine-env.outputs.environment }}
            target_domain: ${{ steps.determine-env.outputs.domain }}
            build_strategy: ${{ steps.determine-env.outputs.build_strategy }}
            should_deploy: ${{ steps.determine-env.outputs.should_deploy }}
            should_test: ${{ steps.determine-env.outputs.should_test }}
        steps:
            - name: üéØ Determine deployment environment
              id: determine-env
              env:
                  HAS_PROD_IP: ${{ secrets.PROD_TAILSCALE_IP != '' }}
                  HAS_SSH_KEY: ${{ secrets.PROD_SSH_KEY != '' }}
                  HAS_TAILSCALE: ${{ secrets.TAILSCALE_OAUTH_CLIENT_ID != '' }}
                  HAS_STAGING_IP: ${{ secrets.STAGING_TAILSCALE_IP != '' }}
                  PROD_TAILSCALE_IP: ${{ secrets.PROD_TAILSCALE_IP }}
                  STAGING_TAILSCALE_IP: ${{ secrets.STAGING_TAILSCALE_IP }}
                  INPUT_ENV: ${{ inputs.environment }}
                  INPUT_STRATEGY: ${{ inputs.build_strategy }}
                  INPUT_SKIP_DEPLOY: ${{ inputs.skip_deploy }}
                  INPUT_SKIP_TESTS: ${{ inputs.skip_tests }}
                  GITHUB_REF: ${{ github.ref }}
                  EVENT_NAME: ${{ github.event_name }}
                  PROD_DOMAIN: ${{ env.DOMAIN }}
                  STAGE_DOMAIN: ${{ env.STAGING_DOMAIN }}
              run: |
                  # NOTE: Do NOT use `set -euo pipefail` here ‚Äî the `&&` pattern
                  # in the optional-secrets validation block causes `set -e` to
                  # terminate the script when the test returns false (exit 1).
                  # We handle errors explicitly with `exit 1` where needed.

                  # ‚îÄ‚îÄ Validate critical secrets ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  if [ -z "$PROD_TAILSCALE_IP" ]; then
                    echo "‚ùå FATAL: PROD_TAILSCALE_IP secret is not set or empty!"
                    cat >> $GITHUB_STEP_SUMMARY << 'EOFSUM'
                  ## ‚ùå Missing Required Secret
                  The `PROD_TAILSCALE_IP` secret must be configured in repository settings.

                  Go to: **Settings ‚Üí Secrets and variables ‚Üí Actions ‚Üí New repository secret**

                  Set `PROD_TAILSCALE_IP` to your production server's Tailscale IP (e.g., `100.x.x.x`)
                  EOFSUM
                    exit 1
                  fi

                  # ‚îÄ‚îÄ Determine environment ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  if [ -n "$INPUT_ENV" ] && [ "$INPUT_ENV" != "auto" ]; then
                    ENV="$INPUT_ENV"
                  elif [ "$GITHUB_REF" == "refs/heads/main" ]; then
                    ENV="production"
                  else
                    ENV="staging"
                  fi

                  # ‚îÄ‚îÄ Set domain ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  if [ "$ENV" = "production" ]; then
                    DOMAIN="$PROD_DOMAIN"
                  else
                    DOMAIN="$STAGE_DOMAIN"
                  fi

                  # ‚îÄ‚îÄ Determine build strategy ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  STRATEGY="${INPUT_STRATEGY:-dockerhub}"

                  # ‚îÄ‚îÄ Determine deploy eligibility ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  SHOULD_DEPLOY="false"
                  if [ "$INPUT_SKIP_DEPLOY" != "true" ]; then
                    if [ "$EVENT_NAME" = "push" ] || [ "$EVENT_NAME" = "workflow_dispatch" ]; then
                      if [ "$GITHUB_REF" = "refs/heads/main" ] || [ "$GITHUB_REF" = "refs/heads/develop" ]; then
                        SHOULD_DEPLOY="true"
                      fi
                    fi
                  fi

                  # ‚îÄ‚îÄ Determine test eligibility ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  # Tests run by default. Skip only when explicitly requested
                  # via workflow_dispatch input.
                  if [ "$INPUT_SKIP_TESTS" = "true" ]; then
                    SHOULD_TEST="false"
                  else
                    SHOULD_TEST="true"
                  fi

                  # ‚îÄ‚îÄ Debug output ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  echo "üéØ Environment:    $ENV"
                  echo "üåê Domain:         $DOMAIN"
                  echo "üîß Build Strategy: $STRATEGY"
                  echo "üöÄ Should Deploy:  $SHOULD_DEPLOY"
                  echo "üß™ Should Test:    $SHOULD_TEST"

                  # ‚îÄ‚îÄ Write outputs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  {
                    echo "environment=$ENV"
                    echo "domain=$DOMAIN"
                    echo "build_strategy=$STRATEGY"
                    echo "should_deploy=$SHOULD_DEPLOY"
                    echo "should_test=$SHOULD_TEST"
                  } >> "$GITHUB_OUTPUT"

                  # ‚îÄ‚îÄ Validate optional secrets ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  MISSING=""
                  if [ "$HAS_PROD_IP" != "true" ]; then MISSING="$MISSING PROD_TAILSCALE_IP"; fi
                  if [ "$HAS_SSH_KEY" != "true" ]; then MISSING="$MISSING PROD_SSH_KEY"; fi
                  if [ "$HAS_TAILSCALE" != "true" ]; then MISSING="$MISSING TAILSCALE_OAUTH_CLIENT_ID"; fi
                  if [ "$HAS_STAGING_IP" != "true" ]; then MISSING="$MISSING STAGING_TAILSCALE_IP"; fi

                  if [ -n "$MISSING" ]; then
                    echo "‚ö†Ô∏è Missing secrets:$MISSING"
                    echo "## ‚ö†Ô∏è Missing Secrets" >> $GITHUB_STEP_SUMMARY
                    echo "Configure these secrets:$MISSING" >> $GITHUB_STEP_SUMMARY
                  fi

                  # ‚îÄ‚îÄ Summary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  cat >> $GITHUB_STEP_SUMMARY << EOF
                  ## üéØ Environment Configuration
                  | Property | Value |
                  |----------|-------|
                  | Target | \`$ENV\` |
                  | Domain | \`$DOMAIN\` |
                  | Build Strategy | \`$STRATEGY\` |
                  | Should Deploy | \`$SHOULD_DEPLOY\` |
                  | Should Test | \`$SHOULD_TEST\` |
                  | Branch | \`${{ github.ref_name }}\` |
                  | Trigger | \`${{ github.event_name }}\` |
                  EOF

    # =========================================================================
    # STAGE 2a: LINT (fast gate ‚Äî blocks all test jobs)
    # =========================================================================
    test-lint:
        name: üßπ Lint & Format
        runs-on: ubuntu-latest
        timeout-minutes: 20
        needs: [setup]
        if: needs.setup.outputs.should_test == 'true'
        steps:
            - name: üì• Checkout code
              uses: actions/checkout@v4

            - name: ü¶Ä Run Lint Checks
              uses: nuniesmith/actions/.github/actions/rust-ci@main
              with:
                  toolchain: ${{ env.RUST_VERSION }}
                  components: clippy, rustfmt
                  install-protobuf: "true"
                  run-fmt: "true"
                  run-clippy: "true"
                  run-tests: "false"
                  run-build: "false"
                  workspace: "true"
                  all-features: "false"
                  clippy-args: "--all-targets"

    # =========================================================================
    # STAGE 2b: TESTS (4 parallel groups, gated by lint)
    # =========================================================================
    #
    # Test groups are split by domain to maximize parallelism on CI runners.
    # Each group compiles only its packages, keeping memory and time bounded.
    #
    # Group           ‚îÇ Packages                                    ‚îÇ ~Tests
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # core            ‚îÇ Core libs, utilities, small crates          ‚îÇ   ~680
    # neuromorphic    ‚îÇ janus-neuromorphic (brain regions)          ‚îÇ  ~5200
    # services        ‚îÇ forward, execution, data, gateway, etc.    ‚îÇ  ~2100
    # trading         ‚îÇ strategies, ML, backtest, regime, audit     ‚îÇ  ~1900
    # =========================================================================

    test-core:
        name: üß± Tests ‚Äî Core & Libraries
        runs-on: ubuntu-latest
        timeout-minutes: 30
        needs: [setup, test-lint]
        if: needs.setup.outputs.should_test == 'true'
        env:
            CARGO_BUILD_JOBS: 4
            CARGO_INCREMENTAL: 0
            RUSTFLAGS: "-D warnings"
        steps:
            - name: üì• Checkout code
              uses: actions/checkout@v4

            - name: ü¶Ä Install Rust toolchain
              uses: dtolnay/rust-toolchain@stable
              with:
                  toolchain: ${{ env.RUST_VERSION }}

            - name: üì¶ Install protobuf compiler
              run: |
                  sudo apt-get update -qq
                  sudo apt-get install -y -qq protobuf-compiler libprotobuf-dev

            - name: üóÑÔ∏è Cargo cache
              uses: actions/cache@v4
              with:
                  path: |
                      ~/.cargo/bin/
                      ~/.cargo/registry/index/
                      ~/.cargo/registry/cache/
                      ~/.cargo/git/db/
                      target/
                  key: ${{ runner.os }}-cargo-core-${{ hashFiles('**/Cargo.lock') }}
                  restore-keys: |
                      ${{ runner.os }}-cargo-core-
                      ${{ runner.os }}-cargo-

            - name: üì¶ Install cargo-nextest
              uses: taiki-e/install-action@nextest

            - name: üß™ Run core & library tests
              run: |
                  echo "::group::Running core & library tests"
                  cargo nextest run --profile ci \
                    -p janus-core \
                    -p common \
                    -p fks-proto \
                    -p janus-health \
                    -p janus-indicators \
                    -p janus-models \
                    -p janus-compliance \
                    -p janus-gap-detection \
                    -p janus-rate-limiter \
                    -p janus-questdb-writer \
                    -p janus-bybit-client \
                    -p logic \
                    -p memory \
                    -p training \
                    -p janus-data-quality \
                    -p janus-dsp \
                    -p janus-ltn \
                    -p janus-risk \
                    -p janus-exchanges \
                    -p apalis-redis \
                    --color always
                  echo "::endgroup::"

            - name: üìä Publish Test Report ‚Äî Core & Libraries
              uses: mikepenz/action-junit-report@v5
              if: always()
              with:
                  check_name: "üß± Rust ‚Äî Core & Libraries"
                  report_paths: "target/nextest/ci/junit.xml"
                  include_passed: true
                  detailed_summary: true
                  fail_on_failure: false

            - name: üì§ Upload JUnit XML
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: junit-core
                  path: target/nextest/ci/junit.xml
                  retention-days: 7
                  if-no-files-found: ignore

    test-neuro-core:
        name: üß† Tests ‚Äî Neuromorphic (Core)
        runs-on: ubuntu-latest
        timeout-minutes: 45
        needs: [setup, test-lint]
        if: needs.setup.outputs.should_test == 'true'
        env:
            CARGO_BUILD_JOBS: 4
            CARGO_INCREMENTAL: 0
            RUSTFLAGS: "-D warnings"
        steps:
            - name: üì• Checkout code
              uses: actions/checkout@v4

            - name: ü¶Ä Install Rust toolchain
              uses: dtolnay/rust-toolchain@stable
              with:
                  toolchain: ${{ env.RUST_VERSION }}

            - name: üì¶ Install protobuf compiler
              run: |
                  sudo apt-get update -qq
                  sudo apt-get install -y -qq protobuf-compiler libprotobuf-dev

            - name: üóÑÔ∏è Cargo cache
              uses: actions/cache@v4
              with:
                  path: |
                      ~/.cargo/bin/
                      ~/.cargo/registry/index/
                      ~/.cargo/registry/cache/
                      ~/.cargo/git/db/
                      target/
                  key: ${{ runner.os }}-cargo-neuro-core-${{ hashFiles('**/Cargo.lock') }}
                  restore-keys: |
                      ${{ runner.os }}-cargo-neuro-core-
                      ${{ runner.os }}-cargo-neuro-
                      ${{ runner.os }}-cargo-

            - name: üì¶ Install cargo-nextest
              uses: taiki-e/install-action@nextest

            - name: üß™ Run neuromorphic tests (excluding ViViT)
              run: |
                  echo "::group::Running neuromorphic core tests (~5100 tests)"
                  cargo nextest run --profile ci \
                    -p janus-neuromorphic \
                    -E 'not test(~visual_cortex::vivit)' \
                    --color always
                  echo "::endgroup::"

            - name: üìä Publish Test Report ‚Äî Neuromorphic (Core)
              uses: mikepenz/action-junit-report@v5
              if: always()
              with:
                  check_name: "üß† Rust ‚Äî Neuromorphic (Core)"
                  report_paths: "target/nextest/ci/junit.xml"
                  include_passed: true
                  detailed_summary: true
                  fail_on_failure: false

            - name: üì§ Upload JUnit XML
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: junit-neuro-core
                  path: target/nextest/ci/junit.xml
                  retention-days: 7
                  if-no-files-found: ignore

    test-neuro-vivit:
        name: üß† Tests ‚Äî Neuromorphic (ViViT)
        runs-on: ubuntu-latest
        timeout-minutes: 30
        needs: [setup, test-lint]
        if: needs.setup.outputs.should_test == 'true'
        env:
            CARGO_BUILD_JOBS: 4
            CARGO_INCREMENTAL: 0
            RUSTFLAGS: "-D warnings"
        steps:
            - name: üì• Checkout code
              uses: actions/checkout@v4

            - name: ü¶Ä Install Rust toolchain
              uses: dtolnay/rust-toolchain@stable
              with:
                  toolchain: ${{ env.RUST_VERSION }}

            - name: üì¶ Install protobuf compiler
              run: |
                  sudo apt-get update -qq
                  sudo apt-get install -y -qq protobuf-compiler libprotobuf-dev

            - name: üóÑÔ∏è Cargo cache
              uses: actions/cache@v4
              with:
                  path: |
                      ~/.cargo/bin/
                      ~/.cargo/registry/index/
                      ~/.cargo/registry/cache/
                      ~/.cargo/git/db/
                      target/
                  key: ${{ runner.os }}-cargo-neuro-vivit-${{ hashFiles('**/Cargo.lock') }}
                  restore-keys: |
                      ${{ runner.os }}-cargo-neuro-vivit-
                      ${{ runner.os }}-cargo-neuro-
                      ${{ runner.os }}-cargo-

            - name: üì¶ Install cargo-nextest
              uses: taiki-e/install-action@nextest

            - name: üß™ Run ViViT tests (ci-heavy profile ‚Äî extended timeouts)
              run: |
                  echo "::group::Running ViViT visual cortex tests"
                  cargo nextest run --profile ci-heavy \
                    -p janus-neuromorphic \
                    -E 'test(~visual_cortex::vivit)' \
                    --run-ignored all \
                    --color always
                  echo "::endgroup::"

            - name: üìä Publish Test Report ‚Äî Neuromorphic (ViViT)
              uses: mikepenz/action-junit-report@v5
              if: always()
              with:
                  check_name: "üß† Rust ‚Äî Neuromorphic (ViViT)"
                  report_paths: "target/nextest/ci-heavy/junit-heavy.xml"
                  include_passed: true
                  detailed_summary: true
                  fail_on_failure: false

            - name: üì§ Upload JUnit XML
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: junit-neuro-vivit
                  path: target/nextest/ci-heavy/junit-heavy.xml
                  retention-days: 7
                  if-no-files-found: ignore

    test-services:
        name: ‚öôÔ∏è Tests ‚Äî Services
        runs-on: ubuntu-latest
        timeout-minutes: 30
        needs: [setup, test-lint]
        if: needs.setup.outputs.should_test == 'true'
        env:
            CARGO_BUILD_JOBS: 4
            CARGO_INCREMENTAL: 0
            RUSTFLAGS: "-D warnings"
        steps:
            - name: üì• Checkout code
              uses: actions/checkout@v4

            - name: ü¶Ä Install Rust toolchain
              uses: dtolnay/rust-toolchain@stable
              with:
                  toolchain: ${{ env.RUST_VERSION }}

            - name: üì¶ Install protobuf compiler
              run: |
                  sudo apt-get update -qq
                  sudo apt-get install -y -qq protobuf-compiler libprotobuf-dev

            - name: üóÑÔ∏è Cargo cache
              uses: actions/cache@v4
              with:
                  path: |
                      ~/.cargo/bin/
                      ~/.cargo/registry/index/
                      ~/.cargo/registry/cache/
                      ~/.cargo/git/db/
                      target/
                  key: ${{ runner.os }}-cargo-svc-${{ hashFiles('**/Cargo.lock') }}
                  restore-keys: |
                      ${{ runner.os }}-cargo-svc-
                      ${{ runner.os }}-cargo-

            - name: üì¶ Install cargo-nextest
              uses: taiki-e/install-action@nextest

            - name: üß™ Run service tests
              run: |
                  echo "::group::Running service tests"
                  cargo nextest run --profile ci \
                    -p janus-forward \
                    -p janus-execution \
                    -p janus-data \
                    -p janus-gateway \
                    -p janus-api \
                    -p janus-backward \
                    -p janus-cns-service \
                    -p janus-optimizer-service \
                    -p janus-registry-lib \
                    -p janus-registry-service \
                    --color always
                  echo "::endgroup::"

            - name: üìä Publish Test Report ‚Äî Services
              uses: mikepenz/action-junit-report@v5
              if: always()
              with:
                  check_name: "‚öôÔ∏è Rust ‚Äî Services"
                  report_paths: "target/nextest/ci/junit.xml"
                  include_passed: true
                  detailed_summary: true
                  fail_on_failure: false

            - name: üì§ Upload JUnit XML
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: junit-services
                  path: target/nextest/ci/junit.xml
                  retention-days: 7
                  if-no-files-found: ignore

    test-trading:
        name: üìà Tests ‚Äî Trading & ML (Janus)
        runs-on: ubuntu-latest
        timeout-minutes: 30
        needs: [setup, test-lint]
        if: needs.setup.outputs.should_test == 'true'
        env:
            CARGO_BUILD_JOBS: 4
            CARGO_INCREMENTAL: 0
            RUSTFLAGS: "-D warnings"
        steps:
            - name: üì• Checkout code
              uses: actions/checkout@v4

            - name: ü¶Ä Install Rust toolchain
              uses: dtolnay/rust-toolchain@stable
              with:
                  toolchain: ${{ env.RUST_VERSION }}

            - name: üì¶ Install protobuf compiler
              run: |
                  sudo apt-get update -qq
                  sudo apt-get install -y -qq protobuf-compiler libprotobuf-dev

            - name: üóÑÔ∏è Cargo cache
              uses: actions/cache@v4
              with:
                  path: |
                      ~/.cargo/bin/
                      ~/.cargo/registry/index/
                      ~/.cargo/registry/cache/
                      ~/.cargo/git/db/
                      target/
                  key: ${{ runner.os }}-cargo-trading-${{ hashFiles('**/Cargo.lock') }}
                  restore-keys: |
                      ${{ runner.os }}-cargo-trading-
                      ${{ runner.os }}-cargo-

            - name: üì¶ Install cargo-nextest
              uses: taiki-e/install-action@nextest

            - name: üß™ Run trading & ML tests
              run: |
                  echo "::group::Running trading & ML tests (Janus)"
                  cargo nextest run --profile ci \
                    -p janus-strategies \
                    -p janus-cns \
                    -p janus-ml \
                    -p janus-regime \
                    -p janus-optimizer \
                    -p janus-backtest \
                    -p janus-lob \
                    --color always
                  echo "::endgroup::"

            - name: üìä Publish Test Report ‚Äî Trading & ML
              uses: mikepenz/action-junit-report@v5
              if: always()
              with:
                  check_name: "üìà Rust ‚Äî Trading & ML (Janus)"
                  report_paths: "target/nextest/ci/junit.xml"
                  include_passed: true
                  detailed_summary: true
                  fail_on_failure: false

            - name: üì§ Upload JUnit XML
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: junit-trading
                  path: target/nextest/ci/junit.xml
                  retention-days: 7
                  if-no-files-found: ignore

    # ‚îÄ‚îÄ fks-audit (independent of Janus) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    test-audit:
        name: üîç Tests ‚Äî Audit (fks-audit)
        runs-on: ubuntu-latest
        timeout-minutes: 20
        needs: [setup, test-lint]
        if: needs.setup.outputs.should_test == 'true'
        env:
            CARGO_BUILD_JOBS: 4
            CARGO_INCREMENTAL: 0
            RUSTFLAGS: "-D warnings"
        steps:
            - name: üì• Checkout code
              uses: actions/checkout@v4

            - name: ü¶Ä Install Rust toolchain
              uses: dtolnay/rust-toolchain@stable
              with:
                  toolchain: ${{ env.RUST_VERSION }}

            - name: üì¶ Install protobuf compiler
              run: |
                  sudo apt-get update -qq
                  sudo apt-get install -y -qq protobuf-compiler libprotobuf-dev

            - name: üóÑÔ∏è Cargo cache
              uses: actions/cache@v4
              with:
                  path: |
                      ~/.cargo/bin/
                      ~/.cargo/registry/index/
                      ~/.cargo/registry/cache/
                      ~/.cargo/git/db/
                      target/
                  key: ${{ runner.os }}-cargo-audit-${{ hashFiles('**/Cargo.lock') }}
                  restore-keys: |
                      ${{ runner.os }}-cargo-audit-
                      ${{ runner.os }}-cargo-

            - name: üì¶ Install cargo-nextest
              uses: taiki-e/install-action@nextest

            - name: üß™ Run audit tests
              run: |
                  echo "::group::Running fks-audit tests"
                  cargo nextest run --profile ci \
                    -p fks-audit \
                    --color always
                  echo "::endgroup::"

            - name: üìä Publish Test Report ‚Äî Audit
              uses: mikepenz/action-junit-report@v5
              if: always()
              with:
                  check_name: "üîç Rust ‚Äî Audit (fks-audit)"
                  report_paths: "target/nextest/ci/junit.xml"
                  include_passed: true
                  detailed_summary: true
                  fail_on_failure: false

            - name: üì§ Upload JUnit XML
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: junit-audit
                  path: target/nextest/ci/junit.xml
                  retention-days: 7
                  if-no-files-found: ignore

    # =========================================================================
    # STAGE 2c: KMP TESTS
    # =========================================================================
    test-kmp:
        name: üì± KMP Tests
        runs-on: ubuntu-latest
        timeout-minutes: 30
        needs: [setup]
        if: needs.setup.outputs.should_test == 'true'
        steps:
            - name: üì• Checkout code
              uses: actions/checkout@v4

            - name: üì± Run KMP CI
              uses: nuniesmith/actions/.github/actions/kotlin-ci@main
              with:
                  java-version: "21"
                  java-distribution: "temurin"
                  working-directory: src/clients
                  run-tests: "true"
                  run-build: "true"
                  test-task: "check"
                  upload-test-results: "true"

    # =========================================================================
    # STAGE 2d: INTEGRATION TESTS (with service containers)
    # =========================================================================
    #
    # These tests require real infrastructure (Redis, QuestDB) and are marked
    # #[ignore] in the source. We run them here with --run-ignored ignored-only
    # so they execute against the service containers below.
    # =========================================================================
    test-integration:
        name: üîó Tests ‚Äî Integration (DB)
        runs-on: ubuntu-latest
        timeout-minutes: 30
        needs: [setup, test-lint]
        if: needs.setup.outputs.should_test == 'true'
        services:
            redis:
                image: redis:7-alpine
                ports:
                    - 6379:6379
                options: >-
                    --health-cmd "redis-cli ping"
                    --health-interval 10s
                    --health-timeout 5s
                    --health-retries 5
            questdb:
                image: questdb/questdb:9.3.2
                ports:
                    - 9000:9000
                    - 9009:9009
                options: >-
                    --health-cmd "curl -sf http://localhost:9000/exec?query=SELECT%201 || exit 1"
                    --health-interval 10s
                    --health-timeout 5s
                    --health-retries 15
                    --health-start-period 30s
        env:
            CARGO_BUILD_JOBS: 4
            CARGO_INCREMENTAL: 0
            RUSTFLAGS: "-D warnings"
            QUESTDB_HOST: localhost
            QUESTDB_ILP_PORT: 9009
            REDIS_URL: "redis://localhost:6379"
            RUN_INTEGRATION_TESTS: "1"
            KRAKEN_API_KEY: ${{ secrets.KRAKEN_API_KEY }}
            KRAKEN_API_SECRET: ${{ secrets.KRAKEN_API_SECRET }}
        steps:
            - name: üì• Checkout code
              uses: actions/checkout@v4

            - name: ü¶Ä Install Rust toolchain
              uses: dtolnay/rust-toolchain@stable
              with:
                  toolchain: ${{ env.RUST_VERSION }}

            - name: üì¶ Install protobuf compiler
              run: |
                  sudo apt-get update -qq
                  sudo apt-get install -y -qq protobuf-compiler libprotobuf-dev

            - name: üóÑÔ∏è Cargo cache
              uses: actions/cache@v4
              with:
                  path: |
                      ~/.cargo/bin/
                      ~/.cargo/registry/index/
                      ~/.cargo/registry/cache/
                      ~/.cargo/git/db/
                      target/
                  key: ${{ runner.os }}-cargo-integ-${{ hashFiles('**/Cargo.lock') }}
                  restore-keys: |
                      ${{ runner.os }}-cargo-integ-
                      ${{ runner.os }}-cargo-

            - name: üì¶ Install cargo-nextest
              uses: taiki-e/install-action@nextest

            - name: üß™ Run integration tests (ignored tests with DB + Kraken services)
              run: |
                  echo "::group::Running integration tests against Redis + QuestDB + Kraken"
                  cargo nextest run --profile ci \
                    --run-ignored ignored-only \
                    -p janus-data \
                    -p janus-rate-limiter \
                    -p apalis-redis \
                    -p janus-execution \
                    --color always
                  echo "::endgroup::"

            - name: üìä Publish Test Report ‚Äî Integration
              uses: mikepenz/action-junit-report@v5
              if: always()
              with:
                  check_name: "üîó Rust ‚Äî Integration (DB + Kraken)"
                  report_paths: "target/nextest/ci/junit.xml"
                  include_passed: true
                  detailed_summary: true
                  fail_on_failure: false

            - name: üì§ Upload JUnit XML
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: junit-integration
                  path: target/nextest/ci/junit.xml
                  retention-days: 7
                  if-no-files-found: ignore

    # =========================================================================
    # STAGE 3: DOCKER BUILD (gated by tests ‚Äî only runs after all tests pass)
    # =========================================================================
    docker-build:
        name: üê≥ Docker (${{ matrix.service.name }})
        runs-on: ubuntu-latest
        timeout-minutes: 45
        needs:
            [
                setup,
                test-lint,
                test-core,
                test-neuro-core,
                test-neuro-vivit,
                test-services,
                test-trading,
                test-audit,
                test-integration,
            ]
        if: |
            always() &&
            needs.setup.result == 'success' &&
            (needs.test-lint.result == 'success' || needs.test-lint.result == 'skipped') &&
            (needs.test-core.result == 'success' || needs.test-core.result == 'skipped') &&
            (needs.test-neuro-core.result == 'success' || needs.test-neuro-core.result == 'skipped') &&
            (needs.test-neuro-vivit.result == 'success' || needs.test-neuro-vivit.result == 'skipped') &&
            (needs.test-services.result == 'success' || needs.test-services.result == 'skipped') &&
            (needs.test-trading.result == 'success' || needs.test-trading.result == 'skipped') &&
            (needs.test-audit.result == 'success' || needs.test-audit.result == 'skipped') &&
            (needs.test-integration.result == 'success' || needs.test-integration.result == 'skipped') &&
            needs.setup.outputs.build_strategy == 'dockerhub' &&
            needs.setup.outputs.should_deploy == 'true'
        strategy:
            fail-fast: false
            matrix:
                service:
                    - name: janus
                      dockerfile: infrastructure/docker/base/rust/Dockerfile
                      target: workspace
                      build_args: SERVICE_NAME=janus
                    - name: audit
                      dockerfile: infrastructure/docker/base/rust/Dockerfile
                      target: audit
                      build_args: ""
                    - name: web
                      dockerfile: infrastructure/docker/services/web/Dockerfile
                      target: production
                      build_args: ""
                    - name: authelia
                      dockerfile: infrastructure/docker/services/authelia/Dockerfile
                      target: runtime
                      build_args: ""
                    - name: nginx
                      dockerfile: infrastructure/docker/services/nginx/Dockerfile
                      target: production
                      build_args: ""
                    - name: redis
                      dockerfile: infrastructure/docker/services/redis/Dockerfile
                      target: production
                      build_args: ""
        steps:
            - name: üì• Checkout code
              uses: actions/checkout@v4

            - name: üê≥ Build and Push
              uses: nuniesmith/actions/.github/actions/docker-build-push@main
              with:
                  image-name: ${{ env.IMAGE_NAME }}
                  username: ${{ secrets.DOCKER_USERNAME }}
                  password: ${{ secrets.DOCKER_TOKEN }}
                  dockerfile: ${{ matrix.service.dockerfile }}
                  context: .
                  platforms: linux/amd64
                  push: "true"
                  tags: |
                      type=raw,value=${{ matrix.service.name }}-latest
                      type=raw,value=${{ matrix.service.name }}-${{ github.sha }}
                      type=raw,value=${{ matrix.service.name }}-${{ needs.setup.outputs.deploy_env }}
                  build-args: ${{ matrix.service.build_args }}
                  target: ${{ matrix.service.target }}

    # =========================================================================
    # STAGE 4: DEPLOY
    # =========================================================================
    # Deploy is gated on:
    #   - setup succeeded
    #   - Docker build succeeded (or was skipped for server-build strategy)
    #   - ALL test groups passed (or were skipped via skip_tests input)
    #
    # This ensures we never deploy code that fails tests unless the operator
    # explicitly chose to skip them.
    # =========================================================================
    deploy:
        name: üöÄ Deploy to ${{ needs.setup.outputs.deploy_env }}
        runs-on: ubuntu-latest
        timeout-minutes: 45
        needs:
            [
                setup,
                docker-build,
                test-lint,
                test-core,
                test-neuro-core,
                test-neuro-vivit,
                test-services,
                test-trading,
                test-audit,
                test-integration,
            ]
        if: |
            always() &&
            needs.setup.result == 'success' &&
            (needs.docker-build.result == 'success' || needs.docker-build.result == 'skipped') &&
            (needs.test-lint.result == 'success' || needs.test-lint.result == 'skipped') &&
            (needs.test-core.result == 'success' || needs.test-core.result == 'skipped') &&
            (needs.test-neuro-core.result == 'success' || needs.test-neuro-core.result == 'skipped') &&
            (needs.test-neuro-vivit.result == 'success' || needs.test-neuro-vivit.result == 'skipped') &&
            (needs.test-services.result == 'success' || needs.test-services.result == 'skipped') &&
            (needs.test-trading.result == 'success' || needs.test-trading.result == 'skipped') &&
            (needs.test-audit.result == 'success' || needs.test-audit.result == 'skipped') &&
            (needs.test-integration.result == 'success' || needs.test-integration.result == 'skipped') &&
            needs.setup.outputs.should_deploy == 'true'
        environment:
            name: ${{ needs.setup.outputs.deploy_env }}
            url: https://${{ needs.setup.outputs.target_domain }}
        outputs:
            deployed: ${{ steps.deploy.outputs.deployed }}
            build_strategy_used: ${{ steps.deploy.outputs.build-strategy-used }}
            ssl_cert_type: ${{ steps.ssl-check.outputs.cert-type || steps.ssl-request.outputs.cert-type || steps.ssl-fallback.outputs.cert_type || steps.ssl-self-signed.outputs.cert-type || '' }}
            ssl_deployed: ${{ steps.ssl-request.outputs.deployed || steps.ssl-self-signed.outputs.deployed || steps.ssl-fallback.outputs.use_existing || steps.ssl-check.outputs.skip-generation || '' }}
            http_health: ${{ steps.health-checks.outputs.healthy }}
        steps:
            - name: üì• Checkout code
              uses: actions/checkout@v4

            # -----------------------------------------------------------------
            # RESOLVE TARGET HOST (in-job ‚Äî secrets can't reliably pass cross-job)
            # -----------------------------------------------------------------
            - name: üéØ Resolve target host
              id: resolve-host
              env:
                  DEPLOY_ENV: ${{ needs.setup.outputs.deploy_env }}
                  PROD_IP: ${{ secrets.PROD_TAILSCALE_IP }}
                  STAGING_IP: ${{ secrets.STAGING_TAILSCALE_IP }}
              run: |
                  if [ "$DEPLOY_ENV" = "production" ]; then
                    HOST="$PROD_IP"
                  else
                    HOST="${STAGING_IP:-$PROD_IP}"
                  fi

                  if [ -z "$HOST" ]; then
                    echo "‚ùå FATAL: Could not resolve target host IP!"
                    echo "   DEPLOY_ENV=$DEPLOY_ENV"
                    exit 1
                  fi

                  echo "target_host=$HOST" >> "$GITHUB_OUTPUT"
                  echo "‚úÖ Target host: $HOST (env: $DEPLOY_ENV)"

            # -----------------------------------------------------------------
            # TAILSCALE CONNECTION
            # -----------------------------------------------------------------
            - name: üîå Connect to Tailscale
              id: tailscale
              uses: nuniesmith/actions/.github/actions/tailscale-connect@main
              with:
                  oauth-client-id: ${{ secrets.TAILSCALE_OAUTH_CLIENT_ID }}
                  oauth-secret: ${{ secrets.TAILSCALE_OAUTH_SECRET }}
                  target-ip: ${{ steps.resolve-host.outputs.target_host }}
                  target-ssh-port: ${{ secrets.PROD_SSH_PORT || '22' }}

            # -----------------------------------------------------------------
            # SSH KEY SETUP (needed by SSL check, fallback, and deploy steps)
            # -----------------------------------------------------------------
            - name: üîê Setup SSH Key
              id: ssh-key-setup
              if: steps.tailscale.outputs.connected == 'true'
              env:
                  SSH_KEY: ${{ secrets.PROD_SSH_KEY }}
                  SSH_HOST: ${{ steps.resolve-host.outputs.target_host }}
                  SSH_PORT: ${{ secrets.PROD_SSH_PORT || '22' }}
              run: |
                  mkdir -p ~/.ssh
                  chmod 700 ~/.ssh

                  if [ -z "$SSH_KEY" ]; then
                    echo "‚ö†Ô∏è PROD_SSH_KEY not set ‚Äî SSH-dependent steps will be skipped"
                    echo "key_ready=false" >> "$GITHUB_OUTPUT"
                    exit 0
                  fi

                  echo "$SSH_KEY" > ~/.ssh/deploy_key
                  chmod 600 ~/.ssh/deploy_key

                  # Add host key to known_hosts
                  ssh-keyscan -p "$SSH_PORT" "$SSH_HOST" >> ~/.ssh/known_hosts 2>/dev/null || true

                  # Configure SSH defaults
                  cat >> ~/.ssh/config << SSHEOF
                  Host $SSH_HOST
                      StrictHostKeyChecking no
                      UserKnownHostsFile /dev/null
                      ConnectTimeout 15
                      ServerAliveInterval 15
                      ServerAliveCountMax 6
                      Port $SSH_PORT
                      LogLevel ERROR
                  SSHEOF

                  echo "‚úÖ SSH key configured at ~/.ssh/deploy_key"
                  echo "key_ready=true" >> "$GITHUB_OUTPUT"

            # -----------------------------------------------------------------
            # DNS UPDATE
            # -----------------------------------------------------------------
            - name: üåê Update Cloudflare DNS
              if: steps.tailscale.outputs.connected == 'true' && steps.resolve-host.outputs.target_host != ''
              uses: nuniesmith/actions/.github/actions/cloudflare-dns-update@main
              continue-on-error: true
              with:
                  api-token: ${{ secrets.CLOUDFLARE_API_KEY }}
                  zone-id: ${{ secrets.CLOUDFLARE_ZONE_ID }}
                  record-name: ${{ needs.setup.outputs.target_domain }}
                  record-content: ${{ steps.resolve-host.outputs.target_host }}
                  additional-records: |
                      [
                        {"name": "www.${{ needs.setup.outputs.target_domain }}"},
                        {"name": "dev.${{ needs.setup.outputs.target_domain }}"},
                        {"name": "staging.${{ needs.setup.outputs.target_domain }}"}
                      ]

            # -----------------------------------------------------------------
            # SSL CERTIFICATE CHECK (shared action ‚Äî Docker volume + host FS)
            # -----------------------------------------------------------------
            - name: üîç Check Existing SSL Certificates
              id: ssl-check
              if: github.ref == 'refs/heads/main' && inputs.skip_ssl != true && steps.ssh-key-setup.outputs.key_ready == 'true'
              continue-on-error: true
              uses: nuniesmith/actions/.github/actions/ssl-check@main
              with:
                  ssh-host: ${{ steps.resolve-host.outputs.target_host }}
                  ssh-port: ${{ secrets.PROD_SSH_PORT || '22' }}
                  ssh-user: ${{ secrets.PROD_SSH_USER || 'actions' }}
                  ssh-key: ${{ secrets.PROD_SSH_KEY }}
                  domain: ${{ needs.setup.outputs.target_domain }}
                  docker-volume-name: ${{ env.SSL_VOLUME_NAME }}
                  renewal-threshold-percent: "70"

            # -----------------------------------------------------------------
            # SSL CERTIFICATE GENERATION (Phase 1: Try Certbot ‚Äî only if needed)
            # -----------------------------------------------------------------
            - name: üîê Request SSL Certificates
              id: ssl-request
              if: |
                  github.ref == 'refs/heads/main' &&
                  inputs.skip_ssl != true &&
                  steps.ssh-key-setup.outputs.key_ready == 'true' &&
                  steps.ssl-check.outputs.skip-generation != 'true'
              continue-on-error: true
              uses: nuniesmith/actions/.github/actions/ssl-certbot-cloudflare@main
              with:
                  domain: ${{ needs.setup.outputs.target_domain }}
                  additional-domains: "www.${{ needs.setup.outputs.target_domain }}"
                  cloudflare-api-token: ${{ secrets.CLOUDFLARE_API_KEY }}
                  email: ${{ secrets.SSL_EMAIL }}
                  fallback-to-self-signed: "false"
                  deploy-to-server: true
                  ssh-host: ${{ steps.resolve-host.outputs.target_host }}
                  ssh-port: ${{ secrets.PROD_SSH_PORT || '22' }}
                  ssh-user: ${{ secrets.PROD_SSH_USER || 'actions' }}
                  ssh-key: ${{ secrets.PROD_SSH_KEY }}
                  root-ssh-key: ${{ secrets.PROD_ROOT_SSH_KEY }}
                  docker-volume-name: ${{ env.SSL_VOLUME_NAME }}
                  docker-username: ${{ secrets.DOCKER_USERNAME }}
                  docker-token: ${{ secrets.DOCKER_TOKEN }}

            # -----------------------------------------------------------------
            # SSL FALLBACK ‚Äî Use existing certs if Certbot failed (rate limit, etc.)
            # -----------------------------------------------------------------
            - name: üîç SSL Fallback ‚Äî Use Existing Certs if Certbot Failed
              id: ssl-fallback
              if: |
                  github.ref == 'refs/heads/main' &&
                  inputs.skip_ssl != true &&
                  steps.ssl-request.outcome == 'failure' &&
                  steps.ssl-check.outputs.cert-exists == 'true' &&
                  steps.ssh-key-setup.outputs.key_ready == 'true'
              env:
                  DOMAIN: ${{ needs.setup.outputs.target_domain }}
                  SSH_HOST: ${{ steps.resolve-host.outputs.target_host }}
                  SSH_PORT: ${{ secrets.PROD_SSH_PORT || '22' }}
                  SSH_USER: ${{ secrets.PROD_SSH_USER || 'actions' }}
                  PRECHECK_CERT_TYPE: ${{ steps.ssl-check.outputs.cert-type }}
                  PRECHECK_DAYS: ${{ steps.ssl-check.outputs.days-remaining }}
                  PRECHECK_SOURCE: ${{ steps.ssl-check.outputs.cert-source }}
              run: |
                  echo "üîç SSL Certbot failed ‚Äî checking if existing volume certs are still usable..."
                  echo ""
                  echo "üìã Pre-check results from volume inspection:"
                  echo "   Cert type:       $PRECHECK_CERT_TYPE"
                  echo "   Days remaining:  $PRECHECK_DAYS"
                  echo "   Source:          $PRECHECK_SOURCE"

                  SSH_CMD="ssh -i ~/.ssh/deploy_key -p $SSH_PORT -o StrictHostKeyChecking=no $SSH_USER@$SSH_HOST"

                  # Re-verify certs are actually in the volume right now
                  VERIFY=$($SSH_CMD "docker run --rm -v ${{ env.SSL_VOLUME_NAME }}:/certs:ro busybox:1.37 sh -c '
                    test -f /certs/live/$DOMAIN/fullchain.pem && test -f /certs/live/$DOMAIN/privkey.pem && echo ok || echo missing
                  '" 2>/dev/null || echo "error")

                  if [ "$VERIFY" = "ok" ]; then
                    if [ "$PRECHECK_CERT_TYPE" = "letsencrypt" ] || [ "$PRECHECK_CERT_TYPE" = "self-signed" ]; then
                      echo ""
                      echo "‚úÖ Existing $PRECHECK_CERT_TYPE certificate verified in Docker volume ($PRECHECK_DAYS days remaining)"
                      echo "   Using existing certs ‚Äî Certbot renewal will be retried next deploy"
                      echo "cert_type=$PRECHECK_CERT_TYPE" >> "$GITHUB_OUTPUT"
                      echo "use_existing=true" >> "$GITHUB_OUTPUT"
                    else
                      echo ""
                      echo "‚ö†Ô∏è Certs exist but type is '$PRECHECK_CERT_TYPE' ‚Äî using them as fallback anyway"
                      echo "cert_type=$PRECHECK_CERT_TYPE" >> "$GITHUB_OUTPUT"
                      echo "use_existing=true" >> "$GITHUB_OUTPUT"
                    fi
                  else
                    echo "‚ùå Certificate files NOT found in Docker volume (verify: $VERIFY)"
                    echo "   Will need self-signed fallback"
                    echo "use_existing=false" >> "$GITHUB_OUTPUT"
                  fi

            # -----------------------------------------------------------------
            # SSL SELF-SIGNED (last resort)
            # -----------------------------------------------------------------
            - name: üîí Generate Self-Signed Certificates (last resort)
              id: ssl-self-signed
              if: |
                  github.ref == 'refs/heads/main' &&
                  inputs.skip_ssl != true &&
                  steps.ssl-check.outputs.skip-generation != 'true' &&
                  steps.ssl-request.outcome != 'success' &&
                  steps.ssl-fallback.outputs.use_existing != 'true' &&
                  steps.ssh-key-setup.outputs.key_ready == 'true'
              continue-on-error: true
              uses: nuniesmith/actions/.github/actions/ssl-certbot-cloudflare@main
              with:
                  domain: ${{ needs.setup.outputs.target_domain }}
                  additional-domains: "www.${{ needs.setup.outputs.target_domain }}"
                  cloudflare-api-token: ${{ secrets.CLOUDFLARE_API_KEY }}
                  email: ${{ secrets.SSL_EMAIL }}
                  fallback-to-self-signed: "true"
                  self-signed-days: "365"
                  deploy-to-server: true
                  ssh-host: ${{ steps.resolve-host.outputs.target_host }}
                  ssh-port: ${{ secrets.PROD_SSH_PORT || '22' }}
                  ssh-user: ${{ secrets.PROD_SSH_USER || 'actions' }}
                  ssh-key: ${{ secrets.PROD_SSH_KEY }}
                  root-ssh-key: ${{ secrets.PROD_ROOT_SSH_KEY }}
                  docker-volume-name: ${{ env.SSL_VOLUME_NAME }}
                  docker-username: ${{ secrets.DOCKER_USERNAME }}
                  docker-token: ${{ secrets.DOCKER_TOKEN }}

            # -----------------------------------------------------------------
            # DEPLOY
            # -----------------------------------------------------------------
            - name: üöÄ Deploy via SSH
              id: deploy
              uses: nuniesmith/actions/.github/actions/ssh-deploy@main
              with:
                  # ‚îÄ‚îÄ SSH Connection ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  host: ${{ steps.resolve-host.outputs.target_host }}
                  port: ${{ secrets.PROD_SSH_PORT || '22' }}
                  username: ${{ secrets.PROD_SSH_USER || 'actions' }}
                  ssh-key: ${{ secrets.PROD_SSH_KEY }}
                  ssh-retries: "3"
                  ssh-retry-delay: "10"
                  command-timeout: "600"

                  # ‚îÄ‚îÄ Project ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  project-path: ~/fks
                  git-pull: "true"
                  git-branch: ${{ github.ref_name }}
                  git-repo-url: "https://github.com/nuniesmith/fks.git"

                  # ‚îÄ‚îÄ Build Strategy ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  build-strategy: ${{ needs.setup.outputs.build_strategy }}

                  # ‚îÄ‚îÄ Docker Registry ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  docker-registry: docker.io
                  docker-username: ${{ secrets.DOCKER_USERNAME }}
                  docker-password: ${{ secrets.DOCKER_TOKEN }}
                  docker-image-prefix: ${{ env.IMAGE_NAME }}
                  docker-image-tag: ${{ github.sha }}

                  # ‚îÄ‚îÄ Docker Compose ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  compose-files: "infrastructure/compose/docker-compose.yml infrastructure/compose/docker-compose.prod.yml"
                  compose-project: fks
                  compose-env-file: .env

                  # ‚îÄ‚îÄ Services ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  app-services: "janus audit web authelia nginx"
                  infra-services: "redis postgres questdb prometheus grafana alertmanager-discord-bridge alertmanager"

                  # ‚îÄ‚îÄ Cleanup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  docker-prune: "true"

                  # ‚îÄ‚îÄ Pre-Deploy ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  pre-deploy-command: |
                      echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
                      echo "üìã PRE-DEPLOY: ${{ needs.setup.outputs.deploy_env }}"
                      echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
                      echo "üñ•Ô∏è  Host: $(hostname) | $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
                      echo "üë§ User: $(whoami) | HOME=$HOME"
                      echo "üìÅ PWD:  $(pwd)"
                      echo "üíæ Disk: $(df -h / | tail -1 | awk '{print $4}') free"

                      # .env status
                      echo ""
                      if [ -f .env ]; then
                        echo "üìÑ .env exists ($(wc -l < .env) lines, $(grep -c '^[A-Z]' .env 2>/dev/null || echo '?') keys)"
                      else
                        echo "üìÑ No .env ‚Äî will be created during deploy"
                      fi

                      # Ensure all Docker volumes exist
                      echo ""
                      echo "üì¶ Creating Docker volumes..."
                      for vol in ${{ env.SSL_VOLUME_NAME }} fks_certbot_www fks_postgres_data fks_questdb_data fks_redis_data fks_grafana_data fks_prometheus_data fks_loki_data fks_alertmanager_data fks_optimizer_data fks_promtail_positions fks_nginx_logs; do
                        docker volume create $vol 2>/dev/null || true
                      done
                      echo "‚úÖ Docker volumes ready"

                  # ‚îÄ‚îÄ Deploy (custom commands that run AFTER strategy build) ‚îÄ
                  # ‚îÄ‚îÄ .env Generation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  # Use the new env-setup-command to run run.sh or fallback
                  env-setup-command: |
                      echo "üîê Setting up .env file..."

                      # Try run.sh first (primary method)
                      ENV_CREATED=false
                      if [ -f ./run.sh ]; then
                        echo "   ‚ñ∂ Running: bash ./run.sh setup-env"
                        bash ./run.sh setup-env 2>&1 || true
                        if [ -f .env ] && [ -s .env ]; then
                          echo "   ‚úÖ .env exists after run.sh ($(wc -l < .env) lines)"
                          ENV_CREATED=true
                        fi
                      fi

                      # Fallback: create .env directly
                      if [ "$ENV_CREATED" != "true" ]; then
                        echo "   üîÑ Fallback: Creating .env directly..."
                        GEN_PASS() { openssl rand -base64 24 2>/dev/null | tr -d '/+=' | head -c 16 || cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 16 | head -n 1; }
                        GEN_SECRET() { openssl rand -hex 16 2>/dev/null || cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 32 | head -n 1; }
                        GEN_LONG() { openssl rand -base64 96 2>/dev/null | tr -d "=+/\n" | cut -c1-64 || cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 64 | head -n 1; }

                        cat > .env << 'ENVEOF'
                      # FKS Trading System - Auto-generated by CI/CD fallback
                      ENVEOF
                        # Generate with variable expansion
                        cat >> .env << ENVEOF
                      POSTGRES_PASSWORD=$(GEN_PASS)
                      POSTGRES_DB=fks
                      POSTGRES_USER=fks_user
                      QUESTDB_PASSWORD=$(GEN_PASS)
                      QUESTDB_USER=admin
                      REDIS_PASSWORD=$(GEN_PASS)
                      GRAFANA_PASSWORD=$(GEN_PASS)
                      GRAFANA_USER=admin
                      GF_SECURITY_SECRET_KEY=$(GEN_SECRET)
                      GATEWAY_SECRET_KEY=$(GEN_SECRET)
                      GATEWAY_JWT_SECRET=$(GEN_SECRET)
                      API_KEY=$(GEN_SECRET)
                      AUTHELIA_JWT_SECRET=$(GEN_LONG)
                      AUTHELIA_SESSION_SECRET=$(GEN_LONG)
                      AUTHELIA_STORAGE_ENCRYPTION_KEY=$(GEN_LONG)
                      AUTHELIA_IDENTITY_VALIDATION_RESET_PASSWORD_JWT_SECRET=$(GEN_LONG)
                      AUTHELIA_POSTGRES_PASSWORD=$(GEN_SECRET)
                      AUTHELIA_POSTGRES_DB=authelia
                      AUTHELIA_POSTGRES_USER=authelia
                      DATA_SERVICE_JWT_SECRET=$(GEN_SECRET)
                      DATA_SERVICE_JWT_EXPIRY=86400
                      ENVIRONMENT=production
                      LOG_LEVEL=info
                      RUST_LOG=info
                      RUST_BACKTRACE=1
                      SSL_EMAIL=${{ secrets.SSL_EMAIL }}
                      SSL_DOMAIN=${{ needs.setup.outputs.target_domain }}
                      SSL_STAGING=false
                      DISCORD_WEBHOOK_URL=
                      DISCORD_BOT_TOKEN=
                      DISCORD_NOTIFICATIONS_ENABLED=false
                      DISCORD_NOTIFY_ON_SIGNAL=true
                      DISCORD_NOTIFY_ON_FILL=true
                      DISCORD_NOTIFY_ON_ERROR=true
                      DISCORD_WEBHOOK_GENERAL=
                      BYBIT_API_KEY=
                      BYBIT_API_SECRET=
                      BYBIT_TESTNET=true
                      BINANCE_API_KEY=
                      BINANCE_API_SECRET=
                      KRAKEN_API_KEY=
                      KRAKEN_API_SECRET=
                      REAL_ORDERS_ENABLED=false
                      ENABLE_EXECUTION=true
                      EXECUTION_ENDPOINT=http://localhost:50052
                      ENVEOF
                        sed -i 's/^                      //' .env
                        echo "   ‚úÖ Fallback .env created ($(wc -l < .env) lines)"
                      fi

                      # Verify critical keys
                      MISSING_KEYS=0
                      for key in POSTGRES_PASSWORD POSTGRES_DB REDIS_PASSWORD ENABLE_EXECUTION; do
                        grep -q "^${key}=" .env 2>/dev/null || MISSING_KEYS=$((MISSING_KEYS + 1))
                      done
                      if [ "$MISSING_KEYS" -gt 2 ]; then
                        echo "   ‚ùå Too many critical keys missing ($MISSING_KEYS)"
                        exit 1
                      fi
                      echo "   ‚úÖ .env verification passed ($(grep -c '^[A-Z]' .env 2>/dev/null || echo '?') keys)"

                  # ‚îÄ‚îÄ Inject CI secrets into .env ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  env-inject-secrets: |
                      DISCORD_WEBHOOK_GENERAL=${{ secrets.DISCORD_WEBHOOK_GENERAL }}
                      KRAKEN_API_KEY=${{ secrets.KRAKEN_API_KEY }}
                      KRAKEN_API_SECRET=${{ secrets.KRAKEN_API_SECRET }}
                      BYBIT_API_KEY=${{ secrets.BYBIT_API_KEY }}
                      BYBIT_API_SECRET=${{ secrets.BYBIT_API_SECRET }}
                      BINANCE_API_KEY=${{ secrets.BINANCE_API_KEY }}
                      BINANCE_API_SECRET=${{ secrets.BINANCE_API_SECRET }}
                      DISCORD_WEBHOOK_URL=${{ secrets.DISCORD_WEBHOOK_URL }}
                      DISCORD_BOT_TOKEN=${{ secrets.DISCORD_BOT_TOKEN }}

                  # ‚îÄ‚îÄ Deploy (runs after env setup, uses built-in strategy) ‚îÄ
                  deploy-command: |
                      echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
                      echo "üöÄ DEPLOYING: ${{ needs.setup.outputs.deploy_env }}"
                      echo "   Strategy:  ${{ needs.setup.outputs.build_strategy }}"
                      echo "   Directory: $(pwd)"
                      echo "   Date:      $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
                      echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"

                      # Source .env for template generation
                      set -a && source .env && set +a

                      # Generate config files from templates
                      TMPL="infrastructure/monitoring/alertmanager/alertmanager.yml.tmpl"
                      DEST="infrastructure/monitoring/alertmanager/alertmanager.yml"
                      if [ -f "$TMPL" ]; then
                        cp "$TMPL" "$DEST"
                        echo "‚úÖ alertmanager.yml generated"
                      fi

                      # Build compose command
                      COMPOSE_CMD="docker compose -p fks --env-file .env -f infrastructure/compose/docker-compose.yml -f infrastructure/compose/docker-compose.prod.yml"

                      # Stop app services (keep infra running)
                      APP_SERVICES="janus audit web authelia nginx"
                      echo "üõë Stopping app services..."
                      $COMPOSE_CMD stop $APP_SERVICES 2>/dev/null || true
                      $COMPOSE_CMD rm -f $APP_SERVICES 2>/dev/null || true
                      docker container prune -f --filter "label=com.docker.compose.project=fks" 2>/dev/null || true

                      # Build or pull
                      STRATEGY="${{ needs.setup.outputs.build_strategy }}"
                      if [ "$STRATEGY" = "dockerhub" ]; then
                        echo "üì• Pulling from DockerHub..."
                        $COMPOSE_CMD pull $APP_SERVICES 2>&1 || { echo "‚ö†Ô∏è Falling back to server build"; STRATEGY="server-build"; }
                      fi
                      if [ "$STRATEGY" = "server-build" ]; then
                        echo "üî® Building on server..."
                        $COMPOSE_CMD build --parallel $APP_SERVICES 2>&1
                      fi

                      # Ensure infra is running
                      echo "üîß Starting infrastructure..."
                      $COMPOSE_CMD up -d --no-recreate redis postgres questdb prometheus grafana alertmanager-discord-bridge alertmanager 2>&1
                      docker kill --signal=HUP fks_alertmanager 2>/dev/null || true

                      # Wait for Redis
                      echo "‚è≥ Waiting for Redis..."
                      for i in $(seq 1 30); do
                        $COMPOSE_CMD exec -T redis redis-cli --no-auth-warning -a "${REDIS_PASSWORD:-}" ping < /dev/null 2>/dev/null | grep -q PONG && break
                        sleep 2
                      done

                      # Start everything
                      echo "üöÄ Starting all services..."
                      $COMPOSE_CMD up -d 2>&1
                      sleep 30
                      docker ps -a --filter "name=fks" --format "table {{.Names}}\t{{.Status}}" | head -20

                  # ‚îÄ‚îÄ Post-Deploy ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  post-deploy-command: |
                      echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
                      echo "üßπ POST-DEPLOY"
                      echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"

                      # Verify .env
                      [ -f .env ] && echo "‚úÖ .env persisted ($(wc -l < .env) lines)" || echo "‚ùå .env missing!"

                      # Restart nginx if SSL certs exist
                      DOMAIN="${{ needs.setup.outputs.target_domain }}"
                      if docker run --rm -v ${{ env.SSL_VOLUME_NAME }}:/certs:ro busybox:1.37 test -f "/certs/live/$DOMAIN/fullchain.pem" 2>/dev/null; then
                        echo "‚úÖ SSL certs found ‚Äî restarting nginx"
                        docker restart fks_nginx 2>/dev/null && sleep 5 || true
                      else
                        echo "‚ö†Ô∏è No SSL certs in volume ‚Äî nginx using fallback"
                      fi

                      echo ""
                      echo "üåê https://${{ needs.setup.outputs.target_domain }}"
                      echo "‚úÖ Deployment complete!"

            # -----------------------------------------------------------------
            # HEALTH CHECKS
            # -----------------------------------------------------------------
            - name: üè• Run Health Checks
              id: health-checks
              if: always() && steps.deploy.outcome == 'success'
              uses: nuniesmith/actions/.github/actions/health-check@main
              with:
                  endpoints: |
                      [
                        {"url": "http://${{ needs.setup.outputs.target_domain }}/health", "expected_status": 200},
                        {"url": "http://${{ needs.setup.outputs.target_domain }}/health/web", "expected_status": 200},
                        {"url": "http://${{ needs.setup.outputs.target_domain }}/health/janus", "expected_status": 200},
                        {"url": "http://${{ needs.setup.outputs.target_domain }}/health/grafana", "expected_status": 200}
                      ]
                  containers: fks_janus fks_audit fks_nginx fks_web
                  ssh-host: ${{ steps.resolve-host.outputs.target_host }}
                  ssh-port: ${{ secrets.PROD_SSH_PORT || '22' }}
                  ssh-user: ${{ secrets.PROD_SSH_USER || 'actions' }}
                  ssh-key: ${{ secrets.PROD_SSH_KEY }}
                  custom-command: |
                      echo "üîç Database connectivity check..."
                      docker exec fks_redis sh -c 'redis-cli --no-auth-warning -a "$REDIS_PASSWORD" ping' 2>/dev/null | grep -q "PONG" && echo "‚úÖ Redis OK" || echo "‚ùå Redis failed"
                      docker exec fks_postgres pg_isready -U fks_user 2>/dev/null | grep -q "accepting" && echo "‚úÖ PostgreSQL OK" || echo "‚ùå PostgreSQL failed"
                      curl -s "http://localhost:9000/exec?query=SELECT%201" 2>/dev/null | grep -q "dataset" && echo "‚úÖ QuestDB OK" || echo "‚ùå QuestDB failed"
                  initial-delay: "30"
                  retry-count: "3"
                  retry-delay: "10"
                  fail-on-unhealthy: "true"

            # -----------------------------------------------------------------
            # NOTIFICATION
            # -----------------------------------------------------------------
            - name: üì£ Notify deployment
              if: always()
              uses: nuniesmith/actions/.github/actions/discord-notify@main
              continue-on-error: true
              with:
                  webhook-url: ${{ secrets.DISCORD_WEBHOOK_ACTIONS }}
                  title: "${{ steps.deploy.outcome == 'success' && 'üöÄ FKS Deployed' || '‚ùå FKS Deploy Failed' }}"
                  description: "Deployed to ${{ needs.setup.outputs.deploy_env }} via ${{ needs.setup.outputs.build_strategy }}"
                  status: ${{ steps.deploy.outcome == 'success' && 'success' || 'failure' }}
                  include-repo-info: "true"
                  fields: |
                      [
                        {"name": "Environment", "value": "${{ needs.setup.outputs.deploy_env }}", "inline": true},
                        {"name": "Domain", "value": "${{ needs.setup.outputs.target_domain }}", "inline": true},
                        {"name": "Strategy", "value": "${{ needs.setup.outputs.build_strategy }}", "inline": true},
                        {"name": "SSL", "value": "${{ steps.ssl-request.outputs.cert-type || steps.ssl-fallback.outputs.cert_type || steps.ssl-self-signed.outputs.cert-type || steps.ssl-check.outputs.cert-type || 'skipped' }}", "inline": true},
                        {"name": "Health", "value": "${{ steps.health-checks.outputs.healthy == 'true' && '‚úÖ healthy' || '‚ö†Ô∏è degraded' }}", "inline": true}
                      ]

    # =========================================================================
    # PIPELINE SUMMARY
    # =========================================================================
    pipeline-summary:
        name: üìä Pipeline Summary
        runs-on: ubuntu-latest
        timeout-minutes: 5
        needs:
            [
                setup,
                test-lint,
                test-core,
                test-neuro-core,
                test-neuro-vivit,
                test-services,
                test-trading,
                test-audit,
                test-integration,
                test-kmp,
                docker-build,
                deploy,
            ]
        if: always()
        steps:
            - name: üì• Download all JUnit artifacts
              uses: actions/download-artifact@v4
              if: always()
              with:
                  pattern: junit-*
                  path: test-reports/

            - name: üìä Generate unified test summary
              if: always()
              run: |
                  # ‚îÄ‚îÄ Helper: map job result to emoji ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  status_icon() {
                    case "$1" in
                      success)  echo "‚úÖ" ;;
                      failure)  echo "‚ùå" ;;
                      skipped)  echo "‚è≠Ô∏è" ;;
                      cancelled) echo "üö´" ;;
                      *)        echo "‚ùì" ;;
                    esac
                  }

                  # ‚îÄ‚îÄ Collect job results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  LINT_RESULT="${{ needs.test-lint.result }}"
                  CORE_RESULT="${{ needs.test-core.result }}"
                  NEURO_CORE_RESULT="${{ needs.test-neuro-core.result }}"
                  NEURO_VIVIT_RESULT="${{ needs.test-neuro-vivit.result }}"
                  SVC_RESULT="${{ needs.test-services.result }}"
                  TRADE_RESULT="${{ needs.test-trading.result }}"
                  AUDIT_RESULT="${{ needs.test-audit.result }}"
                  INTEG_RESULT="${{ needs.test-integration.result }}"
                  KMP_RESULT="${{ needs.test-kmp.result }}"
                  DOCKER_RESULT="${{ needs.docker-build.result }}"
                  DEPLOY_RESULT="${{ needs.deploy.result }}"

                  # ‚îÄ‚îÄ Count failures for hero banner ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  FAILED_JOBS=""
                  FAIL_COUNT=0
                  for pair in \
                    "test-lint:üßπ Lint:$LINT_RESULT" \
                    "test-core:üß± Core:$CORE_RESULT" \
                    "test-neuro-core:üß† Neuro:$NEURO_CORE_RESULT" \
                    "test-neuro-vivit:üß† ViViT:$NEURO_VIVIT_RESULT" \
                    "test-services:‚öôÔ∏è Services:$SVC_RESULT" \
                    "test-trading:üìà Trading:$TRADE_RESULT" \
                    "test-audit:üîç Audit:$AUDIT_RESULT" \
                    "test-integration:üîó Integration:$INTEG_RESULT" \
                    "test-kmp:üì± KMP:$KMP_RESULT" \
                    "docker-build:üê≥ Docker:$DOCKER_RESULT" \
                    "deploy:üöÄ Deploy:$DEPLOY_RESULT"; do
                    JOB_NAME="${pair%%:*}"
                    REST="${pair#*:}"
                    LABEL="${REST%%:*}"
                    RESULT="${REST##*:}"
                    if [ "$RESULT" = "failure" ]; then
                      FAIL_COUNT=$((FAIL_COUNT + 1))
                      FAILED_JOBS="${FAILED_JOBS}\n- **${LABEL}**"
                    fi
                  done

                  # ‚îÄ‚îÄ Parse JUnit XML files for test counts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  python3 << 'PYEOF' > /tmp/test-counts.txt
                  import xml.etree.ElementTree as ET
                  import os, glob, sys, json

                  LABELS = {
                      "junit-core":        "üß± Core & Libraries",
                      "junit-neuro-core":  "üß† Neuromorphic (Core)",
                      "junit-neuro-vivit": "üß† Neuromorphic (ViViT)",
                      "junit-services":    "‚öôÔ∏è Services",
                      "junit-trading":     "üìà Trading & ML",
                      "junit-audit":       "üîç Audit",
                      "junit-integration": "üîó Integration (DB)",
                  }

                  ORDER = list(LABELS.keys())
                  base = "test-reports"
                  totals = {"tests": 0, "passed": 0, "failed": 0, "skipped": 0, "time": 0.0}
                  rows = []
                  failed_tests = []

                  for key in ORDER:
                      artifact_dir = os.path.join(base, key)
                      xmls = glob.glob(os.path.join(artifact_dir, "**", "*.xml"), recursive=True)
                      if not xmls:
                          rows.append((LABELS[key], "-", "-", "-", "-", "-"))
                          continue
                      tests = failures = errors = skipped = 0
                      time_s = 0.0
                      for xf in xmls:
                          try:
                              tree = ET.parse(xf)
                              root = tree.getroot()
                              suites = root.findall(".//testsuite")
                              if not suites and root.tag == "testsuite":
                                  suites = [root]
                              for ts in suites:
                                  tests    += int(ts.get("tests", 0))
                                  failures += int(ts.get("failures", 0))
                                  errors   += int(ts.get("errors", 0))
                                  skipped  += int(ts.get("skipped", 0))
                                  time_s   += float(ts.get("time", 0))
                                  # Collect names of failed test cases
                                  for tc in ts.findall("testcase"):
                                      if tc.find("failure") is not None or tc.find("error") is not None:
                                          name = tc.get("name", "unknown")
                                          cls  = tc.get("classname", "")
                                          fqn  = f"{cls}::{name}" if cls else name
                                          failed_tests.append({"group": LABELS[key], "test": fqn})
                          except Exception as e:
                              print(f"WARN: Failed to parse {xf}: {e}", file=sys.stderr)

                      passed = tests - failures - errors - skipped
                      totals["tests"]   += tests
                      totals["passed"]  += passed
                      totals["failed"]  += failures + errors
                      totals["skipped"] += skipped
                      totals["time"]    += time_s

                      mins = int(time_s) // 60
                      secs = time_s - mins * 60
                      time_fmt = f"{mins}m {secs:.1f}s" if mins else f"{secs:.1f}s"

                      pass_str = f"‚úÖ {passed}" if passed else "0"
                      fail_str = f"‚ùå {failures + errors}" if (failures + errors) else "0"
                      skip_str = f"‚è≠Ô∏è {skipped}" if skipped else "0"

                      rows.append((LABELS[key], str(tests), pass_str, fail_str, skip_str, time_fmt))

                  # Totals
                  t = totals
                  t_mins = int(t["time"]) // 60
                  t_secs = t["time"] - t_mins * 60
                  t_time = f"{t_mins}m {t_secs:.1f}s" if t_mins else f"{t_secs:.1f}s"
                  t_pass = f"‚úÖ {t['passed']}" if t["passed"] else "0"
                  t_fail = f"‚ùå {t['failed']}" if t["failed"] else "0"
                  t_skip = f"‚è≠Ô∏è {t['skipped']}" if t["skipped"] else "0"

                  for r in rows:
                      print("|".join(r))
                  print("---TOTALS---")
                  print("|".join([
                      "**TOTAL**",
                      f"**{t['tests']}**",
                      f"**{t_pass}**",
                      f"**{t_fail}**",
                      f"**{t_skip}**",
                      f"**{t_time}**",
                  ]))
                  print("---META---")
                  print(json.dumps({
                      "total": t["tests"],
                      "passed": t["passed"],
                      "failed": t["failed"],
                      "skipped": t["skipped"],
                      "time": t_time,
                      "failed_tests": failed_tests[:20],
                  }))
                  PYEOF

                  # ‚îÄ‚îÄ Read parsed counts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  TEST_ROWS=""
                  TOTAL_ROW=""
                  META_JSON=""
                  section="rows"
                  while IFS= read -r line; do
                    if [ "$line" = "---TOTALS---" ]; then
                      section="totals"
                      continue
                    fi
                    if [ "$line" = "---META---" ]; then
                      section="meta"
                      continue
                    fi
                    case "$section" in
                      rows)
                        TEST_ROWS="${TEST_ROWS}| $(echo "$line" | sed 's/|/ | /g') |
                  "
                        ;;
                      totals)
                        TOTAL_ROW="| $(echo "$line" | sed 's/|/ | /g') |"
                        ;;
                      meta)
                        META_JSON="$line"
                        ;;
                    esac
                  done < /tmp/test-counts.txt

                  # ‚îÄ‚îÄ Extract totals from JSON for hero banner ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  TOTAL_TESTS=$(echo "$META_JSON" | python3 -c "import sys,json; d=json.load(sys.stdin); print(d['total'])" 2>/dev/null || echo "0")
                  TOTAL_PASSED=$(echo "$META_JSON" | python3 -c "import sys,json; d=json.load(sys.stdin); print(d['passed'])" 2>/dev/null || echo "0")
                  TOTAL_FAILED=$(echo "$META_JSON" | python3 -c "import sys,json; d=json.load(sys.stdin); print(d['failed'])" 2>/dev/null || echo "0")
                  TOTAL_SKIPPED=$(echo "$META_JSON" | python3 -c "import sys,json; d=json.load(sys.stdin); print(d['skipped'])" 2>/dev/null || echo "0")
                  TOTAL_TIME=$(echo "$META_JSON" | python3 -c "import sys,json; d=json.load(sys.stdin); print(d['time'])" 2>/dev/null || echo "?")

                  # ‚îÄ‚îÄ Build failed test list (if any) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  FAILED_TEST_LIST=""
                  if [ "$TOTAL_FAILED" -gt 0 ] 2>/dev/null; then
                    FAILED_TEST_LIST=$(echo "$META_JSON" | python3 -c "
                  import sys, json
                  d = json.load(sys.stdin)
                  ft = d.get('failed_tests', [])
                  if ft:
                      print()
                      print('<details><summary>üîç Failed tests (' + str(len(ft)) + ')</summary>')
                      print()
                      for t in ft:
                          print('- \`' + t['test'] + '\` ‚Äî ' + t['group'])
                      print()
                      print('</details>')
                  " 2>/dev/null || echo "")
                  fi

                  # ‚îÄ‚îÄ Determine overall verdict ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  if [ "$FAIL_COUNT" -gt 0 ]; then
                    VERDICT="‚ùå FAILED"
                    VERDICT_COLOR="red"
                    VERDICT_NOTE="${FAIL_COUNT} job(s) failed"
                  elif [ "$TOTAL_FAILED" -gt 0 ] 2>/dev/null; then
                    VERDICT="‚ö†Ô∏è TESTS FAILED"
                    VERDICT_COLOR="orange"
                    VERDICT_NOTE="${TOTAL_FAILED} test(s) failed"
                  else
                    VERDICT="‚úÖ ALL PASSED"
                    VERDICT_COLOR="green"
                    VERDICT_NOTE="All systems go"
                  fi

                  # ‚îÄ‚îÄ Write summary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  cat >> $GITHUB_STEP_SUMMARY << EOF

                  # ${VERDICT}  ‚Äî  FKS Pipeline \`#${{ github.run_number }}\`

                  > **${TOTAL_TESTS}** tests | **${TOTAL_PASSED}** passed | **${TOTAL_FAILED}** failed | **${TOTAL_SKIPPED}** skipped | ‚è±Ô∏è ${TOTAL_TIME}
                  >
                  > \`${{ github.ref_name }}\` ‚Üí \`${{ needs.setup.outputs.deploy_env }}\` | Actor: \`${{ github.actor }}\`

                  ---

                  ## At a Glance

                  | | Job | Result | | Job | Result |
                  |--|-----|--------|-|-----|--------|
                  | üßπ | Lint | $(status_icon "$LINT_RESULT") $LINT_RESULT | üìà | Trading & ML | $(status_icon "$TRADE_RESULT") $TRADE_RESULT |
                  | üß± | Core | $(status_icon "$CORE_RESULT") $CORE_RESULT | üîç | Audit | $(status_icon "$AUDIT_RESULT") $AUDIT_RESULT |
                  | üß† | Neuro (Core) | $(status_icon "$NEURO_CORE_RESULT") $NEURO_CORE_RESULT | üîó | Integration | $(status_icon "$INTEG_RESULT") $INTEG_RESULT |
                  | üß† | Neuro (ViViT) | $(status_icon "$NEURO_VIVIT_RESULT") $NEURO_VIVIT_RESULT | üì± | KMP | $(status_icon "$KMP_RESULT") $KMP_RESULT |
                  | ‚öôÔ∏è | Services | $(status_icon "$SVC_RESULT") $SVC_RESULT | üê≥ | Docker | $(status_icon "$DOCKER_RESULT") $DOCKER_RESULT |
                  | | | | üöÄ | Deploy | $(status_icon "$DEPLOY_RESULT") $DEPLOY_RESULT |
                  ${FAILED_TEST_LIST}

                  ---

                  <details><summary><strong>üß™ Test Breakdown by Group</strong></summary>

                  | Group | Total | Passed | Failed | Skipped | Duration |
                  |-------|------:|-------:|-------:|--------:|---------:|
                  ${TEST_ROWS}${TOTAL_ROW}

                  </details>

                  <details><summary><strong>üê≥ Docker Images</strong></summary>

                  | Image | Tag |
                  |-------|-----|
                  | janus | \`janus-${{ github.sha }}\` |
                  | audit | \`audit-${{ github.sha }}\` |
                  | web | \`web-${{ github.sha }}\` |
                  | authelia | \`authelia-${{ github.sha }}\` |
                  | nginx | \`nginx-${{ github.sha }}\` |

                  </details>

                  <details><summary><strong>‚öôÔ∏è Environment & Deploy Details</strong></summary>

                  | Property | Value |
                  |----------|-------|
                  | Target | \`${{ needs.setup.outputs.deploy_env }}\` |
                  | Domain | \`${{ needs.setup.outputs.target_domain }}\` |
                  | Build Strategy | \`${{ needs.setup.outputs.build_strategy }}\` |
                  | Tests Enabled | \`${{ needs.setup.outputs.should_test }}\` |
                  | SSL Certificate | ${{ needs.deploy.outputs.ssl_cert_type || 'N/A' }} |
                  | Health Check | ${{ needs.deploy.outputs.http_health == 'true' && '‚úÖ Healthy' || '‚ö†Ô∏è Check logs' }} |

                  </details>
                  EOF

            - name: ‚ùå Fail on critical errors
              if: |
                  needs.test-lint.result == 'failure' ||
                  needs.test-core.result == 'failure' ||
                  needs.test-neuro-core.result == 'failure' ||
                  needs.test-neuro-vivit.result == 'failure' ||
                  needs.test-services.result == 'failure' ||
                  needs.test-trading.result == 'failure' ||
                  needs.test-audit.result == 'failure' ||
                  needs.test-integration.result == 'failure' ||
                  needs.docker-build.result == 'failure' ||
                  needs.deploy.result == 'failure'
              run: |
                  echo "‚ùå Pipeline failed ‚Äî check individual job logs above"
                  echo ""
                  echo "Failed jobs:"
                  [ "${{ needs.test-lint.result }}" = "failure" ] && echo "  - üßπ Lint & Format"
                  [ "${{ needs.test-core.result }}" = "failure" ] && echo "  - üß± Core & Libraries"
                  [ "${{ needs.test-neuro-core.result }}" = "failure" ] && echo "  - üß† Neuromorphic (Core)"
                  [ "${{ needs.test-neuro-vivit.result }}" = "failure" ] && echo "  - üß† Neuromorphic (ViViT)"
                  [ "${{ needs.test-services.result }}" = "failure" ] && echo "  - ‚öôÔ∏è Services"
                  [ "${{ needs.test-trading.result }}" = "failure" ] && echo "  - üìà Trading & ML (Janus)"
                  [ "${{ needs.test-audit.result }}" = "failure" ] && echo "  - üîç Audit (fks-audit)"
                  [ "${{ needs.test-integration.result }}" = "failure" ] && echo "  - üîó Integration (DB)"
                  [ "${{ needs.docker-build.result }}" = "failure" ] && echo "  - üê≥ Docker Build"
                  [ "${{ needs.deploy.result }}" = "failure" ] && echo "  - üöÄ Deploy"
                  exit 1
