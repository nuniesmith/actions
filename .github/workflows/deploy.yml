name: 🚀 Unified Service Management

# Docker Network Configuration:
# This workflow sets up dedicated Docker networks with static IP ranges for each service:
# - FKS:   172.20.0.0/16 (containers: 172.20.1.0/24)
# - ATS:   172.21.0.0/16 (containers: 172.21.1.0/24)  
# - Nginx: 172.22.0.0/16 (containers: 172.22.1.0/24)
# 
# Benefits:
# - Predictable IP addresses for service communication
# - Proper iptables rules for inter-service traffic
# - Tailscale subnet advertisement for VPN access to all containers
# - Network isolation between services while allowing controlled communication

on:
  workflow_call:
    inputs:
      service_name:
        description: 'Name of the service to manage (e.g., fks, nginx, ats)'
        required: true
        type: string
      
      action_type:
        description: 'Action to perform'
        required: false
        type: string
        default: 'deploy'
        # Options: deploy, destroy, health-check, restart
      
      deployment_mode:
        description: 'Deployment mode'
        required: false
        type: string
        default: 'full-deploy'
        # Options: full-deploy, update-only, restart-only, code-only
      
      # 🎯 New Options You Requested
      skip_tests:
        description: 'Skip running code tests'
        required: false
        type: boolean
        default: false
      
      skip_docker_build:
        description: 'Skip building Docker images'
        required: false
        type: boolean
        default: false
      
      build_docker_on_changes:
        description: 'Only build Docker if code/Dockerfile changed'
        required: false
        type: boolean
        default: true
      
      overwrite_server:
        description: 'Destroy and recreate Linode server'
        required: false
        type: boolean
        default: false
      
      # Server Configuration
      server_type:
        description: 'Linode server type'
        required: false
        type: string
        default: 'g6-standard-2'
      
      target_region:
        description: 'Linode region'
        required: false
        type: string
        default: 'ca-central'
      
      domain_suffix:
        description: 'Domain suffix (e.g., 7gram.xyz)'
        required: false
        type: string
        default: '7gram.xyz'
      
      custom_domains:
        description: 'Comma-separated list of custom domains for DNS updates (overrides defaults)'
        required: false
        type: string
        default: ''
      
      # Feature Toggles
      enable_backups:
        description: 'Enable Linode backups'
        required: false
        type: boolean
        default: false
      
      # Destroy Options (for destroy action)
      destroy_scope:
        description: 'What to destroy (for destroy action)'
        required: false
        type: string
        default: 'service-only'
      
      confirm_destruction:
        description: 'Type "DESTROY" to confirm destruction'
        required: false
        type: string

    secrets:
      # Core Infrastructure
      LINODE_CLI_TOKEN:
        required: true
      SERVICE_ROOT_PASSWORD:
        required: true
      
      # User Management
      JORDAN_PASSWORD:
        required: true
      ACTIONS_USER_PASSWORD:
        required: true
      
      # VPN & Networking
      TAILSCALE_AUTH_KEY:
        required: true
      TAILSCALE_TAILNET:
        description: 'Tailscale tailnet name (optional)'
        required: false
      
      # DNS Management (Optional)
      CLOUDFLARE_EMAIL:
        required: false
      CLOUDFLARE_API_TOKEN:
        required: false
      CLOUDFLARE_ZONE_ID:
        required: false
      
      # Container Registry (Optional)
      DOCKER_USERNAME:
        required: false
      DOCKER_TOKEN:
        required: false
      
      # Notifications (Optional)
      DISCORD_WEBHOOK:
        required: false

    outputs:
      # Infrastructure outputs
      server_ip:
        description: 'Public IP address of the deployed server'
        value: ${{ jobs.setup-infrastructure.outputs.server_ip }}
      server_id:
        description: 'Linode server ID'
        value: ${{ jobs.setup-infrastructure.outputs.server_id }}
      tailscale_ip:
        description: 'Tailscale IP address of the server'
        value: ${{ jobs.setup-infrastructure.outputs.tailscale_ip }}

  workflow_dispatch:
    inputs:
      service_name:
        description: 'Name of the service to manage'
        required: true
        type: choice
        options:
          - 'fks'
          - 'nginx'
          - 'ats'
          - 'custom'
      
      action_type:
        description: 'Action to perform'
        required: true
        type: choice
        options:
          - 'deploy'
          - 'destroy'
          - 'health-check'
          - 'restart'
        default: 'deploy'
      
      deployment_mode:
        description: 'Deployment mode (for deploy action)'
        required: false
        type: choice
        options:
          - 'full-deploy'
          - 'update-only'
          - 'restart-only'
          - 'code-only'
        default: 'full-deploy'
      
      # 🎯 Your Requested Options
      skip_tests:
        description: 'Skip running code tests'
        required: false
        type: boolean
        default: false
      
      skip_docker_build:
        description: 'Skip building Docker images'
        required: false
        type: boolean
        default: false
      
      build_docker_on_changes:
        description: 'Only build Docker if code/Dockerfile changed'
        required: false
        type: boolean
        default: true
      
      overwrite_server:
        description: 'Destroy and recreate Linode server'
        required: false
        type: boolean
        default: false
      
      # Destroy Options (for destroy action)
      destroy_scope:
        description: 'What to destroy (for destroy action)'
        required: false
        type: choice
        options:
          - 'service-only'
          - 'full-server'
          - 'reset-service'
        default: 'service-only'
      
      confirm_destruction:
        description: 'Type "DESTROY" to confirm destruction'
        required: false
        type: string
      
      # Server Configuration
      server_type:
        description: 'Linode server type'
        required: false
        type: choice
        options:
          - 'g6-nanode-1'          # 1GB RAM
          - 'g6-standard-1'        # 2GB RAM
          - 'g6-standard-2'        # 4GB RAM
          - 'g6-standard-4'        # 8GB RAM
          - 'g6-standard-8'        # 16GB RAM
        default: 'g6-standard-2'

env:
  SERVICE_NAME: ${{ inputs.service_name }}
  ACTION_TYPE: ${{ inputs.action_type }}
  DEPLOYMENT_MODE: ${{ inputs.deployment_mode }}
  SERVER_TYPE: ${{ inputs.server_type }}
  TARGET_REGION: ${{ inputs.target_region || 'ca-central' }}
  DOMAIN_SUFFIX: ${{ inputs.domain_suffix || '7gram.xyz' }}
  FULL_DOMAIN: ${{ inputs.service_name }}.${{ inputs.domain_suffix || '7gram.xyz' }}
  
  # Your requested options
  SKIP_TESTS: ${{ inputs.skip_tests }}
  SKIP_DOCKER_BUILD: ${{ inputs.skip_docker_build }}
  BUILD_DOCKER_ON_CHANGES: ${{ inputs.build_docker_on_changes }}
  OVERWRITE_SERVER: ${{ inputs.overwrite_server }}

jobs:
  # ============================================================================
  # Pre-flight Checks & Validation
  # ============================================================================
  preflight-checks:
    name: 🛫 Pre-flight Checks
    runs-on: ubuntu-latest
    outputs:
      action_validated: ${{ steps.validate-action.outputs.validated }}
      should_destroy: ${{ steps.validate-action.outputs.should_destroy }}
      should_deploy: ${{ steps.validate-action.outputs.should_deploy }}
      should_health_check: ${{ steps.validate-action.outputs.should_health_check }}
      should_overwrite_server: ${{ steps.validate-action.outputs.should_overwrite_server }}
      destroy_confirmed: ${{ steps.validate-destroy.outputs.confirmed }}
      code_changed: ${{ steps.check-changes.outputs.code_changed }}
      docker_build_needed: ${{ steps.check-changes.outputs.docker_build_needed }}
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch full history for change detection

      - name: 🎯 Validate Action Type
        id: validate-action
        run: |
          echo "🎯 Validating action: ${{ env.ACTION_TYPE }}"
          
          case "${{ env.ACTION_TYPE }}" in
            "deploy")
              echo "should_deploy=true" >> $GITHUB_OUTPUT
              echo "should_destroy=false" >> $GITHUB_OUTPUT
              echo "should_health_check=false" >> $GITHUB_OUTPUT
              ;;
            "destroy")
              echo "should_deploy=false" >> $GITHUB_OUTPUT
              echo "should_destroy=true" >> $GITHUB_OUTPUT
              echo "should_health_check=false" >> $GITHUB_OUTPUT
              ;;
            "health-check")
              echo "should_deploy=false" >> $GITHUB_OUTPUT
              echo "should_destroy=false" >> $GITHUB_OUTPUT
              echo "should_health_check=true" >> $GITHUB_OUTPUT
              ;;
            "restart")
              echo "should_deploy=true" >> $GITHUB_OUTPUT
              echo "should_destroy=false" >> $GITHUB_OUTPUT
              echo "should_health_check=false" >> $GITHUB_OUTPUT
              ;;
            *)
              echo "❌ Invalid action type: ${{ env.ACTION_TYPE }}"
              exit 1
              ;;
          esac
          
          # Check if server should be overwritten
          if [[ "${{ env.OVERWRITE_SERVER }}" == "true" && "${{ env.ACTION_TYPE }}" == "deploy" ]]; then
            echo "should_overwrite_server=true" >> $GITHUB_OUTPUT
            echo "⚠️ Server will be overwritten (destroyed and recreated)"
          else
            echo "should_overwrite_server=false" >> $GITHUB_OUTPUT
          fi
          
          echo "validated=true" >> $GITHUB_OUTPUT

      - name: ⚠️ Validate Destruction Request
        id: validate-destroy
        if: steps.validate-action.outputs.should_destroy == 'true' || steps.validate-action.outputs.should_overwrite_server == 'true'
        run: |
          # For server overwrite during deployment, skip confirmation requirement
          if [[ "${{ steps.validate-action.outputs.should_overwrite_server }}" == "true" && "${{ env.ACTION_TYPE }}" == "deploy" ]]; then
            echo "✅ Server overwrite confirmed (deploy mode)"
            echo "confirmed=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # For explicit destroy actions, require confirmation
          if [[ "${{ inputs.confirm_destruction }}" != "DESTROY" ]]; then
            echo "❌ Destruction not confirmed. You must type 'DESTROY' exactly."
            echo "confirmed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "✅ Destruction confirmed for ${{ env.SERVICE_NAME }}"
          echo "confirmed=true" >> $GITHUB_OUTPUT

      - name: 🔍 Check for Code Changes
        id: check-changes
        if: steps.validate-action.outputs.should_deploy == 'true'
        run: |
          echo "🔍 Checking for code and Docker changes..."
          
          # TEMPORARY: Force Docker builds for all services since DockerHub images were cleared
          echo "🔄 FORCING Docker builds - DockerHub images were cleared"
          echo "code_changed=true" >> $GITHUB_OUTPUT
          echo "docker_build_needed=true" >> $GITHUB_OUTPUT
          
          # TODO: Re-enable change detection later by uncommenting the logic below
          # and removing the forced build logic above
          
          # Check if this is the first commit or if we should build anyway
          #if [[ $(git rev-list --count HEAD) -le 1 ]] || [[ "${{ env.BUILD_DOCKER_ON_CHANGES }}" == "false" ]]; then
          #  echo "First commit or change detection disabled - assuming changes exist"
          #  echo "code_changed=true" >> $GITHUB_OUTPUT
          #  echo "docker_build_needed=true" >> $GITHUB_OUTPUT
          #else
          #  # Check for changes in the last commit
          #  CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD)
          #  echo "Changed files: $CHANGED_FILES"
          #  
          #  # Check if code files changed (exclude docs, configs, etc.)
          #  CODE_CHANGED="false"
          #  if echo "$CHANGED_FILES" | grep -E '\.(js|ts|py|go|java|cpp|c|rs|php)$' > /dev/null; then
          #    CODE_CHANGED="true"
          #    echo "✅ Code files changed"
          #  fi
          #  
          #  # Check if Docker-related files changed
          #  DOCKER_BUILD_NEEDED="false"
          #  if echo "$CHANGED_FILES" | grep -E '(Dockerfile|docker-compose|requirements|package\.json|go\.mod|Cargo\.toml)' > /dev/null; then
          #    DOCKER_BUILD_NEEDED="true"
          #    echo "✅ Docker-related files changed"
          #  fi
          #  
          #  # If build_docker_on_changes is true, only build if changes detected
          #  if [[ "${{ env.BUILD_DOCKER_ON_CHANGES }}" == "true" ]]; then
          #    if [[ "$CODE_CHANGED" == "true" || "$DOCKER_BUILD_NEEDED" == "true" ]]; then
          #      DOCKER_BUILD_NEEDED="true"
          #    else
          #      DOCKER_BUILD_NEEDED="false"
          #      echo "ℹ️ No relevant changes detected - skipping Docker build"
          #    fi
          #  fi
          #  
          #  echo "code_changed=$CODE_CHANGED" >> $GITHUB_OUTPUT
          #  echo "docker_build_needed=$DOCKER_BUILD_NEEDED" >> $GITHUB_OUTPUT
          #fi

      - name: 🔐 Validate Secrets
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
          SERVICE_ROOT_PASSWORD: ${{ secrets.SERVICE_ROOT_PASSWORD }}
          JORDAN_PASSWORD: ${{ secrets.JORDAN_PASSWORD }}
          ACTIONS_USER_PASSWORD: ${{ secrets.ACTIONS_USER_PASSWORD }}
          TAILSCALE_AUTH_KEY: ${{ secrets.TAILSCALE_AUTH_KEY }}
          # SSL-related secrets (optional for nginx)
          CLOUDFLARE_EMAIL: ${{ secrets.CLOUDFLARE_EMAIL }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "🔐 Validating required secrets..."
          
          MISSING_SECRETS=()
          [[ -z "$LINODE_CLI_TOKEN" ]] && MISSING_SECRETS+=("LINODE_CLI_TOKEN")
          [[ -z "$SERVICE_ROOT_PASSWORD" ]] && MISSING_SECRETS+=("SERVICE_ROOT_PASSWORD")
          [[ -z "$JORDAN_PASSWORD" ]] && MISSING_SECRETS+=("JORDAN_PASSWORD")
          [[ -z "$ACTIONS_USER_PASSWORD" ]] && MISSING_SECRETS+=("ACTIONS_USER_PASSWORD")
          [[ -z "$TAILSCALE_AUTH_KEY" ]] && MISSING_SECRETS+=("TAILSCALE_AUTH_KEY")
          
          if [[ ${#MISSING_SECRETS[@]} -gt 0 ]]; then
            echo "❌ Missing required secrets:"
            printf '  - %s\n' "${MISSING_SECRETS[@]}"
            exit 1
          fi
          
          echo "✅ All required secrets validated"
          
          # Check SSL-related secrets for nginx deployments
          if [[ "${{ env.SERVICE_NAME }}" == "nginx" ]]; then
            SSL_SECRETS=()
            [[ -z "$CLOUDFLARE_EMAIL" ]] && SSL_SECRETS+=("CLOUDFLARE_EMAIL")
            [[ -z "$CLOUDFLARE_API_TOKEN" ]] && SSL_SECRETS+=("CLOUDFLARE_API_TOKEN")
            
            if [[ ${#SSL_SECRETS[@]} -gt 0 ]]; then
              echo "⚠️ SSL secrets missing (will use HTTP challenge or self-signed):"
              printf '  - %s\n' "${SSL_SECRETS[@]}"
              echo "💡 For wildcard certificates and better reliability, add:"
              echo "   - CLOUDFLARE_EMAIL (your Cloudflare account email)"
              echo "   - CLOUDFLARE_API_TOKEN (Cloudflare API token with DNS edit permissions)"
            else
              echo "✅ SSL secrets available for DNS-01 challenge"
            fi
          fi

  # ============================================================================
  # Resource Cleanup (Optional, runs before deployment)
  # ============================================================================
  cleanup-old-resources:
    name: 🧹 Cleanup Old Resources
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: preflight-checks
    if: |
      needs.preflight-checks.outputs.should_deploy == 'true' && 
      (github.event_name == 'push' || inputs.overwrite_server == true)
    
    steps:
      - name: 🧹 Cleanup Tailscale and Linode Resources
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
          TAILSCALE_AUTH_KEY: ${{ secrets.TAILSCALE_AUTH_KEY }}
          TAILSCALE_TAILNET: ${{ secrets.TAILSCALE_TAILNET }}
        run: |
          echo "🧹 Cleaning up old ${{ env.SERVICE_NAME }} resources..."
          
          # Function to clean up Tailscale devices by hostname pattern
          cleanup_tailscale_devices() {
            local hostname_pattern="$1"
            local cleanup_reason="${2:-old server cleanup}"
            
            echo "🔗 Tailscale cleanup for pattern: $hostname_pattern ($cleanup_reason)"
            
            DEVICES_RESPONSE=$(curl -s "https://api.tailscale.com/api/v2/tailnet/${{ secrets.TAILSCALE_TAILNET }}/devices" \
              -u "${{ secrets.TAILSCALE_API_KEY }}:" \
              -H "Accept: application/json" 2>/dev/null || echo '{"devices":[]}')
            
            MATCHING_DEVICES=$(echo "$DEVICES_RESPONSE" | jq -r --arg pattern "$hostname_pattern" '
              .devices[]? | 
              select(
                (.name | test("^" + $pattern + "(-[0-9]+)?$")) or
                (.name == $pattern) or
                (.hostname | test("^" + $pattern + "(-[0-9]+)?$")) or
                (.hostname == $pattern)
              ) | 
              .nodeId' 2>/dev/null || echo "")
            
            local removed_count=0
            for device_id in $MATCHING_DEVICES; do
              if [[ -n "$device_id" && "$device_id" != "null" ]]; then
                echo "🗑️ Removing Tailscale device: $device_id"
                curl -s -X DELETE "https://api.tailscale.com/api/v2/device/$device_id" \
                  -u "${{ secrets.TAILSCALE_API_KEY }}:" >/dev/null 2>&1
                
                if [[ $? -eq 0 ]]; then
                  echo "✅ Removed Tailscale device $device_id"
                  removed_count=$((removed_count + 1))
                else
                  echo "⚠️ Failed to remove Tailscale device $device_id"
                fi
                sleep 2
              fi
            done
            
            echo "✅ Removed $removed_count Tailscale devices for pattern: $hostname_pattern"
            return $removed_count
          }
          
          # For nginx deployments, do minimal cleanup to speed up deployment
          if [[ "${{ env.SERVICE_NAME }}" == "nginx" ]]; then
            echo "⚡ Fast cleanup mode for nginx deployment"
            
            # Install dependencies
            sudo apt-get update && sudo apt-get install -y curl jq
            
            # Enhanced Tailscale cleanup for nginx (comprehensive patterns)
            if [[ -n "$TAILSCALE_AUTH_KEY" && -n "$TAILSCALE_TAILNET" ]]; then
              echo "🔗 Enhanced Tailscale cleanup for nginx..."
              DEVICES_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
                "https://api.tailscale.com/api/v2/tailnet/$TAILSCALE_TAILNET/devices" 2>/dev/null || echo "CURL_FAILED")
              
              # Extract HTTP status code
              HTTP_CODE=$(echo "$DEVICES_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
              DEVICES_JSON=$(echo "$DEVICES_RESPONSE" | sed '/HTTP_CODE:/d')
              
              if [[ "$HTTP_CODE" == "200" ]] && echo "$DEVICES_JSON" | jq -e '.devices' >/dev/null 2>&1; then
                echo "🔍 Searching for nginx devices with comprehensive patterns..."
                
                # Multiple patterns to catch nginx devices with various naming conventions
                NGINX_CLEANUP_PATTERNS=(
                  "^nginx(-[0-9]+)?$"
                  "^nginx$" 
                  "^nginx-"
                  "nginx"
                )
                
                TOTAL_NGINX_REMOVED=0
                ALL_NGINX_DEVICES=""
                
                # Collect all matching nginx device IDs
                for pattern in "${NGINX_CLEANUP_PATTERNS[@]}"; do
                  echo "🔍 Searching for nginx pattern: $pattern"
                  
                  DEVICES=$(echo "$DEVICES_JSON" | jq -r --arg pattern "$pattern" '
                    .devices[]? | 
                    select(
                      (.hostname // .name | test($pattern; "i")) or 
                      (.name // .hostname | test($pattern; "i"))
                    ) | 
                    .id // empty' | grep -v '^$')
                  
                  if [[ -n "$DEVICES" ]]; then
                    ALL_NGINX_DEVICES="$ALL_NGINX_DEVICES $DEVICES"
                  fi
                done
                
                # Remove duplicates
                UNIQUE_NGINX_DEVICES=$(echo "$ALL_NGINX_DEVICES" | tr ' ' '\n' | sort -u | grep -v '^$' || true)
                
                if [[ -n "$UNIQUE_NGINX_DEVICES" ]]; then
                  echo "Found nginx devices to remove..."
                  for device_id in $UNIQUE_NGINX_DEVICES; do
                    if [[ -n "$device_id" ]]; then
                      DEVICE_INFO=$(echo "$DEVICES_JSON" | jq -r --arg id "$device_id" '.devices[]? | select(.id == $id) | "\(.hostname // .name // "unknown") (\(.addresses[0] // "no-ip"))"')
                      echo "🗑️ Removing nginx device: $device_id - $DEVICE_INFO"
                      
                      # Try primary endpoint
                      REMOVE_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -X DELETE \
                        -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
                        "https://api.tailscale.com/api/v2/device/$device_id" 2>/dev/null || echo "CURL_FAILED")
                      
                      REMOVE_CODE=$(echo "$REMOVE_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                      
                      if [[ "$REMOVE_CODE" == "200" || "$REMOVE_CODE" == "204" ]]; then
                        echo "   ✅ Successfully removed"
                        ((TOTAL_NGINX_REMOVED++))
                      else
                        echo "   ⚠️ Trying alternative endpoint..."
                        # Try alternative endpoint
                        ALT_REMOVE_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -X DELETE \
                          -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
                          "https://api.tailscale.com/api/v2/tailnet/$TAILSCALE_TAILNET/devices/$device_id" 2>/dev/null || echo "CURL_FAILED")
                        
                        ALT_REMOVE_CODE=$(echo "$ALT_REMOVE_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                        if [[ "$ALT_REMOVE_CODE" == "200" || "$ALT_REMOVE_CODE" == "204" ]]; then
                          echo "   ✅ Successfully removed via alternative endpoint"
                          ((TOTAL_NGINX_REMOVED++))
                        else
                          echo "   ❌ Failed to remove device $device_id"
                        fi
                      fi
                      sleep 1
                    fi
                  done
                  echo "✅ Enhanced nginx Tailscale cleanup completed - removed $TOTAL_NGINX_REMOVED devices"
                else
                  echo "ℹ️ No nginx devices found to remove"
                fi
              else
                echo "⚠️ Tailscale API error or no devices array (HTTP: $HTTP_CODE)"
              fi
            fi
            
            # Quick Linode cleanup
            if [[ -n "$LINODE_CLI_TOKEN" ]]; then
              echo "🖥️ Quick Linode cleanup for nginx..."
              pip install linode-cli
              echo "[DEFAULT]
          token = $LINODE_CLI_TOKEN" > ~/.linode-cli
              
              OLD_SERVERS=$(linode-cli linodes list --json | jq -r '.[] | select(.label == "nginx") | .id')
              for server_id in $OLD_SERVERS; do
                if [[ -n "$server_id" ]]; then
                  echo "🗑️ Removing nginx server: $server_id"
                  linode-cli linodes delete $server_id --format id || echo "Failed to remove $server_id"
                fi
              done
            fi
            
            echo "✅ Quick cleanup completed for nginx"
            exit 0
          fi
          
          # Full cleanup for other services
          echo "🔧 Full cleanup mode for ${{ env.SERVICE_NAME }}"
          
          # Install dependencies
          sudo apt-get update && sudo apt-get install -y curl jq
          
          # Cleanup Tailscale devices first
          if [[ -n "$TAILSCALE_AUTH_KEY" && -n "$TAILSCALE_TAILNET" ]]; then
            echo "🔗 Cleaning up old Tailscale devices..."
            
            # Remove old service devices using direct API
            echo "🔍 Comprehensive cleanup of old ${{ env.SERVICE_NAME }} devices..."
            DEVICES_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
              "https://api.tailscale.com/api/v2/tailnet/$TAILSCALE_TAILNET/devices" 2>/dev/null || echo "CURL_FAILED")
            
            # Extract HTTP status code
            HTTP_CODE=$(echo "$DEVICES_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
            DEVICES_JSON=$(echo "$DEVICES_RESPONSE" | sed '/HTTP_CODE:/d')
            
            if [[ "$HTTP_CODE" == "200" ]] && echo "$DEVICES_JSON" | jq -e '.devices' >/dev/null 2>&1; then
              # Multiple patterns to catch all service variants
              CLEANUP_PATTERNS=(
                "^${{ env.SERVICE_NAME }}(-[0-9]+)?$"
                "^${{ env.SERVICE_NAME }}$" 
                "^${{ env.SERVICE_NAME }}-"
                "${{ env.SERVICE_NAME }}"
              )
              
              TOTAL_REMOVED=0
              ALL_FOUND_DEVICES=""
              
              # Collect all matching device IDs
              for pattern in "${CLEANUP_PATTERNS[@]}"; do
                echo "🔍 Searching for pattern: $pattern"
                
                DEVICES=$(echo "$DEVICES_JSON" | jq -r --arg pattern "$pattern" '
                  .devices[]? | 
                  select(
                    (.hostname // .name | test($pattern; "i")) or 
                    (.name // .hostname | test($pattern; "i"))
                  ) | 
                  .id // empty' | grep -v '^$')
                
                if [[ -n "$DEVICES" ]]; then
                  ALL_FOUND_DEVICES="$ALL_FOUND_DEVICES $DEVICES"
                fi
              done
              
              # Remove duplicates
              UNIQUE_DEVICES=$(echo "$ALL_FOUND_DEVICES" | tr ' ' '\n' | sort -u | grep -v '^$' || true)
              
              if [[ -n "$UNIQUE_DEVICES" ]]; then
                echo "Found ${{ env.SERVICE_NAME }} devices to remove..."
                for device_id in $UNIQUE_DEVICES; do
                  if [[ -n "$device_id" ]]; then
                    DEVICE_INFO=$(echo "$DEVICES_JSON" | jq -r --arg id "$device_id" '.devices[]? | select(.id == $id) | "\(.hostname // .name // "unknown") (\(.addresses[0] // "no-ip"))"')
                    echo "🗑️ Removing Tailscale device: $device_id - $DEVICE_INFO"
                    
                    # Try primary endpoint
                    REMOVE_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -X DELETE \
                      -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
                      "https://api.tailscale.com/api/v2/device/$device_id" 2>/dev/null || echo "CURL_FAILED")
                    
                    REMOVE_CODE=$(echo "$REMOVE_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                    
                    if [[ "$REMOVE_CODE" == "200" || "$REMOVE_CODE" == "204" ]]; then
                      echo "   ✅ Successfully removed"
                      ((TOTAL_REMOVED++))
                    else
                      echo "   ⚠️ Trying alternative endpoint..."
                      # Try alternative endpoint
                      ALT_REMOVE_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -X DELETE \
                        -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
                        "https://api.tailscale.com/api/v2/tailnet/$TAILSCALE_TAILNET/devices/$device_id" 2>/dev/null || echo "CURL_FAILED")
                      
                      ALT_REMOVE_CODE=$(echo "$ALT_REMOVE_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                      if [[ "$ALT_REMOVE_CODE" == "200" || "$ALT_REMOVE_CODE" == "204" ]]; then
                        echo "   ✅ Successfully removed via alternative endpoint"
                        ((TOTAL_REMOVED++))
                      else
                        echo "   ❌ Failed to remove device $device_id"
                      fi
                    fi
                    sleep 1
                  fi
                done
                echo "✅ ${{ env.SERVICE_NAME }} Tailscale cleanup completed - removed $TOTAL_REMOVED devices"
              else
                echo "No ${{ env.SERVICE_NAME }} devices found to remove"
              fi
            else
              echo "⚠️ No devices array in Tailscale response or API error"
            fi
          else
            echo "⚠️ Tailscale API credentials not available"
          fi
          
          # Cleanup Linode servers
          if [[ -n "$LINODE_CLI_TOKEN" ]]; then
            echo "🖥️ Cleaning up old Linode servers..."
            
            # Install linode-cli
            pip install linode-cli
            
            # Configure linode-cli
            echo "[DEFAULT]
          token = $LINODE_CLI_TOKEN" > ~/.linode-cli
            
            # Remove old service servers with Tailscale cleanup
            echo "🔍 Looking for old ${{ env.SERVICE_NAME }} servers..."
            OLD_SERVERS=$(linode-cli linodes list --json | jq -r --arg service "${{ env.SERVICE_NAME }}" '.[] | select(.label | startswith($service)) | "\(.id):\(.label)"')
            
            for server_entry in $OLD_SERVERS; do
              if [[ -n "$server_entry" && "$server_entry" != ":" ]]; then
                server_id="${server_entry%%:*}"
                server_label="${server_entry#*:}"
                
                echo "🗑️ Preparing to remove old server: $server_id ($server_label)"
                
                # Clean up Tailscale devices for this server first
                if [[ -n "$server_label" ]]; then
                  cleanup_tailscale_devices "$server_label" "server removal"
                fi
                
                # Now remove the Linode server
                echo "🗑️ Removing Linode server: $server_id"
                linode-cli linodes delete "$server_id" --json || echo "⚠️ Failed to remove server $server_id"
                sleep 10
              fi
            done
          else
            echo "⚠️ Linode CLI token not available"
          fi
          
          # Final Tailscale cleanup to catch any remaining devices
          echo "🔗 Final Tailscale cleanup for service ${{ env.SERVICE_NAME }}..."
          cleanup_tailscale_devices "${{ env.SERVICE_NAME }}" "final cleanup"
          
          echo "✅ Cleanup completed for ${{ env.SERVICE_NAME }}"

  # ============================================================================
  # Code Testing (Optional)
  # ============================================================================
  run-tests:
    name: 🧪 Run Tests
    runs-on: ubuntu-latest
    needs: [preflight-checks, cleanup-old-resources]
    if: |
      always() &&
      needs.preflight-checks.outputs.should_deploy == 'true' && 
      inputs.skip_tests == false &&
      (needs.cleanup-old-resources.result == 'success' || needs.cleanup-old-resources.result == 'skipped')
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 🧪 Auto-detect and Run Tests
        run: |
          echo "🧪 Auto-detecting test framework..."
          
          # Node.js/JavaScript tests
          if [[ -f "package.json" ]]; then
            echo "📦 Node.js project detected"
            if command -v npm &> /dev/null; then
              echo "Installing dependencies..."
              npm install
              
              if npm run test --if-present; then
                echo "✅ Node.js tests passed"
              else
                echo "⚠️ Node.js tests failed or no test script found"
              fi
            fi
          fi
          
          # Python tests
          if [[ -f "requirements.txt" ]] || [[ -f "pyproject.toml" ]] || [[ -f "setup.py" ]]; then
            echo "🐍 Python project detected"
            if command -v python3 &> /dev/null; then
              if [[ -f "requirements.txt" ]]; then
                pip install -r requirements.txt
              fi
              
              # Try different test runners
              if python -m pytest --version &> /dev/null && find . -name "*test*.py" | grep -q .; then
                echo "Running pytest..."
                python -m pytest
              elif python -m unittest discover -s . -p "*test*.py" 2>/dev/null; then
                echo "✅ Python unittest tests passed"
              else
                echo "ℹ️ No Python tests found or test framework not available"
              fi
            fi
          fi
          
          # Go tests
          if [[ -f "go.mod" ]]; then
            echo "🔷 Go project detected"
            if command -v go &> /dev/null; then
              go test ./...
              echo "✅ Go tests passed"
            fi
          fi
          
          echo "✅ Test phase complete"

  # ============================================================================
  # Docker Build (Conditional)
  # ============================================================================
  build-docker-api:
    name: 🐳 Build API Docker Images
    runs-on: ubuntu-latest
    needs: [preflight-checks, cleanup-old-resources, run-tests]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_deploy == 'true' && 
      inputs.skip_docker_build == false && 
      needs.preflight-checks.outputs.docker_build_needed == 'true' &&
      (needs.cleanup-old-resources.result == 'success' || needs.cleanup-old-resources.result == 'skipped') &&
      (needs.run-tests.result == 'success' || needs.run-tests.result == 'skipped')
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 🔑 Login to Docker Hub
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
          DOCKER_TOKEN: ${{ secrets.DOCKER_TOKEN }}
        if: env.DOCKER_USERNAME != '' && env.DOCKER_TOKEN != ''
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}

      - name: 🐳 Build and Push API Docker Images
        run: |
          echo "🐳 Building API Docker images for ${{ env.SERVICE_NAME }}..."
          
          # Build API services (Python servers: api, worker, data)
          API_SERVICES=()
          
          # Check for API service configuration
          if [[ -f "docker-compose.api.yml" ]]; then
            echo "📋 Found docker-compose.api.yml - building API services"
            docker compose -f docker-compose.api.yml build
            
            if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
              echo "📤 Pushing API compose images..."
              docker compose -f docker-compose.api.yml push || echo "⚠️ Some API images may not have push configured"
            fi
          elif [[ -f "docker-compose.yml" ]]; then
            # Build only API-related services from main compose file
            echo "📋 Building API services from main docker-compose.yml"
            
            # Extract API service names (common patterns: api, worker, data, backend)
            API_SERVICES=($(docker compose config --services 2>/dev/null | grep -E '^(api|worker|data|backend|server)$' || true))
            
            if [[ ${#API_SERVICES[@]} -gt 0 ]]; then
              echo "🔍 Found API services: ${API_SERVICES[*]}"
              
              for service in "${API_SERVICES[@]}"; do
                echo "🐳 Building service: $service"
                docker compose build "$service"
                
                if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
                  echo "📤 Pushing service: $service"
                  docker compose push "$service" || echo "⚠️ Failed to push $service"
                fi
              done
            else
              echo "ℹ️ No API services found in docker-compose.yml"
            fi
          elif [[ -f "Dockerfile" ]]; then
            # Single Dockerfile - assume it's for API if service name suggests it
            if [[ "${{ env.SERVICE_NAME }}" =~ (api|backend|server) ]]; then
              echo "📋 Found Dockerfile - building as API service"
              
              IMAGE_TAG="${{ secrets.DOCKER_USERNAME }}/${{ env.SERVICE_NAME }}-api:latest"
              
              docker build -t "$IMAGE_TAG" .
              
              if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
                echo "📤 Pushing image: $IMAGE_TAG"
                docker push "$IMAGE_TAG"
              fi
            else
              echo "ℹ️ Service doesn't appear to be API-focused - skipping API build"
            fi
          else
            echo "ℹ️ No Docker configuration found for API services"
          fi
          
          echo "✅ API Docker build complete"

  build-docker-web:
    name: 🌐 Build Web Docker Images  
    runs-on: ubuntu-latest
    needs: [preflight-checks, cleanup-old-resources, run-tests]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_deploy == 'true' && 
      inputs.skip_docker_build == false && 
      needs.preflight-checks.outputs.docker_build_needed == 'true' &&
      (needs.cleanup-old-resources.result == 'success' || needs.cleanup-old-resources.result == 'skipped') &&
      (needs.run-tests.result == 'success' || needs.run-tests.result == 'skipped')
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 🔑 Login to Docker Hub
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
          DOCKER_TOKEN: ${{ secrets.DOCKER_TOKEN }}
        if: env.DOCKER_USERNAME != '' && env.DOCKER_TOKEN != ''
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}

      - name: 🌐 Build and Push Web Docker Images
        run: |
          echo "🌐 Building Web Docker images for ${{ env.SERVICE_NAME }}..."
          
          # Build Web services (React web interface, frontend)
          WEB_SERVICES=()
          
          # Check for Web service configuration
          if [[ -f "docker-compose.web.yml" ]]; then
            echo "📋 Found docker-compose.web.yml - building Web services"
            docker compose -f docker-compose.web.yml build
            
            if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
              echo "📤 Pushing Web compose images..."
              docker compose -f docker-compose.web.yml push || echo "⚠️ Some Web images may not have push configured"
            fi
          elif [[ -f "docker-compose.yml" ]]; then
            # Build only Web-related services from main compose file
            echo "📋 Building Web services from main docker-compose.yml"
            
            # Extract Web service names (common patterns: web, frontend, ui, client)
            WEB_SERVICES=($(docker compose config --services 2>/dev/null | grep -E '^(web|frontend|ui|client|app)$' || true))
            
            if [[ ${#WEB_SERVICES[@]} -gt 0 ]]; then
              echo "🔍 Found Web services: ${WEB_SERVICES[*]}"
              
              for service in "${WEB_SERVICES[@]}"; do
                echo "🌐 Building service: $service"
                docker compose build "$service"
                
                if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
                  echo "📤 Pushing service: $service"
                  docker compose push "$service" || echo "⚠️ Failed to push $service"
                fi
              done
            else
              echo "ℹ️ No Web services found in docker-compose.yml"
            fi
          elif [[ -f "Dockerfile" ]]; then
            # Single Dockerfile - assume it's for Web if service name suggests it
            if [[ "${{ env.SERVICE_NAME }}" =~ (web|frontend|ui|client) ]]; then
              echo "📋 Found Dockerfile - building as Web service"
              
              IMAGE_TAG="${{ secrets.DOCKER_USERNAME }}/${{ env.SERVICE_NAME }}-web:latest"
              
              docker build -t "$IMAGE_TAG" .
              
              if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
                echo "📤 Pushing image: $IMAGE_TAG"
                docker push "$IMAGE_TAG"
              fi
            else
              echo "ℹ️ Service doesn't appear to be Web-focused - skipping Web build"
            fi
          else
            echo "ℹ️ No Docker configuration found for Web services"
          fi
          
          echo "✅ Web Docker build complete"

  build-docker-auth:
    name: 🔐 Build Auth Docker Images
    runs-on: ubuntu-latest
    needs: [preflight-checks, cleanup-old-resources, run-tests]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_deploy == 'true' && 
      inputs.skip_docker_build == false && 
      needs.preflight-checks.outputs.docker_build_needed == 'true' &&
      (needs.cleanup-old-resources.result == 'success' || needs.cleanup-old-resources.result == 'skipped') &&
      (needs.run-tests.result == 'success' || needs.run-tests.result == 'skipped')
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 🔑 Login to Docker Hub
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
          DOCKER_TOKEN: ${{ secrets.DOCKER_TOKEN }}
        if: env.DOCKER_USERNAME != '' && env.DOCKER_TOKEN != ''
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}

      - name: 🔐 Build and Push Auth Docker Images
        run: |
          echo "🔐 Building Auth Docker images for ${{ env.SERVICE_NAME }}..."
          
          # Build Auth services (Authentication, authorization services)
          AUTH_SERVICES=()
          
          # Check for Auth service configuration
          if [[ -f "docker-compose.auth.yml" ]]; then
            echo "📋 Found docker-compose.auth.yml - building Auth services"
            docker compose -f docker-compose.auth.yml build
            
            if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
              echo "📤 Pushing Auth compose images..."
              docker compose -f docker-compose.auth.yml push || echo "⚠️ Some Auth images may not have push configured"
            fi
          elif [[ -f "docker-compose.yml" ]]; then
            # Build only Auth-related services from main compose file
            echo "📋 Building Auth services from main docker-compose.yml"
            
            # Extract Auth service names (common patterns: auth, oauth, keycloak, etc.)
            AUTH_SERVICES=($(docker compose config --services 2>/dev/null | grep -E '^(auth|oauth|keycloak|identity|session)$' || true))
            
            if [[ ${#AUTH_SERVICES[@]} -gt 0 ]]; then
              echo "🔍 Found Auth services: ${AUTH_SERVICES[*]}"
              
              for service in "${AUTH_SERVICES[@]}"; do
                echo "🔐 Building service: $service"
                docker compose build "$service"
                
                if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
                  echo "📤 Pushing service: $service"
                  docker compose push "$service" || echo "⚠️ Failed to push $service"
                fi
              done
            else
              echo "ℹ️ No Auth services found in docker-compose.yml - may use external auth services"
            fi
          else
            echo "ℹ️ No custom Auth services to build - likely using external authentication"
          fi
          
          echo "✅ Auth Docker build complete (or skipped if no custom services)"

  # ============================================================================
  # Server Destruction (if overwrite requested)
  # ============================================================================
  destroy-existing-server:
    name: 💥 Destroy Existing Server
    runs-on: ubuntu-latest
    needs: [preflight-checks, cleanup-old-resources, build-docker-api, build-docker-web, build-docker-auth]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_overwrite_server == 'true' &&
      needs.preflight-checks.outputs.destroy_confirmed == 'true' &&
      (needs.cleanup-old-resources.result == 'success' || needs.cleanup-old-resources.result == 'skipped') &&
      (needs.build-docker-api.result == 'success' || needs.build-docker-api.result == 'skipped') &&
      (needs.build-docker-web.result == 'success' || needs.build-docker-web.result == 'skipped') &&
      (needs.build-docker-auth.result == 'success' || needs.build-docker-auth.result == 'skipped')
    
    steps:
      - name: � Checkout repository
        uses: actions/checkout@v4

      - name: �🔧 Setup Linode CLI
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
        run: |
          pip install linode-cli
          # Configure via environment variable to avoid config file issues
          export LINODE_CLI_TOKEN="${{ secrets.LINODE_CLI_TOKEN }}"
          # Test CLI access
          linode-cli --version

      - name: 🧹 Cleanup Services Before Destruction
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
          TAILSCALE_AUTH_KEY: ${{ secrets.TAILSCALE_AUTH_KEY }}
          TAILSCALE_TAILNET: ${{ secrets.TAILSCALE_TAILNET }}
        run: |
          echo "🧹 Cleaning up external service registrations..."
          
          # Install dependencies
          sudo apt-get update && sudo apt-get install -y curl jq sshpass >/dev/null 2>&1 || true
          
          # Find existing server
          EXISTING_SERVER=$(linode-cli linodes list --text --no-headers | grep "${{ env.SERVICE_NAME }}" | head -1)
          
          if [[ -n "$EXISTING_SERVER" ]]; then
            SERVER_ID=$(echo "$EXISTING_SERVER" | cut -f1)
            SERVER_LABEL=$(echo "$EXISTING_SERVER" | cut -f2)
            
            # Try to get server IP for cleanup
            SERVER_INFO=$(linode-cli linodes view "$SERVER_ID" --text --no-headers)
            SERVER_IP_COL4=$(echo "$SERVER_INFO" | cut -f4)
            SERVER_IP_COL5=$(echo "$SERVER_INFO" | cut -f5)
            SERVER_IP_COL6=$(echo "$SERVER_INFO" | cut -f6)
            SERVER_IP_COL7=$(echo "$SERVER_INFO" | cut -f7)
            
            SERVER_IP=""
            for IP in "$SERVER_IP_COL4" "$SERVER_IP_COL5" "$SERVER_IP_COL6" "$SERVER_IP_COL7"; do
              if [[ "$IP" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
                SERVER_IP="$IP"
                break
              fi
            done
            
            if [[ -n "$SERVER_IP" ]]; then
              echo "🔍 Found server to cleanup: $SERVER_LABEL ($SERVER_IP)"
              
              # Try to connect using password authentication for cleanup
              echo "🔗 Attempting cleanup connection via password auth..."
              
              # Try to connect and cleanup using root password
              if timeout 30 sshpass -p "${{ secrets.SERVICE_ROOT_PASSWORD }}" ssh -o StrictHostKeyChecking=no -o ConnectTimeout=10 root@$SERVER_IP "echo 'Cleanup connection successful'" 2>/dev/null; then
                echo "🔗 Connected to server for cleanup..."
                
                # Cleanup Tailscale device
                echo "🧹 Removing Tailscale device from network..."
                sshpass -p "${{ secrets.SERVICE_ROOT_PASSWORD }}" ssh -o StrictHostKeyChecking=no root@$SERVER_IP "tailscale logout 2>/dev/null || true" || true
                
                # Get device info before cleanup
                DEVICE_NAME=$(sshpass -p "${{ secrets.SERVICE_ROOT_PASSWORD }}" ssh -o StrictHostKeyChecking=no root@$SERVER_IP "hostname 2>/dev/null || echo '${{ env.SERVICE_NAME }}'" || echo "${{ env.SERVICE_NAME }}")
                echo "Device name for cleanup: $DEVICE_NAME"
                
                echo "✅ Service cleanup completed"
              else
                echo "⚠️ Could not connect to server for cleanup (server may be down, password changed, or SSH not configured)"
                echo "ℹ️ This is normal if the server was already destroyed or is not responding"
              fi
            else
              echo "⚠️ Could not determine server IP for cleanup"
            fi
            
            # Cleanup Tailscale devices via API (more reliable and comprehensive)
            if [[ -n "$TAILSCALE_AUTH_KEY" ]]; then
              echo "🔗 Comprehensive Tailscale cleanup for service ${{ env.SERVICE_NAME }}..."
              
              TAILNET="${TAILSCALE_TAILNET}"
              if [[ -z "$TAILNET" ]]; then
                echo "⚠️ TAILSCALE_TAILNET not set, using default discovery"
                # For personal accounts, use the default endpoint without tailnet
                DEVICES_URL="https://api.tailscale.com/api/v2/devices"
              else
                echo "🔍 Using tailnet: $TAILNET"
                DEVICES_URL="https://api.tailscale.com/api/v2/tailnet/$TAILNET/devices"
              fi
              
              echo "🌐 Fetching ALL devices for comprehensive cleanup..."
              DEVICES_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" "$DEVICES_URL" 2>/dev/null || echo "CURL_FAILED")
              
              # Extract HTTP status code
              HTTP_CODE=$(echo "$DEVICES_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
              DEVICES_JSON=$(echo "$DEVICES_RESPONSE" | sed '/HTTP_CODE:/d')
              
              echo "🔍 API Response Code: $HTTP_CODE"
              
              if [[ "$HTTP_CODE" == "200" ]] && echo "$DEVICES_JSON" | jq -e '.devices' >/dev/null 2>&1; then
                # Multiple cleanup patterns to catch all variants
                CLEANUP_PATTERNS=(
                  "^${{ env.SERVICE_NAME }}(-[0-9]+)?$"
                  "^${{ env.SERVICE_NAME }}$" 
                  "^${{ env.SERVICE_NAME }}-"
                  "${{ env.SERVICE_NAME }}"
                )
                
                TOTAL_REMOVED=0
                ALL_FOUND_DEVICES=""
                
                # First pass: collect all matching device IDs
                for pattern in "${CLEANUP_PATTERNS[@]}"; do
                  echo "🔍 Searching for devices matching pattern: $pattern"
                  
                  DEVICES=$(echo "$DEVICES_JSON" | jq -r --arg pattern "$pattern" '
                    .devices[]? | 
                    select(
                      (.hostname // .name | test($pattern; "i")) or 
                      (.name // .hostname | test($pattern; "i"))
                    ) | 
                    .id // empty' | grep -v '^$')
                  
                  if [[ -n "$DEVICES" ]]; then
                    ALL_FOUND_DEVICES="$ALL_FOUND_DEVICES $DEVICES"
                  fi
                done
                
                # Remove duplicates and clean up the list
                UNIQUE_DEVICES=$(echo "$ALL_FOUND_DEVICES" | tr ' ' '\n' | sort -u | grep -v '^$' || true)
                
                if [[ -n "$UNIQUE_DEVICES" ]]; then
                  echo "Found devices to remove:"
                  for device_id in $UNIQUE_DEVICES; do
                    if [[ -n "$device_id" ]]; then
                      # Get device details before removal
                      DEVICE_INFO=$(echo "$DEVICES_JSON" | jq -r --arg id "$device_id" '.devices[]? | select(.id == $id) | "\(.hostname // .name // "unknown") (\(.addresses[0] // "no-ip"))"')
                      echo "🗑️ Removing device: $device_id - $DEVICE_INFO"
                      
                      # Try both API endpoint formats
                      DELETE_URL="https://api.tailscale.com/api/v2/device/$device_id"
                      REMOVE_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -X DELETE \
                        -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
                        "$DELETE_URL" 2>/dev/null || echo "CURL_FAILED")
                      
                      REMOVE_CODE=$(echo "$REMOVE_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                      
                      if [[ "$REMOVE_CODE" == "200" || "$REMOVE_CODE" == "204" ]]; then
                        echo "   ✅ Successfully removed"
                        ((TOTAL_REMOVED++))
                      else
                        echo "   ⚠️ Primary endpoint failed (HTTP: $REMOVE_CODE), trying alternative..."
                        # Try alternative API endpoint format
                        if [[ -n "$TAILNET" ]]; then
                          ALT_DELETE_URL="https://api.tailscale.com/api/v2/tailnet/$TAILNET/devices/$device_id"
                        else
                          ALT_DELETE_URL="https://api.tailscale.com/api/v2/devices/$device_id"
                        fi
                        
                        ALT_REMOVE_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -X DELETE \
                          -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
                          "$ALT_DELETE_URL" 2>/dev/null || echo "CURL_FAILED")
                        
                        ALT_REMOVE_CODE=$(echo "$ALT_REMOVE_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                        if [[ "$ALT_REMOVE_CODE" == "200" || "$ALT_REMOVE_CODE" == "204" ]]; then
                          echo "   ✅ Successfully removed via alternative endpoint"
                          ((TOTAL_REMOVED++))
                        else
                          echo "   ❌ Failed to remove device $device_id (Primary: $REMOVE_CODE, Alt: $ALT_REMOVE_CODE)"
                        fi
                      fi
                      
                      # Rate limiting: small delay between deletions
                      sleep 1
                    fi
                  done
                  echo "✅ Comprehensive Tailscale cleanup completed - removed $TOTAL_REMOVED devices total"
                else
                  echo "ℹ️ No Tailscale devices found matching service name pattern: $SERVICE_PATTERN"
                fi
              elif [[ "$HTTP_CODE" == "401" ]]; then
                echo "❌ Tailscale API authentication failed - check TAILSCALE_AUTH_KEY"
              elif [[ "$HTTP_CODE" == "403" ]]; then
                echo "❌ Tailscale API access forbidden - check API key permissions"
              elif [[ "$HTTP_CODE" == "404" ]]; then
                echo "❌ Tailscale tailnet not found - check TAILSCALE_TAILNET value"
              else
                echo "⚠️ Could not retrieve Tailscale devices list"
                echo "HTTP Code: $HTTP_CODE"
                echo "Response: $DEVICES_JSON" | head -200
              fi
            else
              echo "⚠️ Tailscale API key not available"
            fi
          else
            echo "ℹ️ No existing server found for cleanup"
          fi

      - name: 💥 Destroy Existing Server
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
        run: |
          echo "💥 Looking for existing ${{ env.SERVICE_NAME }} server to destroy..."
          
          # Find existing server
          EXISTING_SERVER=$(linode-cli linodes list --text --no-headers | grep "${{ env.SERVICE_NAME }}" | head -1)
          
          if [[ -n "$EXISTING_SERVER" ]]; then
            SERVER_ID=$(echo "$EXISTING_SERVER" | cut -f1)
            SERVER_LABEL=$(echo "$EXISTING_SERVER" | cut -f2)
            
            echo "🔥 Destroying server: $SERVER_LABEL (ID: $SERVER_ID)"
            linode-cli linodes delete "$SERVER_ID"
            
            echo "⏳ Waiting for server destruction to complete..."
            sleep 30
            
            echo "✅ Server destroyed successfully"
          else
            echo "ℹ️ No existing server found for ${{ env.SERVICE_NAME }}"
          fi

  # ============================================================================
  # Main Destroy Job (for destroy action)
  # ============================================================================
  destroy-service:
    name: 🗑️ Destroy Service
    runs-on: ubuntu-latest
    needs: preflight-checks
    if: needs.preflight-checks.outputs.should_destroy == 'true' && needs.preflight-checks.outputs.destroy_confirmed == 'true'
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 🔧 Setup Linode CLI
        if: inputs.destroy_scope == 'full-server'
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
        run: |
          pip install linode-cli
          # Configure via environment variable to avoid config file issues
          export LINODE_CLI_TOKEN="${{ secrets.LINODE_CLI_TOKEN }}"
          # Test CLI access
          linode-cli --version

      - name: 🗑️ Execute Destruction
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
          TAILSCALE_AUTH_KEY: ${{ secrets.TAILSCALE_AUTH_KEY }}
          TAILSCALE_TAILNET: ${{ secrets.TAILSCALE_TAILNET }}
        run: |
          echo "🗑️ Destroying ${{ env.SERVICE_NAME }}..."
          echo "Scope: ${{ inputs.destroy_scope }}"
          
          # Install dependencies for API calls
          sudo apt-get update && sudo apt-get install -y curl jq >/dev/null 2>&1 || true
          
          case "${{ inputs.destroy_scope }}" in
            "service-only")
              echo "🛑 Stopping service containers only..."
              # Logic for service-only destruction
              ;;
            "reset-service")
              echo "🧹 Resetting service to clean state..."
              # Logic for service reset
              ;;
            "full-server")
              echo "💥 Destroying entire server with cleanup..."
              
              # Find and cleanup server before destruction
              SERVER_INFO=$(linode-cli linodes list --text --no-headers | grep "${{ env.SERVICE_NAME }}" | head -1)
              if [[ -n "$SERVER_INFO" ]]; then
                SERVER_ID=$(echo "$SERVER_INFO" | cut -f1)
                SERVER_LABEL=$(echo "$SERVER_INFO" | cut -f2)
                
                # Try to get server IP for cleanup
                SERVER_DETAILS=$(linode-cli linodes view "$SERVER_ID" --text --no-headers)
                SERVER_IP_COL4=$(echo "$SERVER_DETAILS" | cut -f4)
                SERVER_IP_COL5=$(echo "$SERVER_DETAILS" | cut -f5)
                SERVER_IP_COL6=$(echo "$SERVER_DETAILS" | cut -f6)
                SERVER_IP_COL7=$(echo "$SERVER_DETAILS" | cut -f7)
                
                SERVER_IP=""
                for IP in "$SERVER_IP_COL4" "$SERVER_IP_COL5" "$SERVER_IP_COL6" "$SERVER_IP_COL7"; do
                  if [[ "$IP" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
                    SERVER_IP="$IP"
                    break
                  fi
                done
                
                if [[ -n "$SERVER_IP" ]]; then
                  echo "🧹 Cleaning up services on server before destruction..."
                  
                  # Generate SSH key for cleanup
                  ssh-keygen -t rsa -b 4096 -f ~/.ssh/cleanup_key -N "" -C "cleanup-${{ env.SERVICE_NAME }}" || true
                  
                  # Try to connect and cleanup
                  if timeout 30 ssh -i ~/.ssh/cleanup_key -o StrictHostKeyChecking=no -o ConnectTimeout=10 root@$SERVER_IP "echo 'Cleanup connection successful'" 2>/dev/null; then
                    echo "🔗 Connected for cleanup..."
                    
                    # Cleanup Tailscale
                    ssh -i ~/.ssh/cleanup_key -o StrictHostKeyChecking=no root@$SERVER_IP "tailscale logout || true" || true
                    
                    echo "✅ Service cleanup completed"
                  else
                    echo "⚠️ Could not connect for cleanup"
                  fi
                fi
                
                echo "Destroying: $SERVER_LABEL (ID: $SERVER_ID)"
                linode-cli linodes delete "$SERVER_ID"
                echo "✅ Server destroyed"
                
                # Cleanup Tailscale devices via API after server destruction (comprehensive)
                if [[ -n "$TAILSCALE_AUTH_KEY" ]]; then
                  echo "🔗 Final comprehensive Tailscale cleanup for service ${{ env.SERVICE_NAME }}..."
                  
                  TAILNET="${TAILSCALE_TAILNET}"
                  if [[ -z "$TAILNET" ]]; then
                    echo "⚠️ TAILSCALE_TAILNET not set, using default discovery"
                    DEVICES_URL="https://api.tailscale.com/api/v2/devices"
                  else
                    echo "🔍 Using tailnet: $TAILNET"
                    DEVICES_URL="https://api.tailscale.com/api/v2/tailnet/$TAILNET/devices"
                  fi
                  
                  echo "🌐 Fetching ALL remaining devices for final cleanup..."
                  DEVICES_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" "$DEVICES_URL" 2>/dev/null || echo "CURL_FAILED")
                  
                  # Extract HTTP status code
                  HTTP_CODE=$(echo "$DEVICES_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                  DEVICES_JSON=$(echo "$DEVICES_RESPONSE" | sed '/HTTP_CODE:/d')
                  
                  echo "🔍 API Response Code: $HTTP_CODE"
                  
                  if [[ "$HTTP_CODE" == "200" ]] && echo "$DEVICES_JSON" | jq -e '.devices' >/dev/null 2>&1; then
                    # Even more aggressive cleanup patterns for final cleanup
                    CLEANUP_PATTERNS=(
                      "^${{ env.SERVICE_NAME }}(-[0-9]+)?$"
                      "^${{ env.SERVICE_NAME }}$" 
                      "^${{ env.SERVICE_NAME }}-"
                      "${{ env.SERVICE_NAME }}"
                      ".*${{ env.SERVICE_NAME }}.*"  # Catch any device containing the service name
                    )
                    
                    TOTAL_REMOVED=0
                    ALL_FOUND_DEVICES=""
                    
                    # Collect all matching device IDs from all patterns
                    for pattern in "${CLEANUP_PATTERNS[@]}"; do
                      echo "🔍 Final scan for pattern: $pattern"
                      
                      DEVICES=$(echo "$DEVICES_JSON" | jq -r --arg pattern "$pattern" '
                        .devices[]? | 
                        select(
                          (.hostname // .name | test($pattern; "i")) or 
                          (.name // .hostname | test($pattern; "i"))
                        ) | 
                        .id // empty' | grep -v '^$')
                      
                      if [[ -n "$DEVICES" ]]; then
                        ALL_FOUND_DEVICES="$ALL_FOUND_DEVICES $DEVICES"
                      fi
                    done
                    
                    # Remove duplicates and clean up the list
                    UNIQUE_DEVICES=$(echo "$ALL_FOUND_DEVICES" | tr ' ' '\n' | sort -u | grep -v '^$' || true)
                    
                    if [[ -n "$UNIQUE_DEVICES" ]]; then
                      echo "Found orphaned devices for final removal:"
                      for device_id in $UNIQUE_DEVICES; do
                        if [[ -n "$device_id" ]]; then
                          # Get device details before removal
                          DEVICE_INFO=$(echo "$DEVICES_JSON" | jq -r --arg id "$device_id" '.devices[]? | select(.id == $id) | "\(.hostname // .name // "unknown") (\(.addresses[0] // "no-ip"))"')
                          echo "🗑️ Final cleanup - removing: $device_id - $DEVICE_INFO"
                          
                          # Try both API endpoint formats aggressively
                          DELETE_URL="https://api.tailscale.com/api/v2/device/$device_id"
                          REMOVE_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -X DELETE \
                            -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
                            "$DELETE_URL" 2>/dev/null || echo "CURL_FAILED")
                          
                          REMOVE_CODE=$(echo "$REMOVE_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                          
                          if [[ "$REMOVE_CODE" == "200" || "$REMOVE_CODE" == "204" ]]; then
                            echo "   ✅ Successfully removed"
                            ((TOTAL_REMOVED++))
                          else
                            echo "   ⚠️ Trying alternative endpoint (HTTP: $REMOVE_CODE)..."
                            # Try alternative API endpoint format
                            if [[ -n "$TAILNET" ]]; then
                              ALT_DELETE_URL="https://api.tailscale.com/api/v2/tailnet/$TAILNET/devices/$device_id"
                            else
                              ALT_DELETE_URL="https://api.tailscale.com/api/v2/devices/$device_id"
                            fi
                            
                            ALT_REMOVE_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -X DELETE \
                              -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
                              "$ALT_DELETE_URL" 2>/dev/null || echo "CURL_FAILED")
                            
                            ALT_REMOVE_CODE=$(echo "$ALT_REMOVE_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                            if [[ "$ALT_REMOVE_CODE" == "200" || "$ALT_REMOVE_CODE" == "204" ]]; then
                              echo "   ✅ Successfully removed via alternative endpoint"
                              ((TOTAL_REMOVED++))
                            else
                              echo "   ❌ Could not remove device $device_id (Primary: $REMOVE_CODE, Alt: $ALT_REMOVE_CODE)"
                            fi
                          fi
                          
                          # Rate limiting: small delay between deletions
                          sleep 1
                        fi
                      done
                      echo "✅ Final Tailscale cleanup completed - removed $TOTAL_REMOVED devices total"
                          echo "🗑️ Removing orphaned Tailscale device: $device_id - $DEVICE_INFO"
                          
                          DELETE_URL="https://api.tailscale.com/api/v2/device/$device_id"
                          REMOVE_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -X DELETE \
                            -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
                            "$DELETE_URL" 2>/dev/null || echo "CURL_FAILED")
                          
                          REMOVE_CODE=$(echo "$REMOVE_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                          
                          if [[ "$REMOVE_CODE" == "200" || "$REMOVE_CODE" == "204" ]]; then
                            echo "   ✅ Successfully removed"
                            ((REMOVED_COUNT++))
                          else
                            echo "   ❌ Failed to remove device $device_id (HTTP: $REMOVE_CODE)"
                          fi
                          
                          # Rate limiting
                          sleep 1
                        fi
                      done
                      echo "✅ Orphaned device cleanup completed - removed $REMOVED_COUNT devices"
                    else
                      echo "ℹ️ No orphaned Tailscale devices found matching pattern: $SERVICE_PATTERN"
                    fi
                  else
                    echo "⚠️ Could not retrieve Tailscale devices for cleanup - HTTP: $HTTP_CODE"
                  fi
                fi
              else
                echo "⚠️ No server found for ${{ env.SERVICE_NAME }}"
              fi
              ;;
          esac

  # ============================================================================
  # Server Infrastructure Setup
  # ============================================================================
  setup-infrastructure:
    name: 🏗️ Setup Infrastructure
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [preflight-checks, cleanup-old-resources, destroy-existing-server, build-docker-api, build-docker-web, build-docker-auth]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_deploy == 'true' &&
      (needs.cleanup-old-resources.result == 'success' || needs.cleanup-old-resources.result == 'skipped') &&
      (needs.destroy-existing-server.result == 'success' || needs.destroy-existing-server.result == 'skipped') &&
      (needs.build-docker-api.result == 'success' || needs.build-docker-api.result == 'skipped') &&
      (needs.build-docker-web.result == 'success' || needs.build-docker-web.result == 'skipped') &&
      (needs.build-docker-auth.result == 'success' || needs.build-docker-auth.result == 'skipped')
    outputs:
      server_ip: ${{ steps.create-server.outputs.server_ip }}
      server_id: ${{ steps.create-server.outputs.server_id }}
      tailscale_ip: ${{ steps.stage2-setup.outputs.tailscale_ip }}
      ssh_private_key: ${{ steps.create-server.outputs.ssh_private_key }}
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 🔧 Setup Linode CLI
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
        run: |
          pip install linode-cli
          # Configure via environment variable to avoid config file issues
          export LINODE_CLI_TOKEN="${{ secrets.LINODE_CLI_TOKEN }}"
          # Test CLI access
          linode-cli --version

      - name: 🚀 Create or Find Server
        id: create-server
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
        run: |
          echo "🚀 Managing Linode server for ${{ env.SERVICE_NAME }}..."
          
          # Check if server already exists (unless we just destroyed it)
          if [[ "${{ inputs.overwrite_server }}" != "true" ]]; then
            EXISTING_SERVER=$(linode-cli linodes list --text --no-headers | grep "${{ env.SERVICE_NAME }}" | head -1)
            if [[ -n "$EXISTING_SERVER" ]]; then
              echo "🔍 Debug - Found existing server:"
              echo "$EXISTING_SERVER"
              
              SERVER_ID=$(echo "$EXISTING_SERVER" | cut -f1)
              # Try different columns for IP address
              SERVER_IP_COL4=$(echo "$EXISTING_SERVER" | cut -f4)
              SERVER_IP_COL5=$(echo "$EXISTING_SERVER" | cut -f5)
              SERVER_IP_COL6=$(echo "$EXISTING_SERVER" | cut -f6)
              SERVER_IP_COL7=$(echo "$EXISTING_SERVER" | cut -f7)
              
              echo "IP candidates: Col4='$SERVER_IP_COL4', Col5='$SERVER_IP_COL5', Col6='$SERVER_IP_COL6', Col7='$SERVER_IP_COL7'"
              
              # Use the first valid IP address we find
              for IP in "$SERVER_IP_COL4" "$SERVER_IP_COL5" "$SERVER_IP_COL6" "$SERVER_IP_COL7"; do
                if [[ "$IP" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
                  SERVER_IP="$IP"
                  break
                fi
              done
              
              if [[ -z "$SERVER_IP" ]]; then
                echo "❌ Could not extract IP address from server info"
                exit 1
              fi
              
              echo "✅ Using existing server: $SERVER_IP (ID: $SERVER_ID)"
              echo "server_ip=$SERVER_IP" >> $GITHUB_OUTPUT
              echo "server_id=$SERVER_ID" >> $GITHUB_OUTPUT
              
              # Create a placeholder SSH key for consistency (will use password auth for existing servers)
              ssh-keygen -t rsa -b 4096 -f ~/.ssh/linode_deployment_key -N "" -C "github-actions-${{ env.SERVICE_NAME }}" 2>/dev/null || true
              SSH_PRIVATE_KEY=$(base64 -w 0 ~/.ssh/linode_deployment_key 2>/dev/null || echo "")
              echo "ssh_private_key=$SSH_PRIVATE_KEY" >> $GITHUB_OUTPUT
              
              exit 0
            fi
          fi
          
          # Create new server
          SERVER_LABEL="${{ env.SERVICE_NAME }}"
          echo "🆕 Creating new server: $SERVER_LABEL"
          
          # Generate SSH key for this deployment
          echo "🔑 Generating SSH key for server access..."
          ssh-keygen -t rsa -b 4096 -f ~/.ssh/linode_deployment_key -N "" -C "github-actions-${{ env.SERVICE_NAME }}"
          
          # Get the public key content for server authorization
          SSH_PUBLIC_KEY=$(cat ~/.ssh/linode_deployment_key.pub)
          echo "🔑 SSH Public Key: $SSH_PUBLIC_KEY"
          
          # Store the private key (base64 encoded for safe storage)
          SSH_PRIVATE_KEY=$(base64 -w 0 ~/.ssh/linode_deployment_key)
          echo "ssh_private_key=$SSH_PRIVATE_KEY" >> $GITHUB_OUTPUT
          
          echo "🚀 Creating server with SSH key authentication..."
          echo "Using server type: ${{ env.SERVER_TYPE }}"
          echo "Using region: ${{ env.TARGET_REGION }}"
          echo "Using backup setting: ${{ inputs.enable_backups || 'false' }}"
          
          RESULT=$(linode-cli linodes create \
            --type "${{ env.SERVER_TYPE }}" \
            --region "${{ env.TARGET_REGION }}" \
            --image "linode/arch" \
            --label "$SERVER_LABEL" \
            --root_pass "${{ secrets.SERVICE_ROOT_PASSWORD }}" \
            --authorized_keys "$SSH_PUBLIC_KEY" \
            --backups_enabled=${{ inputs.enable_backups || 'false' }} \
            --text --no-headers)
          
          echo "🔍 Server creation result:"
          echo "$RESULT"
          
          if [[ -z "$RESULT" ]] || [[ "$RESULT" == *"error"* ]] || [[ "$RESULT" == *"Error"* ]]; then
            echo "❌ Server creation failed!"
            echo "Result: $RESULT"
            exit 1
          fi
          
          SERVER_ID=$(echo "$RESULT" | cut -f1)
          
          if [[ -z "$SERVER_ID" ]] || [[ ! "$SERVER_ID" =~ ^[0-9]+$ ]]; then
            echo "❌ Invalid server ID extracted: '$SERVER_ID'"
            echo "Full result: $RESULT"
            exit 1
          fi
          
          echo "🆔 Server created with ID: $SERVER_ID"
          
          # Wait for server to be running
          echo "⏳ Waiting for server to be ready..."
          ATTEMPT=0
          while true; do
            # Get server info and check status
            SERVER_INFO=$(linode-cli linodes view "$SERVER_ID" --text --no-headers)
            
            # Debug: show the full output on first few attempts
            if [[ $ATTEMPT -lt 3 ]]; then
              echo "🔍 Debug - Server info columns:"
              echo "$SERVER_INFO"
            fi
            
            # Status is in column 6 (ID|Label|Region|Type|Image|Status|IP|Backups)
            STATUS=$(echo "$SERVER_INFO" | cut -f6)
            
            echo "Attempt $((++ATTEMPT)): Status='$STATUS'"
            
            # Check if server is running
            if [[ "$STATUS" == "running" ]]; then
              echo "✅ Server is running!"
              break
            fi
            
            # Don't wait forever for server status
            if [[ $ATTEMPT -gt 15 ]]; then
              echo "⚠️ Server status check timeout - proceeding to SSH test"
              break
            fi
            
            sleep 5  # Check more frequently
          done
          
          # Get server IP
          SERVER_INFO=$(linode-cli linodes view "$SERVER_ID" --text --no-headers)
          echo "🔍 Debug - Server view output:"
          echo "$SERVER_INFO"
          
          # Try different columns for IP address
          SERVER_IP_COL4=$(echo "$SERVER_INFO" | cut -f4)
          SERVER_IP_COL5=$(echo "$SERVER_INFO" | cut -f5)
          SERVER_IP_COL6=$(echo "$SERVER_INFO" | cut -f6)
          SERVER_IP_COL7=$(echo "$SERVER_INFO" | cut -f7)
          
          echo "IP candidates: Col4='$SERVER_IP_COL4', Col5='$SERVER_IP_COL5', Col6='$SERVER_IP_COL6', Col7='$SERVER_IP_COL7'"
          
          # Use the first valid IP address we find
          for IP in "$SERVER_IP_COL4" "$SERVER_IP_COL5" "$SERVER_IP_COL6" "$SERVER_IP_COL7"; do
            if [[ "$IP" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
              SERVER_IP="$IP"
              break
            fi
          done
          
          if [[ -z "$SERVER_IP" ]]; then
            echo "❌ Could not extract IP address from server info"
            exit 1
          fi
          
          echo "✅ Server ready: $SERVER_IP (ID: $SERVER_ID)"
          
          echo "server_ip=$SERVER_IP" >> $GITHUB_OUTPUT
          echo "server_id=$SERVER_ID" >> $GITHUB_OUTPUT

      - name: ⏳ Wait for SSH Access
        run: |
          echo "⏳ Waiting for SSH access to ${{ steps.create-server.outputs.server_ip }}..."
          
          SSH_READY=false
          
          # First, test basic connectivity
          echo "🔍 Testing basic connectivity to port 22..."
          for i in {1..10}; do
            if timeout 5 nc -zv ${{ steps.create-server.outputs.server_ip }} 22 2>/dev/null; then
              echo "✅ Port 22 is reachable on attempt $i"
              break
            fi
            echo "Port 22 not ready, waiting 10 seconds..."
            sleep 10
          done
          
          # Test SSH with detailed error output
          echo "🔑 Testing SSH connection with private key..."
          
          for i in {1..15}; do
            echo "Attempt $i/15: Testing SSH connection..."
            
            # Use the generated private key for authentication
            SSH_OUTPUT=$(timeout 10 ssh -i ~/.ssh/linode_deployment_key -v -o StrictHostKeyChecking=no -o ConnectTimeout=5 -o ConnectionAttempts=1 \
               root@${{ steps.create-server.outputs.server_ip }} "echo 'SSH ready'" 2>&1 || echo "SSH_FAILED")
            
            if echo "$SSH_OUTPUT" | grep -q "SSH ready"; then
              echo "✅ SSH ready after $i attempts"
              SSH_READY=true
              break
            else
              echo "SSH failed. Last few lines of output:"
              echo "$SSH_OUTPUT" | tail -3
            fi
            
            echo "Waiting 15 seconds before next attempt..."
            sleep 15
          done
          
          if [[ "$SSH_READY" != "true" ]]; then
            echo "❌ SSH failed to become ready after 30 attempts (5 minutes)"
            echo "🔍 Debugging SSH connection..."
            
            # Try to get more info about why SSH is failing
            echo "Testing basic connectivity..."
            timeout 5 nc -zv ${{ steps.create-server.outputs.server_ip }} 22 || echo "Port 22 not reachable"
            
            exit 1
          fi

      - name: 🏗️ Stage 1 - Pre-Reboot Setup
        id: stage1-setup
        run: |
          echo "🏗️ Stage 1: Pre-reboot foundation setup..."
          
          # Download and execute the stage 1 setup script
          curl -o stage1-setup.sh https://raw.githubusercontent.com/nuniesmith/actions/main/scripts/stage1-complete-setup.sh
          chmod +x stage1-setup.sh
          
          # Replace placeholders in setup script
          sed -i "s/SERVICE_NAME_PLACEHOLDER/${{ env.SERVICE_NAME }}/g" stage1-setup.sh
          sed -i "s/TAILSCALE_AUTH_KEY_PLACEHOLDER/${{ secrets.TAILSCALE_AUTH_KEY }}/g" stage1-setup.sh
          sed -i "s/ACTIONS_USER_PASSWORD_PLACEHOLDER/${{ secrets.ACTIONS_USER_PASSWORD }}/g" stage1-setup.sh
          sed -i "s/JORDAN_PASSWORD_PLACEHOLDER/${{ secrets.JORDAN_PASSWORD }}/g" stage1-setup.sh
          
          # Download and prepare the stage 2 script with proper placeholders replaced
          curl -o stage2-post-reboot.sh https://raw.githubusercontent.com/nuniesmith/actions/main/scripts/stage2-post-reboot.sh
          chmod +x stage2-post-reboot.sh
          
          # Debug: Show what secrets we have
          echo "🔍 Debug: Checking secrets availability..."
          echo "Service name: ${{ env.SERVICE_NAME }}"
          echo "Full domain: ${{ env.FULL_DOMAIN }}"
          echo "Tailscale key starts with: ${{ secrets.TAILSCALE_AUTH_KEY != '' && 'SET' || 'EMPTY' }}"
          echo "Cloudflare email set: ${{ secrets.CLOUDFLARE_EMAIL != '' && 'SET' || 'EMPTY' }}"
          echo "Cloudflare token set: ${{ secrets.CLOUDFLARE_API_TOKEN != '' && 'SET' || 'EMPTY' }}"
          
          # Fail early if required secrets are missing
          if [[ -z "${{ secrets.TAILSCALE_AUTH_KEY }}" ]]; then
            echo "❌ TAILSCALE_AUTH_KEY secret is empty or not set!"
            echo "🔍 Please check repository secrets in GitHub settings"
            exit 1
          fi
          
          # Create a temporary script to do the replacements more safely
          cat > replace_placeholders.sh << 'EOF'
          #!/bin/bash
          
          # Replace SERVICE_NAME_PLACEHOLDER
          sed -i "s|SERVICE_NAME_PLACEHOLDER|${SERVICE_NAME}|g" stage2-post-reboot.sh
          
          # Replace TAILSCALE_AUTH_KEY_PLACEHOLDER  
          sed -i "s|TAILSCALE_AUTH_KEY_PLACEHOLDER|${TAILSCALE_AUTH_KEY}|g" stage2-post-reboot.sh
          
          # Replace CLOUDFLARE_EMAIL_PLACEHOLDER
          sed -i "s|CLOUDFLARE_EMAIL_PLACEHOLDER|${CLOUDFLARE_EMAIL}|g" stage2-post-reboot.sh
          
          # Replace CLOUDFLARE_API_TOKEN_PLACEHOLDER
          sed -i "s|CLOUDFLARE_API_TOKEN_PLACEHOLDER|${CLOUDFLARE_API_TOKEN}|g" stage2-post-reboot.sh
          
          # Replace DOMAIN_NAME_PLACEHOLDER
          sed -i "s|DOMAIN_NAME_PLACEHOLDER|${FULL_DOMAIN}|g" stage2-post-reboot.sh
          EOF
          
          chmod +x replace_placeholders.sh
          
          # Set environment variables and run replacement script
          export SERVICE_NAME="${{ env.SERVICE_NAME }}"
          export TAILSCALE_AUTH_KEY="${{ secrets.TAILSCALE_AUTH_KEY }}"
          export CLOUDFLARE_EMAIL="${{ secrets.CLOUDFLARE_EMAIL || '' }}"
          export CLOUDFLARE_API_TOKEN="${{ secrets.CLOUDFLARE_API_TOKEN || '' }}"
          export FULL_DOMAIN="${{ env.FULL_DOMAIN }}"
          
          ./replace_placeholders.sh
          
          # Verify replacements worked
          echo "🔍 Verifying placeholder replacement..."
          if grep -q "TAILSCALE_AUTH_KEY_PLACEHOLDER" stage2-post-reboot.sh; then
            echo "❌ TAILSCALE_AUTH_KEY placeholder not replaced!"
            echo "🔍 Checking what's in the script around the auth key:"
            grep -n -A2 -B2 "AUTH_KEY" stage2-post-reboot.sh || true
            echo "🔍 Environment variable contents:"
            echo "TAILSCALE_AUTH_KEY length: ${#TAILSCALE_AUTH_KEY}"
            echo "TAILSCALE_AUTH_KEY starts with: ${TAILSCALE_AUTH_KEY:0:20}..."
            echo "🔍 Full script content around placeholders:"
            grep -n "PLACEHOLDER" stage2-post-reboot.sh || echo "No remaining placeholders found"
            exit 1
          else
            echo "✅ Tailscale auth key placeholder replaced successfully"
          fi
          
          # Also verify stage1 replacements
          if grep -q "TAILSCALE_AUTH_KEY_PLACEHOLDER" stage1-setup.sh; then
            echo "❌ TAILSCALE_AUTH_KEY placeholder not replaced in stage1!"
            exit 1
          else
            echo "✅ Stage1 script placeholders replaced successfully"
          fi
          
          # Upload both scripts
          scp -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no stage1-setup.sh root@${{ steps.create-server.outputs.server_ip }}:/tmp/
          scp -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no stage2-post-reboot.sh root@${{ steps.create-server.outputs.server_ip }}:/usr/local/bin/
          
          # Execute stage 1 setup
          ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "chmod +x /tmp/stage1-setup.sh && chmod +x /usr/local/bin/stage2-post-reboot.sh && /tmp/stage1-setup.sh"
          
          STAGE1_STATUS=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "cat /tmp/stage1_status" || echo "unknown")
          echo "stage1_status=$STAGE1_STATUS" >> $GITHUB_OUTPUT

      - name: 🔄 Reboot Server for Kernel Updates
        run: |
          echo "🔄 Rebooting server for kernel updates and service initialization..."
          ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "reboot" || true
          
          echo "⏳ Waiting for server to come back online..."
          sleep 45  # Give more time for reboot
          
          # Wait for SSH to be available again
          for i in {1..20}; do
            if ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no -o ConnectTimeout=10 root@${{ steps.create-server.outputs.server_ip }} "echo 'SSH ready after reboot'"; then
              echo "✅ Server is back online after reboot"
              break
            fi
            echo "Attempt $i/20: Waiting for server to come back online..."
            sleep 15
          done

      - name: 🏗️ Stage 2 - Post-Reboot Verification
        id: stage2-setup
        run: |
          echo "🏗️ Stage 2: Verifying post-reboot setup..."
          
          # Wait for SSH to be available after reboot (servers take time to reboot)
          echo "⏳ Waiting for server to come back online after reboot..."
          SSH_READY=false
          
          for i in {1..20}; do
            echo "Attempt $i/20: Testing SSH connection after reboot..."
            
            if timeout 10 ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no -o ConnectTimeout=5 \
               root@${{ steps.create-server.outputs.server_ip }} "echo 'SSH ready after reboot'" 2>/dev/null; then
              echo "✅ SSH ready after reboot (attempt $i)"
              SSH_READY=true
              break
            fi
            sleep 15  # Wait longer between attempts for reboot
          done
          
          if [[ "$SSH_READY" != "true" ]]; then
            echo "❌ SSH failed to become ready after reboot"
            exit 1
          fi
          
          # Debug: Check if stage2 service exists and was enabled
          echo "🔍 Debugging stage2-setup.service status..."
          ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "
            echo '📋 Checking systemd service files:'
            ls -la /etc/systemd/system/stage2-setup.service || echo 'Service file not found'
            echo ''
            echo '📋 Service enabled status:'
            systemctl is-enabled stage2-setup.service || echo 'Service not enabled'
            echo ''
            echo '📋 Service status details:'
            systemctl status stage2-setup.service --no-pager || echo 'Service status unavailable'
            echo ''
            echo '📋 Recent systemd logs:'
            journalctl -u stage2-setup.service --no-pager -l --since='10 minutes ago' || echo 'No logs available'
          " || true
          
          # Quick check if Tailscale is already working
          echo "🔍 Quick Tailscale connectivity check..."
          QUICK_TAILSCALE_CHECK=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
            "timeout 10 tailscale status 2>/dev/null | grep -q 'Logged in' && echo 'connected' || echo 'checking'" || echo "checking")
          
          if [[ "$QUICK_TAILSCALE_CHECK" == "connected" ]]; then
            echo "✅ Tailscale is already connected - skipping service wait"
            SKIP_SERVICE_WAIT=true
          else
            echo "⏳ Tailscale not yet ready - will monitor service completion"
            SKIP_SERVICE_WAIT=false
          fi
          
          # Wait for Stage 2 systemd service to complete (only if Tailscale not already connected)
          if [[ "$SKIP_SERVICE_WAIT" != "true" ]]; then
            echo "⏳ Waiting for stage2-setup.service to complete..."
            for i in {1..8}; do  # Reduced to 2 minutes (8 * 15s) since it's usually quick
              SERVICE_STATUS=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
                "systemctl is-active stage2-setup.service 2>/dev/null || echo 'inactive'")
              
              echo "Attempt $i/8: Stage 2 service status: $SERVICE_STATUS"
              
              # Check Tailscale status during wait
              TAILSCALE_READY=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
                "timeout 5 tailscale status 2>/dev/null | grep -q 'Logged in' && echo 'ready' || echo 'pending'" || echo "pending")
              
              if [[ "$TAILSCALE_READY" == "ready" ]]; then
                echo "✅ Tailscale is connected - service completed successfully"
                break
              fi
              
              # For oneshot services: inactive means it completed (successfully or failed)
              if [[ "$SERVICE_STATUS" == "inactive" ]]; then
                # Check if it completed successfully
                EXIT_STATUS=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
                  "systemctl show stage2-setup.service --property=ExecMainStatus --value 2>/dev/null || echo 'unknown'")
                
                if [[ "$EXIT_STATUS" == "0" ]]; then
                  echo "✅ Stage 2 service completed successfully"
                  break
                else
                  echo "⚠️ Stage 2 service completed with exit status: $EXIT_STATUS"
                  echo "🔍 Checking if Tailscale connected anyway..."
                  FINAL_CHECK=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
                    "timeout 5 tailscale status 2>/dev/null | grep -q 'Logged in' && echo 'connected' || echo 'failed'")
                  
                  if [[ "$FINAL_CHECK" == "connected" ]]; then
                    echo "✅ Tailscale is connected despite service exit status - continuing"
                    break
                  else
                    # Show logs for debugging
                    echo "🔍 Stage 2 service logs:"
                    ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
                      "journalctl -u stage2-setup.service --no-pager -l --since='5 minutes ago'" || true
                    break
                  fi
                fi
              fi
              
              sleep 15
            done
          else
            echo "⚡ Skipped service wait - Tailscale already operational"
          fi
          
          # Smart stage2 completion check
          echo "🔧 Verifying deployment completion..."
          TAILSCALE_STATUS=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
            "timeout 10 tailscale status 2>/dev/null | grep -q 'Logged in' && echo 'connected' || echo 'not-connected'")
          
          if [[ "$TAILSCALE_STATUS" == "connected" ]]; then
            echo "✅ Tailscale is connected and operational"
            
            # Quick verification of key services
            echo "🔍 Verifying core services..."
            DOCKER_STATUS=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
              "systemctl is-active docker 2>/dev/null || echo 'inactive'")
            echo "Docker status: $DOCKER_STATUS"
            
            if [[ "$DOCKER_STATUS" == "active" ]]; then
              echo "✅ All core services are operational"
            else
              echo "⚠️ Docker not active, but continuing since Tailscale is connected"
            fi
          else
            echo "⚠️ Tailscale not connected - attempting manual stage2 trigger..."
            ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
              "timeout 60 /usr/local/bin/stage2-post-reboot.sh || echo 'Manual stage2 execution completed with timeout/error'" || true
            
            # Recheck after manual trigger
            TAILSCALE_STATUS=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
              "timeout 10 tailscale status 2>/dev/null | grep -q 'Logged in' && echo 'connected' || echo 'not-connected'")
            
            if [[ "$TAILSCALE_STATUS" == "connected" ]]; then
              echo "✅ Manual trigger successful - Tailscale now connected"
            else
              echo "❌ Manual trigger failed - Tailscale still not connected"
            fi
          fi
          
          # Get Tailscale IP (multiple methods)
          TAILSCALE_IP=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
            "tailscale ip -4 2>/dev/null || cat /tmp/tailscale_ip 2>/dev/null || echo 'pending'")
          echo "🔗 Tailscale IP: $TAILSCALE_IP"
          echo "tailscale_ip=$TAILSCALE_IP" >> $GITHUB_OUTPUT
          
          # Verify essential services
          echo "🔍 Verifying essential services..."
          ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
            "systemctl is-active docker && echo '✅ Docker is active'" || echo "⚠️ Docker may not be active"
          
  # ============================================================================
  # Deploy Service Application  
  # ============================================================================
  deploy-service:
    name: 🚀 Deploy Service
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [preflight-checks, setup-infrastructure]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_deploy == 'true' &&
      needs.setup-infrastructure.result == 'success'
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 🚀 Deploy Service to Server
        run: |
          echo "🚀 Deploying ${{ env.SERVICE_NAME }} service..."
          echo "Server IP: ${{ needs.setup-infrastructure.outputs.server_ip }}"
          echo "Tailscale IP: ${{ needs.setup-infrastructure.outputs.tailscale_ip }}"
          
          # Debug: Check if SSH key output exists
          if [[ -z "${{ needs.setup-infrastructure.outputs.ssh_private_key }}" ]]; then
            echo "❌ SSH private key output is empty"
            echo "🔍 Available outputs from setup-infrastructure:"
            echo "  server_ip: ${{ needs.setup-infrastructure.outputs.server_ip }}"
            echo "  server_id: ${{ needs.setup-infrastructure.outputs.server_id }}"
            echo "  tailscale_ip: ${{ needs.setup-infrastructure.outputs.tailscale_ip }}"
            exit 1
          fi
          
          # Ensure .ssh directory exists and decode SSH private key for deployment
          mkdir -p ~/.ssh
          echo "${{ needs.setup-infrastructure.outputs.ssh_private_key }}" | base64 -d > ~/.ssh/deployment_key
          chmod 600 ~/.ssh/deployment_key
          
          # Verify the key was created successfully
          if [[ ! -f ~/.ssh/deployment_key ]]; then
            echo "❌ Failed to create SSH deployment key"
            exit 1
          fi
          echo "✅ SSH deployment key created successfully"
          
          # Clone service repository to server
          echo "📥 Cloning ${{ env.SERVICE_NAME }} repository..."
          ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no root@${{ needs.setup-infrastructure.outputs.server_ip }} "
            cd /home/${{ env.SERVICE_NAME }}_user || cd /home
            
            # Clone the service repository
            if [[ ! -d '${{ env.SERVICE_NAME }}' ]]; then
              echo 'Cloning ${{ env.SERVICE_NAME }} repository...'
              git clone https://github.com/${{ github.repository_owner }}/${{ env.SERVICE_NAME }}.git || {
                echo 'Repository clone failed, creating basic structure...'
                mkdir -p ${{ env.SERVICE_NAME }}
                cd ${{ env.SERVICE_NAME }}
                echo 'version: \"3.8\"' > docker-compose.yml
                echo 'services:' >> docker-compose.yml
                echo '  app:' >> docker-compose.yml  
                echo '    image: nginx:alpine' >> docker-compose.yml
                echo '    ports:' >> docker-compose.yml
                echo '      - \"80:80\"' >> docker-compose.yml
                echo '    networks:' >> docker-compose.yml
                echo '      - ${{ env.SERVICE_NAME }}-network' >> docker-compose.yml
                echo 'networks:' >> docker-compose.yml
                echo '  ${{ env.SERVICE_NAME }}-network:' >> docker-compose.yml
                echo '    external: true' >> docker-compose.yml
              }
            fi
            
            cd ${{ env.SERVICE_NAME }}
            
            # Update repository if it exists
            git pull origin main 2>/dev/null || echo 'No updates available'
            
            # Set ownership to service user
            chown -R ${{ env.SERVICE_NAME }}_user:${{ env.SERVICE_NAME }}_user /home/${{ env.SERVICE_NAME }}_user/${{ env.SERVICE_NAME }} 2>/dev/null || true
          "
          
          # Deploy the service based on its type
          echo "🐳 Starting service deployment..."
          ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no root@${{ needs.setup-infrastructure.outputs.server_ip }} "
            cd /home/${{ env.SERVICE_NAME }}_user/${{ env.SERVICE_NAME }} || cd /home/${{ env.SERVICE_NAME }}
            
            # Determine deployment method
            if [[ -f 'docker-compose.yml' ]]; then
              echo '🐳 Deploying with Docker Compose...'
              
              # Stop existing containers
              docker-compose down 2>/dev/null || true
              
              # Pull latest images
              docker-compose pull 2>/dev/null || echo 'Pull skipped'
              
              # Start services
              docker-compose up -d
              
              echo '✅ Docker Compose deployment completed'
            elif [[ -f 'start.sh' ]]; then
              echo '📜 Deploying with start script...'
              chmod +x start.sh
              ./start.sh
              echo '✅ Script deployment completed'
            elif [[ -f 'deploy.sh' ]]; then
              echo '📜 Deploying with deploy script...'
              chmod +x deploy.sh
              ./deploy.sh
              echo '✅ Deploy script completed'
            else
              echo '⚠️ No recognized deployment method found'
              echo 'Creating basic nginx service...'
              
              # Create a basic nginx container if no deployment method is found
              docker run -d \
                --name ${{ env.SERVICE_NAME }}-app \
                --restart unless-stopped \
                --network ${{ env.SERVICE_NAME }}-network \
                -p 80:80 \
                nginx:alpine
              
              echo '✅ Basic service deployment completed'
            fi
          "
          
          # Verify deployment
          echo "🔍 Verifying service deployment..."
          DEPLOYMENT_SUCCESS=false
          for i in {1..5}; do
            if ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no root@${{ needs.setup-infrastructure.outputs.server_ip }} "docker ps | grep -q '${{ env.SERVICE_NAME }}' || systemctl is-active ${{ env.SERVICE_NAME }} 2>/dev/null"; then
              echo "✅ Service is running (attempt $i)"
              DEPLOYMENT_SUCCESS=true
              break
            fi
            echo "Attempt $i/5: Waiting for service to start..."
            sleep 10
          done
          
          if [[ "$DEPLOYMENT_SUCCESS" == "true" ]]; then
            echo "✅ ${{ env.SERVICE_NAME }} service deployment completed successfully"
          else
            echo "⚠️ Service deployment may have issues - check server logs"
          fi

  # ============================================================================
  # Health Checks
  # ============================================================================
  health-check:
    name: 🏥 Health Check
    runs-on: ubuntu-latest
    needs: [preflight-checks, setup-infrastructure, deploy-service]
    if: |
      always() && 
      (needs.preflight-checks.outputs.should_health_check == 'true' || 
       (needs.preflight-checks.outputs.should_deploy == 'true' && needs.deploy-service.result == 'success'))
    
    steps:
      - name: 🏥 Perform Health Checks
        run: |
          echo "🏥 Running comprehensive health checks for ${{ env.SERVICE_NAME }}..."
          
          if [[ -n "${{ needs.setup-infrastructure.outputs.server_ip }}" ]]; then
            SERVER_IP="${{ needs.setup-infrastructure.outputs.server_ip }}"
            TAILSCALE_IP="${{ needs.setup-infrastructure.outputs.tailscale_ip }}"
            
            # Ensure .ssh directory exists and decode SSH key for health checks
            mkdir -p ~/.ssh
            echo "${{ needs.setup-infrastructure.outputs.ssh_private_key }}" | base64 -d > ~/.ssh/deployment_key
            chmod 600 ~/.ssh/deployment_key
            
            # Verify the key was created successfully
            if [[ ! -f ~/.ssh/deployment_key ]]; then
              echo "❌ Failed to create SSH deployment key for health checks"
              exit 1
            fi
            echo "✅ SSH deployment key created successfully for health checks"
            
            echo "🔍 1. Basic connectivity tests..."
            # Basic connectivity test
            if ping -c 3 "$SERVER_IP" >/dev/null 2>&1; then
              echo "✅ Server ping successful"
            else
              echo "⚠️ Server ping failed"
            fi
            
            # SSH connectivity test
            if ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no -o ConnectTimeout=10 root@"$SERVER_IP" "echo 'SSH OK'"; then
              echo "✅ SSH connection successful"
            else
              echo "❌ SSH connection failed"
              exit 1
            fi
            
            echo "🔍 2. Service health checks..."
            # Check if Docker is running
            DOCKER_STATUS=$(ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no root@"$SERVER_IP" "systemctl is-active docker 2>/dev/null || echo 'inactive'")
            if [[ "$DOCKER_STATUS" == "active" ]]; then
              echo "✅ Docker service is running"
            else
              echo "❌ Docker service is not running: $DOCKER_STATUS"
            fi
            
            # Check if Tailscale is connected
            TAILSCALE_STATUS=$(ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no root@"$SERVER_IP" "tailscale status --self --peers=false 2>/dev/null | head -1" || echo "not connected")
            if echo "$TAILSCALE_STATUS" | grep -q "online"; then
              echo "✅ Tailscale is connected"
            else
              echo "⚠️ Tailscale status: $TAILSCALE_STATUS"
            fi
            
            echo "🔍 3. Service-specific health checks..."
            # Check if service containers are running
            RUNNING_CONTAINERS=$(ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no root@"$SERVER_IP" "docker ps --format 'table {{.Names}}\t{{.Status}}' | grep '${{ env.SERVICE_NAME }}' || echo 'none'")
            if [[ "$RUNNING_CONTAINERS" != "none" ]]; then
              echo "✅ Service containers are running:"
              echo "$RUNNING_CONTAINERS"
            else
              echo "⚠️ No service containers found running"
            fi
            
            # Check network connectivity
            echo "🔍 4. Network connectivity tests..."
            # Test HTTP connectivity (if service exposes port 80)
            if timeout 10 curl -s -o /dev/null -w "%{http_code}" "http://$SERVER_IP" | grep -E "^[2-3][0-9][0-9]$"; then
              echo "✅ HTTP service is responding"
            else
              echo "ℹ️ HTTP service not responding on port 80 (may be normal)"
            fi
            
            # Test Tailscale IP connectivity if available
            if [[ "$TAILSCALE_IP" != "pending" && -n "$TAILSCALE_IP" ]]; then
              if timeout 5 ping -c 1 "$TAILSCALE_IP" >/dev/null 2>&1; then
                echo "✅ Tailscale IP is reachable: $TAILSCALE_IP"
              else
                echo "⚠️ Tailscale IP not reachable: $TAILSCALE_IP"
              fi
            fi
            
            echo "🔍 5. Resource health checks..."
            # Check system resources
            SYSTEM_INFO=$(ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no root@"$SERVER_IP" "
              echo 'CPU:' \$(nproc) 'cores'
              echo 'RAM:' \$(free -h | awk '/^Mem:/ {print \$2}' | head -1)
              echo 'Disk:' \$(df -h / | awk 'NR==2 {print \$4}' | head -1) 'free'
              echo 'Uptime:' \$(uptime -p)
            ")
            echo "📊 System resources:"
            echo "$SYSTEM_INFO"
            
            echo "🔍 6. DNS verification checks..."
            # Check if DNS record was updated correctly
            if [[ -n "${{ secrets.CLOUDFLARE_EMAIL }}" && -n "${{ secrets.CLOUDFLARE_API_TOKEN }}" ]]; then
              echo "🌐 Verifying DNS record for ${{ env.FULL_DOMAIN }}..."
              
              # Check DNS resolution
              DNS_RESULT=$(dig +short "${{ env.FULL_DOMAIN }}" A 2>/dev/null | head -1 || echo "")
              if [[ -n "$DNS_RESULT" ]]; then
                if [[ "$DNS_RESULT" == "$TAILSCALE_IP" ]]; then
                  echo "✅ DNS record correct: ${{ env.FULL_DOMAIN }} -> $DNS_RESULT"
                else
                  echo "⚠️ DNS record mismatch: ${{ env.FULL_DOMAIN }} -> $DNS_RESULT (expected: $TAILSCALE_IP)"
                  echo "ℹ️ DNS propagation may still be in progress"
                fi
              else
                echo "⚠️ DNS record not found for ${{ env.FULL_DOMAIN }}"
              fi
            else
              echo "ℹ️ Cloudflare credentials not available - skipping DNS verification"
            fi
            
            echo "✅ Health checks completed for ${{ env.SERVICE_NAME }}"
          else
            echo "⚠️ No server IP available for health checks"
          fi

  # ============================================================================
  # Summary Report
  # ============================================================================
  deployment-summary:
    name: 📋 Deployment Summary
    runs-on: ubuntu-latest
    needs: [preflight-checks, setup-infrastructure, deploy-service, health-check]
    if: always()
    
    steps:
      - name: 📋 Generate Deployment Report
        run: |
          echo "📋 Deployment Summary for ${{ env.SERVICE_NAME }}"
          echo "=================================================="
          echo "🎯 Action: ${{ env.ACTION_TYPE }}"
          echo "🖥️  Server Type: ${{ env.SERVER_TYPE }}"
          echo "🌍 Region: ${{ env.TARGET_REGION }}"
          echo "🔗 Domain: ${{ env.FULL_DOMAIN }}"
          echo ""
          
          # Job Status Summary
          echo "📊 Job Results:"
          echo "✅ Preflight Checks: ${{ needs.preflight-checks.result }}"
          echo "🏗️  Infrastructure: ${{ needs.setup-infrastructure.result }}"
          echo "🚀 Service Deploy: ${{ needs.deploy-service.result }}"
          echo "🏥 Health Check: ${{ needs.health-check.result }}"
          echo ""
          
          # Server Information
          if [[ "${{ needs.setup-infrastructure.result }}" == "success" ]]; then
            echo "🖥️  Server Details:"
            echo "   📍 Public IP: ${{ needs.setup-infrastructure.outputs.server_ip }}"
            echo "   🔗 Tailscale IP: ${{ needs.setup-infrastructure.outputs.tailscale_ip }}"
            echo "   🆔 Server ID: ${{ needs.setup-infrastructure.outputs.server_id }}"
            echo ""
          fi
          
          # Overall Status
          if [[ "${{ needs.setup-infrastructure.result }}" == "success" && 
                ("${{ needs.deploy-service.result }}" == "success" || "${{ needs.deploy-service.result }}" == "skipped") ]]; then
            echo "🎉 Overall Status: SUCCESS"
            echo "✅ ${{ env.SERVICE_NAME }} deployment completed successfully!"
          else
            echo "❌ Overall Status: FAILED"
            echo "💥 Deployment encountered errors - check job logs for details"
          fi
