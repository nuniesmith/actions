name: üöÄ Unified Service Management

on:
  workflow_call:
    inputs:
      service_name:
        description: 'Name of the service to manage (e.g., fks, nginx, ats)'
        required: true
        type: string
      
      action_type:
        description: 'Action to perform'
        required: false
        type: string
        default: 'deploy'
        # Options: deploy, destroy, health-check, restart
      
      deployment_mode:
        description: 'Deployment mode'
        required: false
        type: string
        default: 'full-deploy'
        # Options: full-deploy, update-only, restart-only, code-only
      
      # üéØ New Options You Requested
      skip_tests:
        description: 'Skip running code tests'
        required: false
        type: boolean
        default: false
      
      skip_docker_build:
        description: 'Skip building Docker images'
        required: false
        type: boolean
        default: false
      
      build_docker_on_changes:
        description: 'Only build Docker if code/Dockerfile changed'
        required: false
        type: boolean
        default: true
      
      overwrite_server:
        description: 'Destroy and recreate Linode server'
        required: false
        type: boolean
        default: false
      
      # Server Configuration
      server_type:
        description: 'Linode server type'
        required: false
        type: string
        default: 'g6-standard-2'
      
      target_region:
        description: 'Linode region'
        required: false
        type: string
        default: 'ca-central'
      
      domain_suffix:
        description: 'Domain suffix (e.g., 7gram.xyz)'
        required: false
        type: string
        default: '7gram.xyz'
      
      # Feature Toggles
      enable_monitoring:
        description: 'Enable Netdata monitoring'
        required: false
        type: boolean
        default: true
      
      enable_backups:
        description: 'Enable Linode backups'
        required: false
        type: boolean
        default: false
      
      # Destroy Options (for destroy action)
      destroy_scope:
        description: 'What to destroy (for destroy action)'
        required: false
        type: string
        default: 'service-only'
      
      confirm_destruction:
        description: 'Type "DESTROY" to confirm destruction'
        required: false
        type: string

    secrets:
      # Core Infrastructure
      LINODE_CLI_TOKEN:
        required: true
      SERVICE_ROOT_PASSWORD:
        required: true
      
      # User Management
      JORDAN_PASSWORD:
        required: true
      ACTIONS_USER_PASSWORD:
        required: true
      
      # VPN & Networking
      TAILSCALE_AUTH_KEY:
        required: true
      TAILSCALE_TAILNET:
        description: 'Tailscale tailnet name (optional)'
        required: false
      
      # Monitoring (Optional)
      NETDATA_CLAIM_TOKEN:
        required: false
      NETDATA_CLAIM_ROOM:
        required: false
      
      # DNS Management (Optional)
      CLOUDFLARE_API_TOKEN:
        required: false
      CLOUDFLARE_ZONE_ID:
        required: false
      
      # Container Registry (Optional)
      DOCKER_USERNAME:
        required: false
      DOCKER_TOKEN:
        required: false
      
      # Notifications (Optional)
      DISCORD_WEBHOOK:
        required: false

    outputs:
      # Infrastructure outputs
      server_ip:
        description: 'Public IP address of the deployed server'
        value: ${{ jobs.setup-infrastructure.outputs.server_ip }}
      server_id:
        description: 'Linode server ID'
        value: ${{ jobs.setup-infrastructure.outputs.server_id }}
      tailscale_ip:
        description: 'Tailscale IP address of the server'
        value: ${{ jobs.setup-infrastructure.outputs.tailscale_ip }}

  workflow_dispatch:
    inputs:
      service_name:
        description: 'Name of the service to manage'
        required: true
        type: choice
        options:
          - 'fks'
          - 'nginx'
          - 'ats'
          - 'custom'
      
      action_type:
        description: 'Action to perform'
        required: true
        type: choice
        options:
          - 'deploy'
          - 'destroy'
          - 'health-check'
          - 'restart'
        default: 'deploy'
      
      deployment_mode:
        description: 'Deployment mode (for deploy action)'
        required: false
        type: choice
        options:
          - 'full-deploy'
          - 'update-only'
          - 'restart-only'
          - 'code-only'
        default: 'full-deploy'
      
      # üéØ Your Requested Options
      skip_tests:
        description: 'Skip running code tests'
        required: false
        type: boolean
        default: false
      
      skip_docker_build:
        description: 'Skip building Docker images'
        required: false
        type: boolean
        default: false
      
      build_docker_on_changes:
        description: 'Only build Docker if code/Dockerfile changed'
        required: false
        type: boolean
        default: true
      
      overwrite_server:
        description: 'Destroy and recreate Linode server'
        required: false
        type: boolean
        default: false
      
      # Destroy Options (for destroy action)
      destroy_scope:
        description: 'What to destroy (for destroy action)'
        required: false
        type: choice
        options:
          - 'service-only'
          - 'full-server'
          - 'reset-service'
        default: 'service-only'
      
      confirm_destruction:
        description: 'Type "DESTROY" to confirm destruction'
        required: false
        type: string
      
      # Server Configuration
      server_type:
        description: 'Linode server type'
        required: false
        type: choice
        options:
          - 'g6-nanode-1'          # 1GB RAM
          - 'g6-standard-1'        # 2GB RAM
          - 'g6-standard-2'        # 4GB RAM
          - 'g6-standard-4'        # 8GB RAM
          - 'g6-standard-8'        # 16GB RAM
        default: 'g6-standard-2'

env:
  SERVICE_NAME: ${{ inputs.service_name }}
  ACTION_TYPE: ${{ inputs.action_type }}
  DEPLOYMENT_MODE: ${{ inputs.deployment_mode }}
  SERVER_TYPE: ${{ inputs.server_type }}
  TARGET_REGION: ${{ inputs.target_region || 'ca-central' }}
  DOMAIN_SUFFIX: ${{ inputs.domain_suffix || '7gram.xyz' }}
  FULL_DOMAIN: ${{ inputs.service_name }}.${{ inputs.domain_suffix || '7gram.xyz' }}
  
  # Your requested options
  SKIP_TESTS: ${{ inputs.skip_tests }}
  SKIP_DOCKER_BUILD: ${{ inputs.skip_docker_build }}
  BUILD_DOCKER_ON_CHANGES: ${{ inputs.build_docker_on_changes }}
  OVERWRITE_SERVER: ${{ inputs.overwrite_server }}

jobs:
  # ============================================================================
  # Pre-flight Checks & Validation
  # ============================================================================
  preflight-checks:
    name: üõ´ Pre-flight Checks
    runs-on: ubuntu-latest
    outputs:
      action_validated: ${{ steps.validate-action.outputs.validated }}
      should_destroy: ${{ steps.validate-action.outputs.should_destroy }}
      should_deploy: ${{ steps.validate-action.outputs.should_deploy }}
      should_health_check: ${{ steps.validate-action.outputs.should_health_check }}
      should_overwrite_server: ${{ steps.validate-action.outputs.should_overwrite_server }}
      destroy_confirmed: ${{ steps.validate-destroy.outputs.confirmed }}
      code_changed: ${{ steps.check-changes.outputs.code_changed }}
      docker_build_needed: ${{ steps.check-changes.outputs.docker_build_needed }}
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch full history for change detection

      - name: üéØ Validate Action Type
        id: validate-action
        run: |
          echo "üéØ Validating action: ${{ env.ACTION_TYPE }}"
          
          case "${{ env.ACTION_TYPE }}" in
            "deploy")
              echo "should_deploy=true" >> $GITHUB_OUTPUT
              echo "should_destroy=false" >> $GITHUB_OUTPUT
              echo "should_health_check=false" >> $GITHUB_OUTPUT
              ;;
            "destroy")
              echo "should_deploy=false" >> $GITHUB_OUTPUT
              echo "should_destroy=true" >> $GITHUB_OUTPUT
              echo "should_health_check=false" >> $GITHUB_OUTPUT
              ;;
            "health-check")
              echo "should_deploy=false" >> $GITHUB_OUTPUT
              echo "should_destroy=false" >> $GITHUB_OUTPUT
              echo "should_health_check=true" >> $GITHUB_OUTPUT
              ;;
            "restart")
              echo "should_deploy=true" >> $GITHUB_OUTPUT
              echo "should_destroy=false" >> $GITHUB_OUTPUT
              echo "should_health_check=false" >> $GITHUB_OUTPUT
              ;;
            *)
              echo "‚ùå Invalid action type: ${{ env.ACTION_TYPE }}"
              exit 1
              ;;
          esac
          
          # Check if server should be overwritten
          if [[ "${{ env.OVERWRITE_SERVER }}" == "true" && "${{ env.ACTION_TYPE }}" == "deploy" ]]; then
            echo "should_overwrite_server=true" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è Server will be overwritten (destroyed and recreated)"
          else
            echo "should_overwrite_server=false" >> $GITHUB_OUTPUT
          fi
          
          echo "validated=true" >> $GITHUB_OUTPUT

      - name: ‚ö†Ô∏è Validate Destruction Request
        id: validate-destroy
        if: steps.validate-action.outputs.should_destroy == 'true' || steps.validate-action.outputs.should_overwrite_server == 'true'
        run: |
          # For server overwrite during deployment, skip confirmation requirement
          if [[ "${{ steps.validate-action.outputs.should_overwrite_server }}" == "true" && "${{ env.ACTION_TYPE }}" == "deploy" ]]; then
            echo "‚úÖ Server overwrite confirmed (deploy mode)"
            echo "confirmed=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # For explicit destroy actions, require confirmation
          if [[ "${{ inputs.confirm_destruction }}" != "DESTROY" ]]; then
            echo "‚ùå Destruction not confirmed. You must type 'DESTROY' exactly."
            echo "confirmed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "‚úÖ Destruction confirmed for ${{ env.SERVICE_NAME }}"
          echo "confirmed=true" >> $GITHUB_OUTPUT

      - name: üîç Check for Code Changes
        id: check-changes
        if: steps.validate-action.outputs.should_deploy == 'true'
        run: |
          echo "üîç Checking for code and Docker changes..."
          
          # TEMPORARY: Force Docker builds for all services since DockerHub images were cleared
          echo "üîÑ FORCING Docker builds - DockerHub images were cleared"
          echo "code_changed=true" >> $GITHUB_OUTPUT
          echo "docker_build_needed=true" >> $GITHUB_OUTPUT
          
          # TODO: Re-enable change detection later by uncommenting the logic below
          # and removing the forced build logic above
          
          # Check if this is the first commit or if we should build anyway
          #if [[ $(git rev-list --count HEAD) -le 1 ]] || [[ "${{ env.BUILD_DOCKER_ON_CHANGES }}" == "false" ]]; then
          #  echo "First commit or change detection disabled - assuming changes exist"
          #  echo "code_changed=true" >> $GITHUB_OUTPUT
          #  echo "docker_build_needed=true" >> $GITHUB_OUTPUT
          #else
          #  # Check for changes in the last commit
          #  CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD)
          #  echo "Changed files: $CHANGED_FILES"
          #  
          #  # Check if code files changed (exclude docs, configs, etc.)
          #  CODE_CHANGED="false"
          #  if echo "$CHANGED_FILES" | grep -E '\.(js|ts|py|go|java|cpp|c|rs|php)$' > /dev/null; then
          #    CODE_CHANGED="true"
          #    echo "‚úÖ Code files changed"
          #  fi
          #  
          #  # Check if Docker-related files changed
          #  DOCKER_BUILD_NEEDED="false"
          #  if echo "$CHANGED_FILES" | grep -E '(Dockerfile|docker-compose|requirements|package\.json|go\.mod|Cargo\.toml)' > /dev/null; then
          #    DOCKER_BUILD_NEEDED="true"
          #    echo "‚úÖ Docker-related files changed"
          #  fi
          #  
          #  # If build_docker_on_changes is true, only build if changes detected
          #  if [[ "${{ env.BUILD_DOCKER_ON_CHANGES }}" == "true" ]]; then
          #    if [[ "$CODE_CHANGED" == "true" || "$DOCKER_BUILD_NEEDED" == "true" ]]; then
          #      DOCKER_BUILD_NEEDED="true"
          #    else
          #      DOCKER_BUILD_NEEDED="false"
          #      echo "‚ÑπÔ∏è No relevant changes detected - skipping Docker build"
          #    fi
          #  fi
          #  
          #  echo "code_changed=$CODE_CHANGED" >> $GITHUB_OUTPUT
          #  echo "docker_build_needed=$DOCKER_BUILD_NEEDED" >> $GITHUB_OUTPUT
          #fi

      - name: üîê Validate Secrets
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
          SERVICE_ROOT_PASSWORD: ${{ secrets.SERVICE_ROOT_PASSWORD }}
          JORDAN_PASSWORD: ${{ secrets.JORDAN_PASSWORD }}
          ACTIONS_USER_PASSWORD: ${{ secrets.ACTIONS_USER_PASSWORD }}
          TAILSCALE_AUTH_KEY: ${{ secrets.TAILSCALE_AUTH_KEY }}
          # SSL-related secrets (optional for nginx)
          CLOUDFLARE_EMAIL: ${{ secrets.CLOUDFLARE_EMAIL }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "üîê Validating required secrets..."
          
          MISSING_SECRETS=()
          [[ -z "$LINODE_CLI_TOKEN" ]] && MISSING_SECRETS+=("LINODE_CLI_TOKEN")
          [[ -z "$SERVICE_ROOT_PASSWORD" ]] && MISSING_SECRETS+=("SERVICE_ROOT_PASSWORD")
          [[ -z "$JORDAN_PASSWORD" ]] && MISSING_SECRETS+=("JORDAN_PASSWORD")
          [[ -z "$ACTIONS_USER_PASSWORD" ]] && MISSING_SECRETS+=("ACTIONS_USER_PASSWORD")
          [[ -z "$TAILSCALE_AUTH_KEY" ]] && MISSING_SECRETS+=("TAILSCALE_AUTH_KEY")
          
          if [[ ${#MISSING_SECRETS[@]} -gt 0 ]]; then
            echo "‚ùå Missing required secrets:"
            printf '  - %s\n' "${MISSING_SECRETS[@]}"
            exit 1
          fi
          
          echo "‚úÖ All required secrets validated"
          
          # Check SSL-related secrets for nginx deployments
          if [[ "${{ env.SERVICE_NAME }}" == "nginx" ]]; then
            SSL_SECRETS=()
            [[ -z "$CLOUDFLARE_EMAIL" ]] && SSL_SECRETS+=("CLOUDFLARE_EMAIL")
            [[ -z "$CLOUDFLARE_API_TOKEN" ]] && SSL_SECRETS+=("CLOUDFLARE_API_TOKEN")
            
            if [[ ${#SSL_SECRETS[@]} -gt 0 ]]; then
              echo "‚ö†Ô∏è SSL secrets missing (will use HTTP challenge or self-signed):"
              printf '  - %s\n' "${SSL_SECRETS[@]}"
              echo "üí° For wildcard certificates and better reliability, add:"
              echo "   - CLOUDFLARE_EMAIL (your Cloudflare account email)"
              echo "   - CLOUDFLARE_API_TOKEN (Cloudflare API token with DNS edit permissions)"
            else
              echo "‚úÖ SSL secrets available for DNS-01 challenge"
            fi
          fi

  # ============================================================================
  # Code Testing (Optional)
  # ============================================================================
  run-tests:
    name: üß™ Run Tests
    runs-on: ubuntu-latest
    needs: preflight-checks
    if: needs.preflight-checks.outputs.should_deploy == 'true' && inputs.skip_tests == false
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üß™ Auto-detect and Run Tests
        run: |
          echo "üß™ Auto-detecting test framework..."
          
          # Node.js/JavaScript tests
          if [[ -f "package.json" ]]; then
            echo "üì¶ Node.js project detected"
            if command -v npm &> /dev/null; then
              echo "Installing dependencies..."
              npm install
              
              if npm run test --if-present; then
                echo "‚úÖ Node.js tests passed"
              else
                echo "‚ö†Ô∏è Node.js tests failed or no test script found"
              fi
            fi
          fi
          
          # Python tests
          if [[ -f "requirements.txt" ]] || [[ -f "pyproject.toml" ]] || [[ -f "setup.py" ]]; then
            echo "üêç Python project detected"
            if command -v python3 &> /dev/null; then
              if [[ -f "requirements.txt" ]]; then
                pip install -r requirements.txt
              fi
              
              # Try different test runners
              if python -m pytest --version &> /dev/null && find . -name "*test*.py" | grep -q .; then
                echo "Running pytest..."
                python -m pytest
              elif python -m unittest discover -s . -p "*test*.py" 2>/dev/null; then
                echo "‚úÖ Python unittest tests passed"
              else
                echo "‚ÑπÔ∏è No Python tests found or test framework not available"
              fi
            fi
          fi
          
          # Go tests
          if [[ -f "go.mod" ]]; then
            echo "üî∑ Go project detected"
            if command -v go &> /dev/null; then
              go test ./...
              echo "‚úÖ Go tests passed"
            fi
          fi
          
          echo "‚úÖ Test phase complete"

  # ============================================================================
  # Docker Build (Conditional)
  # ============================================================================
  build-docker-api:
    name: üê≥ Build API Docker Images
    runs-on: ubuntu-latest
    needs: [preflight-checks, run-tests]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_deploy == 'true' && 
      inputs.skip_docker_build == false && 
      needs.preflight-checks.outputs.docker_build_needed == 'true' &&
      (needs.run-tests.result == 'success' || needs.run-tests.result == 'skipped')
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üîë Login to Docker Hub
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
          DOCKER_TOKEN: ${{ secrets.DOCKER_TOKEN }}
        if: env.DOCKER_USERNAME != '' && env.DOCKER_TOKEN != ''
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}

      - name: üê≥ Build and Push API Docker Images
        run: |
          echo "üê≥ Building API Docker images for ${{ env.SERVICE_NAME }}..."
          
          # Build API services (Python servers: api, worker, data)
          API_SERVICES=()
          
          # Check for API service configuration
          if [[ -f "docker-compose.api.yml" ]]; then
            echo "üìã Found docker-compose.api.yml - building API services"
            docker compose -f docker-compose.api.yml build
            
            if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
              echo "üì§ Pushing API compose images..."
              docker compose -f docker-compose.api.yml push || echo "‚ö†Ô∏è Some API images may not have push configured"
            fi
          elif [[ -f "docker-compose.yml" ]]; then
            # Build only API-related services from main compose file
            echo "üìã Building API services from main docker-compose.yml"
            
            # Extract API service names (common patterns: api, worker, data, backend)
            API_SERVICES=($(docker compose config --services 2>/dev/null | grep -E '^(api|worker|data|backend|server)$' || true))
            
            if [[ ${#API_SERVICES[@]} -gt 0 ]]; then
              echo "üîç Found API services: ${API_SERVICES[*]}"
              
              for service in "${API_SERVICES[@]}"; do
                echo "üê≥ Building service: $service"
                docker compose build "$service"
                
                if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
                  echo "üì§ Pushing service: $service"
                  docker compose push "$service" || echo "‚ö†Ô∏è Failed to push $service"
                fi
              done
            else
              echo "‚ÑπÔ∏è No API services found in docker-compose.yml"
            fi
          elif [[ -f "Dockerfile" ]]; then
            # Single Dockerfile - assume it's for API if service name suggests it
            if [[ "${{ env.SERVICE_NAME }}" =~ (api|backend|server) ]]; then
              echo "üìã Found Dockerfile - building as API service"
              
              IMAGE_TAG="${{ secrets.DOCKER_USERNAME }}/${{ env.SERVICE_NAME }}-api:latest"
              
              docker build -t "$IMAGE_TAG" .
              
              if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
                echo "üì§ Pushing image: $IMAGE_TAG"
                docker push "$IMAGE_TAG"
              fi
            else
              echo "‚ÑπÔ∏è Service doesn't appear to be API-focused - skipping API build"
            fi
          else
            echo "‚ÑπÔ∏è No Docker configuration found for API services"
          fi
          
          echo "‚úÖ API Docker build complete"

  build-docker-web:
    name: üåê Build Web Docker Images  
    runs-on: ubuntu-latest
    needs: [preflight-checks, run-tests]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_deploy == 'true' && 
      inputs.skip_docker_build == false && 
      needs.preflight-checks.outputs.docker_build_needed == 'true' &&
      (needs.run-tests.result == 'success' || needs.run-tests.result == 'skipped')
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üîë Login to Docker Hub
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
          DOCKER_TOKEN: ${{ secrets.DOCKER_TOKEN }}
        if: env.DOCKER_USERNAME != '' && env.DOCKER_TOKEN != ''
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}

      - name: üåê Build and Push Web Docker Images
        run: |
          echo "üåê Building Web Docker images for ${{ env.SERVICE_NAME }}..."
          
          # Build Web services (React web interface, frontend)
          WEB_SERVICES=()
          
          # Check for Web service configuration
          if [[ -f "docker-compose.web.yml" ]]; then
            echo "üìã Found docker-compose.web.yml - building Web services"
            docker compose -f docker-compose.web.yml build
            
            if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
              echo "üì§ Pushing Web compose images..."
              docker compose -f docker-compose.web.yml push || echo "‚ö†Ô∏è Some Web images may not have push configured"
            fi
          elif [[ -f "docker-compose.yml" ]]; then
            # Build only Web-related services from main compose file
            echo "üìã Building Web services from main docker-compose.yml"
            
            # Extract Web service names (common patterns: web, frontend, ui, client)
            WEB_SERVICES=($(docker compose config --services 2>/dev/null | grep -E '^(web|frontend|ui|client|app)$' || true))
            
            if [[ ${#WEB_SERVICES[@]} -gt 0 ]]; then
              echo "üîç Found Web services: ${WEB_SERVICES[*]}"
              
              for service in "${WEB_SERVICES[@]}"; do
                echo "üåê Building service: $service"
                docker compose build "$service"
                
                if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
                  echo "üì§ Pushing service: $service"
                  docker compose push "$service" || echo "‚ö†Ô∏è Failed to push $service"
                fi
              done
            else
              echo "‚ÑπÔ∏è No Web services found in docker-compose.yml"
            fi
          elif [[ -f "Dockerfile" ]]; then
            # Single Dockerfile - assume it's for Web if service name suggests it
            if [[ "${{ env.SERVICE_NAME }}" =~ (web|frontend|ui|client) ]]; then
              echo "üìã Found Dockerfile - building as Web service"
              
              IMAGE_TAG="${{ secrets.DOCKER_USERNAME }}/${{ env.SERVICE_NAME }}-web:latest"
              
              docker build -t "$IMAGE_TAG" .
              
              if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
                echo "üì§ Pushing image: $IMAGE_TAG"
                docker push "$IMAGE_TAG"
              fi
            else
              echo "‚ÑπÔ∏è Service doesn't appear to be Web-focused - skipping Web build"
            fi
          else
            echo "‚ÑπÔ∏è No Docker configuration found for Web services"
          fi
          
          echo "‚úÖ Web Docker build complete"

  build-docker-auth:
    name: üîê Build Auth Docker Images
    runs-on: ubuntu-latest
    needs: [preflight-checks, run-tests]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_deploy == 'true' && 
      inputs.skip_docker_build == false && 
      needs.preflight-checks.outputs.docker_build_needed == 'true' &&
      (needs.run-tests.result == 'success' || needs.run-tests.result == 'skipped')
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üîë Login to Docker Hub
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
          DOCKER_TOKEN: ${{ secrets.DOCKER_TOKEN }}
        if: env.DOCKER_USERNAME != '' && env.DOCKER_TOKEN != ''
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}

      - name: üîê Build and Push Auth Docker Images
        run: |
          echo "üîê Building Auth Docker images for ${{ env.SERVICE_NAME }}..."
          
          # Build Auth services (Authentication, authorization services)
          AUTH_SERVICES=()
          
          # Check for Auth service configuration
          if [[ -f "docker-compose.auth.yml" ]]; then
            echo "üìã Found docker-compose.auth.yml - building Auth services"
            docker compose -f docker-compose.auth.yml build
            
            if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
              echo "üì§ Pushing Auth compose images..."
              docker compose -f docker-compose.auth.yml push || echo "‚ö†Ô∏è Some Auth images may not have push configured"
            fi
          elif [[ -f "docker-compose.yml" ]]; then
            # Build only Auth-related services from main compose file
            echo "üìã Building Auth services from main docker-compose.yml"
            
            # Extract Auth service names (common patterns: auth, oauth, keycloak, etc.)
            AUTH_SERVICES=($(docker compose config --services 2>/dev/null | grep -E '^(auth|oauth|keycloak|identity|session)$' || true))
            
            if [[ ${#AUTH_SERVICES[@]} -gt 0 ]]; then
              echo "üîç Found Auth services: ${AUTH_SERVICES[*]}"
              
              for service in "${AUTH_SERVICES[@]}"; do
                echo "üîê Building service: $service"
                docker compose build "$service"
                
                if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
                  echo "üì§ Pushing service: $service"
                  docker compose push "$service" || echo "‚ö†Ô∏è Failed to push $service"
                fi
              done
            else
              echo "‚ÑπÔ∏è No Auth services found in docker-compose.yml - may use external auth services"
            fi
          else
            echo "‚ÑπÔ∏è No custom Auth services to build - likely using external authentication"
          fi
          
          echo "‚úÖ Auth Docker build complete (or skipped if no custom services)"

  # ============================================================================
  # Server Destruction (if overwrite requested)
  # ============================================================================
  destroy-existing-server:
    name: üí• Destroy Existing Server
    runs-on: ubuntu-latest
    needs: [preflight-checks, build-docker-api, build-docker-web, build-docker-auth]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_overwrite_server == 'true' &&
      needs.preflight-checks.outputs.destroy_confirmed == 'true' &&
      (needs.build-docker-api.result == 'success' || needs.build-docker-api.result == 'skipped') &&
      (needs.build-docker-web.result == 'success' || needs.build-docker-web.result == 'skipped') &&
      (needs.build-docker-auth.result == 'success' || needs.build-docker-auth.result == 'skipped')
    
    steps:
      - name: ÔøΩ Checkout repository
        uses: actions/checkout@v4

      - name: ÔøΩüîß Setup Linode CLI
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
        run: |
          pip install linode-cli
          # Configure via environment variable to avoid config file issues
          export LINODE_CLI_TOKEN="${{ secrets.LINODE_CLI_TOKEN }}"
          # Test CLI access
          linode-cli --version

      - name: üßπ Cleanup Services Before Destruction
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
          TAILSCALE_AUTH_KEY: ${{ secrets.TAILSCALE_AUTH_KEY }}
          TAILSCALE_TAILNET: ${{ secrets.TAILSCALE_TAILNET }}
        run: |
          echo "üßπ Cleaning up external service registrations..."
          
          # Install dependencies
          sudo apt-get update && sudo apt-get install -y curl jq sshpass >/dev/null 2>&1 || true
          
          # Find existing server
          EXISTING_SERVER=$(linode-cli linodes list --text --no-headers | grep "${{ env.SERVICE_NAME }}" | head -1)
          
          if [[ -n "$EXISTING_SERVER" ]]; then
            SERVER_ID=$(echo "$EXISTING_SERVER" | cut -f1)
            SERVER_LABEL=$(echo "$EXISTING_SERVER" | cut -f2)
            
            # Try to get server IP for cleanup
            SERVER_INFO=$(linode-cli linodes view "$SERVER_ID" --text --no-headers)
            SERVER_IP_COL4=$(echo "$SERVER_INFO" | cut -f4)
            SERVER_IP_COL5=$(echo "$SERVER_INFO" | cut -f5)
            SERVER_IP_COL6=$(echo "$SERVER_INFO" | cut -f6)
            SERVER_IP_COL7=$(echo "$SERVER_INFO" | cut -f7)
            
            SERVER_IP=""
            for IP in "$SERVER_IP_COL4" "$SERVER_IP_COL5" "$SERVER_IP_COL6" "$SERVER_IP_COL7"; do
              if [[ "$IP" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
                SERVER_IP="$IP"
                break
              fi
            done
            
            if [[ -n "$SERVER_IP" ]]; then
              echo "üîç Found server to cleanup: $SERVER_LABEL ($SERVER_IP)"
              
              # Try to connect using password authentication for cleanup
              echo "üîó Attempting cleanup connection via password auth..."
              
              # Try to connect and cleanup using root password
              if timeout 30 sshpass -p "${{ secrets.SERVICE_ROOT_PASSWORD }}" ssh -o StrictHostKeyChecking=no -o ConnectTimeout=10 root@$SERVER_IP "echo 'Cleanup connection successful'" 2>/dev/null; then
                echo "üîó Connected to server for cleanup..."
                
                # Cleanup Tailscale device
                echo "üßπ Removing Tailscale device from network..."
                sshpass -p "${{ secrets.SERVICE_ROOT_PASSWORD }}" ssh -o StrictHostKeyChecking=no root@$SERVER_IP "tailscale logout 2>/dev/null || true" || true
                
                # Get device info before cleanup
                DEVICE_NAME=$(sshpass -p "${{ secrets.SERVICE_ROOT_PASSWORD }}" ssh -o StrictHostKeyChecking=no root@$SERVER_IP "hostname 2>/dev/null || echo '${{ env.SERVICE_NAME }}'" || echo "${{ env.SERVICE_NAME }}")
                echo "Device name for cleanup: $DEVICE_NAME"
                
                echo "‚úÖ Service cleanup completed"
              else
                echo "‚ö†Ô∏è Could not connect to server for cleanup (server may be down, password changed, or SSH not configured)"
                echo "‚ÑπÔ∏è This is normal if the server was already destroyed or is not responding"
              fi
            else
              echo "‚ö†Ô∏è Could not determine server IP for cleanup"
            fi
            
            # Cleanup Tailscale devices via API (more reliable and comprehensive)
            if [[ -n "$TAILSCALE_AUTH_KEY" ]]; then
              echo "üîó Comprehensive Tailscale cleanup for service ${{ env.SERVICE_NAME }}..."
              
              TAILNET="${TAILSCALE_TAILNET}"
              if [[ -z "$TAILNET" ]]; then
                echo "‚ö†Ô∏è TAILSCALE_TAILNET not set, using default discovery"
                # For personal accounts, use the default endpoint without tailnet
                DEVICES_URL="https://api.tailscale.com/api/v2/devices"
              else
                echo "üîç Using tailnet: $TAILNET"
                DEVICES_URL="https://api.tailscale.com/api/v2/tailnet/$TAILNET/devices"
              fi
              
              echo "üåê Fetching ALL devices for comprehensive cleanup..."
              DEVICES_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" "$DEVICES_URL" 2>/dev/null || echo "CURL_FAILED")
              
              # Extract HTTP status code
              HTTP_CODE=$(echo "$DEVICES_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
              DEVICES_JSON=$(echo "$DEVICES_RESPONSE" | sed '/HTTP_CODE:/d')
              
              echo "üîç API Response Code: $HTTP_CODE"
              
              if [[ "$HTTP_CODE" == "200" ]] && echo "$DEVICES_JSON" | jq -e '.devices' >/dev/null 2>&1; then
                # Multiple cleanup patterns to catch all variants
                CLEANUP_PATTERNS=(
                  "^${{ env.SERVICE_NAME }}(-[0-9]+)?$"
                  "^${{ env.SERVICE_NAME }}$" 
                  "^${{ env.SERVICE_NAME }}-"
                  "${{ env.SERVICE_NAME }}"
                )
                
                TOTAL_REMOVED=0
                ALL_FOUND_DEVICES=""
                
                # First pass: collect all matching device IDs
                for pattern in "${CLEANUP_PATTERNS[@]}"; do
                  echo "üîç Searching for devices matching pattern: $pattern"
                  
                  DEVICES=$(echo "$DEVICES_JSON" | jq -r --arg pattern "$pattern" '
                    .devices[]? | 
                    select(
                      (.hostname // .name | test($pattern; "i")) or 
                      (.name // .hostname | test($pattern; "i"))
                    ) | 
                    .id // empty' | grep -v '^$')
                  
                  if [[ -n "$DEVICES" ]]; then
                    ALL_FOUND_DEVICES="$ALL_FOUND_DEVICES $DEVICES"
                  fi
                done
                
                # Remove duplicates and clean up the list
                UNIQUE_DEVICES=$(echo "$ALL_FOUND_DEVICES" | tr ' ' '\n' | sort -u | grep -v '^$' || true)
                
                if [[ -n "$UNIQUE_DEVICES" ]]; then
                  echo "Found devices to remove:"
                  for device_id in $UNIQUE_DEVICES; do
                    if [[ -n "$device_id" ]]; then
                      # Get device details before removal
                      DEVICE_INFO=$(echo "$DEVICES_JSON" | jq -r --arg id "$device_id" '.devices[]? | select(.id == $id) | "\(.hostname // .name // "unknown") (\(.addresses[0] // "no-ip"))"')
                      echo "üóëÔ∏è Removing device: $device_id - $DEVICE_INFO"
                      
                      # Try both API endpoint formats
                      DELETE_URL="https://api.tailscale.com/api/v2/device/$device_id"
                      REMOVE_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -X DELETE \
                        -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
                        "$DELETE_URL" 2>/dev/null || echo "CURL_FAILED")
                      
                      REMOVE_CODE=$(echo "$REMOVE_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                      
                      if [[ "$REMOVE_CODE" == "200" || "$REMOVE_CODE" == "204" ]]; then
                        echo "   ‚úÖ Successfully removed"
                        ((TOTAL_REMOVED++))
                      else
                        echo "   ‚ö†Ô∏è Primary endpoint failed (HTTP: $REMOVE_CODE), trying alternative..."
                        # Try alternative API endpoint format
                        if [[ -n "$TAILNET" ]]; then
                          ALT_DELETE_URL="https://api.tailscale.com/api/v2/tailnet/$TAILNET/devices/$device_id"
                        else
                          ALT_DELETE_URL="https://api.tailscale.com/api/v2/devices/$device_id"
                        fi
                        
                        ALT_REMOVE_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -X DELETE \
                          -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
                          "$ALT_DELETE_URL" 2>/dev/null || echo "CURL_FAILED")
                        
                        ALT_REMOVE_CODE=$(echo "$ALT_REMOVE_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                        if [[ "$ALT_REMOVE_CODE" == "200" || "$ALT_REMOVE_CODE" == "204" ]]; then
                          echo "   ‚úÖ Successfully removed via alternative endpoint"
                          ((TOTAL_REMOVED++))
                        else
                          echo "   ‚ùå Failed to remove device $device_id (Primary: $REMOVE_CODE, Alt: $ALT_REMOVE_CODE)"
                        fi
                      fi
                      
                      # Rate limiting: small delay between deletions
                      sleep 1
                    fi
                  done
                  echo "‚úÖ Comprehensive Tailscale cleanup completed - removed $TOTAL_REMOVED devices total"
                else
                  echo "‚ÑπÔ∏è No Tailscale devices found matching service name pattern: $SERVICE_PATTERN"
                fi
              elif [[ "$HTTP_CODE" == "401" ]]; then
                echo "‚ùå Tailscale API authentication failed - check TAILSCALE_AUTH_KEY"
              elif [[ "$HTTP_CODE" == "403" ]]; then
                echo "‚ùå Tailscale API access forbidden - check API key permissions"
              elif [[ "$HTTP_CODE" == "404" ]]; then
                echo "‚ùå Tailscale tailnet not found - check TAILSCALE_TAILNET value"
              else
                echo "‚ö†Ô∏è Could not retrieve Tailscale devices list"
                echo "HTTP Code: $HTTP_CODE"
                echo "Response: $DEVICES_JSON" | head -200
              fi
            else
              echo "‚ö†Ô∏è Tailscale API key not available"
            fi
          else
            echo "‚ÑπÔ∏è No existing server found for cleanup"
          fi

      - name: üí• Destroy Existing Server
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
        run: |
          echo "üí• Looking for existing ${{ env.SERVICE_NAME }} server to destroy..."
          
          # Find existing server
          EXISTING_SERVER=$(linode-cli linodes list --text --no-headers | grep "${{ env.SERVICE_NAME }}" | head -1)
          
          if [[ -n "$EXISTING_SERVER" ]]; then
            SERVER_ID=$(echo "$EXISTING_SERVER" | cut -f1)
            SERVER_LABEL=$(echo "$EXISTING_SERVER" | cut -f2)
            
            echo "üî• Destroying server: $SERVER_LABEL (ID: $SERVER_ID)"
            linode-cli linodes delete "$SERVER_ID"
            
            echo "‚è≥ Waiting for server destruction to complete..."
            sleep 30
            
            echo "‚úÖ Server destroyed successfully"
          else
            echo "‚ÑπÔ∏è No existing server found for ${{ env.SERVICE_NAME }}"
          fi

  # ============================================================================
  # Main Destroy Job (for destroy action)
  # ============================================================================
  destroy-service:
    name: üóëÔ∏è Destroy Service
    runs-on: ubuntu-latest
    needs: preflight-checks
    if: needs.preflight-checks.outputs.should_destroy == 'true' && needs.preflight-checks.outputs.destroy_confirmed == 'true'
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üîß Setup Linode CLI
        if: inputs.destroy_scope == 'full-server'
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
        run: |
          pip install linode-cli
          # Configure via environment variable to avoid config file issues
          export LINODE_CLI_TOKEN="${{ secrets.LINODE_CLI_TOKEN }}"
          # Test CLI access
          linode-cli --version

      - name: üóëÔ∏è Execute Destruction
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
          TAILSCALE_AUTH_KEY: ${{ secrets.TAILSCALE_AUTH_KEY }}
          TAILSCALE_TAILNET: ${{ secrets.TAILSCALE_TAILNET }}
        run: |
          echo "üóëÔ∏è Destroying ${{ env.SERVICE_NAME }}..."
          echo "Scope: ${{ inputs.destroy_scope }}"
          
          # Install dependencies for API calls
          sudo apt-get update && sudo apt-get install -y curl jq >/dev/null 2>&1 || true
          
          case "${{ inputs.destroy_scope }}" in
            "service-only")
              echo "üõë Stopping service containers only..."
              # Logic for service-only destruction
              ;;
            "reset-service")
              echo "üßπ Resetting service to clean state..."
              # Logic for service reset
              ;;
            "full-server")
              echo "üí• Destroying entire server with cleanup..."
              
              # Find and cleanup server before destruction
              SERVER_INFO=$(linode-cli linodes list --text --no-headers | grep "${{ env.SERVICE_NAME }}" | head -1)
              if [[ -n "$SERVER_INFO" ]]; then
                SERVER_ID=$(echo "$SERVER_INFO" | cut -f1)
                SERVER_LABEL=$(echo "$SERVER_INFO" | cut -f2)
                
                # Try to get server IP for cleanup
                SERVER_DETAILS=$(linode-cli linodes view "$SERVER_ID" --text --no-headers)
                SERVER_IP_COL4=$(echo "$SERVER_DETAILS" | cut -f4)
                SERVER_IP_COL5=$(echo "$SERVER_DETAILS" | cut -f5)
                SERVER_IP_COL6=$(echo "$SERVER_DETAILS" | cut -f6)
                SERVER_IP_COL7=$(echo "$SERVER_DETAILS" | cut -f7)
                
                SERVER_IP=""
                for IP in "$SERVER_IP_COL4" "$SERVER_IP_COL5" "$SERVER_IP_COL6" "$SERVER_IP_COL7"; do
                  if [[ "$IP" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
                    SERVER_IP="$IP"
                    break
                  fi
                done
                
                if [[ -n "$SERVER_IP" ]]; then
                  echo "üßπ Cleaning up services on server before destruction..."
                  
                  # Generate SSH key for cleanup
                  ssh-keygen -t rsa -b 4096 -f ~/.ssh/cleanup_key -N "" -C "cleanup-${{ env.SERVICE_NAME }}" || true
                  
                  # Try to connect and cleanup
                  if timeout 30 ssh -i ~/.ssh/cleanup_key -o StrictHostKeyChecking=no -o ConnectTimeout=10 root@$SERVER_IP "echo 'Cleanup connection successful'" 2>/dev/null; then
                    echo "üîó Connected for cleanup..."
                    
                    # Cleanup Tailscale
                    ssh -i ~/.ssh/cleanup_key -o StrictHostKeyChecking=no root@$SERVER_IP "tailscale logout || true" || true
                    
                    echo "‚úÖ Service cleanup completed"
                  else
                    echo "‚ö†Ô∏è Could not connect for cleanup"
                  fi
                fi
                
                echo "Destroying: $SERVER_LABEL (ID: $SERVER_ID)"
                linode-cli linodes delete "$SERVER_ID"
                echo "‚úÖ Server destroyed"
                
                # Cleanup Tailscale devices via API after server destruction (comprehensive)
                if [[ -n "$TAILSCALE_AUTH_KEY" ]]; then
                  echo "üîó Final comprehensive Tailscale cleanup for service ${{ env.SERVICE_NAME }}..."
                  
                  TAILNET="${TAILSCALE_TAILNET}"
                  if [[ -z "$TAILNET" ]]; then
                    echo "‚ö†Ô∏è TAILSCALE_TAILNET not set, using default discovery"
                    DEVICES_URL="https://api.tailscale.com/api/v2/devices"
                  else
                    echo "üîç Using tailnet: $TAILNET"
                    DEVICES_URL="https://api.tailscale.com/api/v2/tailnet/$TAILNET/devices"
                  fi
                  
                  echo "üåê Fetching ALL remaining devices for final cleanup..."
                  DEVICES_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" "$DEVICES_URL" 2>/dev/null || echo "CURL_FAILED")
                  
                  # Extract HTTP status code
                  HTTP_CODE=$(echo "$DEVICES_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                  DEVICES_JSON=$(echo "$DEVICES_RESPONSE" | sed '/HTTP_CODE:/d')
                  
                  echo "üîç API Response Code: $HTTP_CODE"
                  
                  if [[ "$HTTP_CODE" == "200" ]] && echo "$DEVICES_JSON" | jq -e '.devices' >/dev/null 2>&1; then
                    # Even more aggressive cleanup patterns for final cleanup
                    CLEANUP_PATTERNS=(
                      "^${{ env.SERVICE_NAME }}(-[0-9]+)?$"
                      "^${{ env.SERVICE_NAME }}$" 
                      "^${{ env.SERVICE_NAME }}-"
                      "${{ env.SERVICE_NAME }}"
                      ".*${{ env.SERVICE_NAME }}.*"  # Catch any device containing the service name
                    )
                    
                    TOTAL_REMOVED=0
                    ALL_FOUND_DEVICES=""
                    
                    # Collect all matching device IDs from all patterns
                    for pattern in "${CLEANUP_PATTERNS[@]}"; do
                      echo "üîç Final scan for pattern: $pattern"
                      
                      DEVICES=$(echo "$DEVICES_JSON" | jq -r --arg pattern "$pattern" '
                        .devices[]? | 
                        select(
                          (.hostname // .name | test($pattern; "i")) or 
                          (.name // .hostname | test($pattern; "i"))
                        ) | 
                        .id // empty' | grep -v '^$')
                      
                      if [[ -n "$DEVICES" ]]; then
                        ALL_FOUND_DEVICES="$ALL_FOUND_DEVICES $DEVICES"
                      fi
                    done
                    
                    # Remove duplicates and clean up the list
                    UNIQUE_DEVICES=$(echo "$ALL_FOUND_DEVICES" | tr ' ' '\n' | sort -u | grep -v '^$' || true)
                    
                    if [[ -n "$UNIQUE_DEVICES" ]]; then
                      echo "Found orphaned devices for final removal:"
                      for device_id in $UNIQUE_DEVICES; do
                        if [[ -n "$device_id" ]]; then
                          # Get device details before removal
                          DEVICE_INFO=$(echo "$DEVICES_JSON" | jq -r --arg id "$device_id" '.devices[]? | select(.id == $id) | "\(.hostname // .name // "unknown") (\(.addresses[0] // "no-ip"))"')
                          echo "üóëÔ∏è Final cleanup - removing: $device_id - $DEVICE_INFO"
                          
                          # Try both API endpoint formats aggressively
                          DELETE_URL="https://api.tailscale.com/api/v2/device/$device_id"
                          REMOVE_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -X DELETE \
                            -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
                            "$DELETE_URL" 2>/dev/null || echo "CURL_FAILED")
                          
                          REMOVE_CODE=$(echo "$REMOVE_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                          
                          if [[ "$REMOVE_CODE" == "200" || "$REMOVE_CODE" == "204" ]]; then
                            echo "   ‚úÖ Successfully removed"
                            ((TOTAL_REMOVED++))
                          else
                            echo "   ‚ö†Ô∏è Trying alternative endpoint (HTTP: $REMOVE_CODE)..."
                            # Try alternative API endpoint format
                            if [[ -n "$TAILNET" ]]; then
                              ALT_DELETE_URL="https://api.tailscale.com/api/v2/tailnet/$TAILNET/devices/$device_id"
                            else
                              ALT_DELETE_URL="https://api.tailscale.com/api/v2/devices/$device_id"
                            fi
                            
                            ALT_REMOVE_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -X DELETE \
                              -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
                              "$ALT_DELETE_URL" 2>/dev/null || echo "CURL_FAILED")
                            
                            ALT_REMOVE_CODE=$(echo "$ALT_REMOVE_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                            if [[ "$ALT_REMOVE_CODE" == "200" || "$ALT_REMOVE_CODE" == "204" ]]; then
                              echo "   ‚úÖ Successfully removed via alternative endpoint"
                              ((TOTAL_REMOVED++))
                            else
                              echo "   ‚ùå Could not remove device $device_id (Primary: $REMOVE_CODE, Alt: $ALT_REMOVE_CODE)"
                            fi
                          fi
                          
                          # Rate limiting: small delay between deletions
                          sleep 1
                        fi
                      done
                      echo "‚úÖ Final Tailscale cleanup completed - removed $TOTAL_REMOVED devices total"
                          echo "üóëÔ∏è Removing orphaned Tailscale device: $device_id - $DEVICE_INFO"
                          
                          DELETE_URL="https://api.tailscale.com/api/v2/device/$device_id"
                          REMOVE_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -X DELETE \
                            -H "Authorization: Bearer $TAILSCALE_AUTH_KEY" \
                            "$DELETE_URL" 2>/dev/null || echo "CURL_FAILED")
                          
                          REMOVE_CODE=$(echo "$REMOVE_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                          
                          if [[ "$REMOVE_CODE" == "200" || "$REMOVE_CODE" == "204" ]]; then
                            echo "   ‚úÖ Successfully removed"
                            ((REMOVED_COUNT++))
                          else
                            echo "   ‚ùå Failed to remove device $device_id (HTTP: $REMOVE_CODE)"
                          fi
                          
                          # Rate limiting
                          sleep 1
                        fi
                      done
                      echo "‚úÖ Orphaned device cleanup completed - removed $REMOVED_COUNT devices"
                    else
                      echo "‚ÑπÔ∏è No orphaned Tailscale devices found matching pattern: $SERVICE_PATTERN"
                    fi
                  else
                    echo "‚ö†Ô∏è Could not retrieve Tailscale devices for cleanup - HTTP: $HTTP_CODE"
                  fi
                fi
              else
                echo "‚ö†Ô∏è No server found for ${{ env.SERVICE_NAME }}"
              fi
              ;;
          esac

  # ============================================================================
  # Server Infrastructure Setup
  # ============================================================================
  setup-infrastructure:
    name: üèóÔ∏è Setup Infrastructure
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [preflight-checks, destroy-existing-server, build-docker-api, build-docker-web, build-docker-auth]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_deploy == 'true' &&
      (needs.destroy-existing-server.result == 'success' || needs.destroy-existing-server.result == 'skipped') &&
      (needs.build-docker-api.result == 'success' || needs.build-docker-api.result == 'skipped') &&
      (needs.build-docker-web.result == 'success' || needs.build-docker-web.result == 'skipped') &&
      (needs.build-docker-auth.result == 'success' || needs.build-docker-auth.result == 'skipped')
    outputs:
      server_ip: ${{ steps.create-server.outputs.server_ip }}
      server_id: ${{ steps.create-server.outputs.server_id }}
      tailscale_ip: ${{ steps.stage2-setup.outputs.tailscale_ip }}
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üîß Setup Linode CLI
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
        run: |
          pip install linode-cli
          # Configure via environment variable to avoid config file issues
          export LINODE_CLI_TOKEN="${{ secrets.LINODE_CLI_TOKEN }}"
          # Test CLI access
          linode-cli --version

      - name: üöÄ Create or Find Server
        id: create-server
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
        run: |
          echo "üöÄ Managing Linode server for ${{ env.SERVICE_NAME }}..."
          
          # Check if server already exists (unless we just destroyed it)
          if [[ "${{ inputs.overwrite_server }}" != "true" ]]; then
            EXISTING_SERVER=$(linode-cli linodes list --text --no-headers | grep "${{ env.SERVICE_NAME }}" | head -1)
            if [[ -n "$EXISTING_SERVER" ]]; then
              echo "üîç Debug - Found existing server:"
              echo "$EXISTING_SERVER"
              
              SERVER_ID=$(echo "$EXISTING_SERVER" | cut -f1)
              # Try different columns for IP address
              SERVER_IP_COL4=$(echo "$EXISTING_SERVER" | cut -f4)
              SERVER_IP_COL5=$(echo "$EXISTING_SERVER" | cut -f5)
              SERVER_IP_COL6=$(echo "$EXISTING_SERVER" | cut -f6)
              SERVER_IP_COL7=$(echo "$EXISTING_SERVER" | cut -f7)
              
              echo "IP candidates: Col4='$SERVER_IP_COL4', Col5='$SERVER_IP_COL5', Col6='$SERVER_IP_COL6', Col7='$SERVER_IP_COL7'"
              
              # Use the first valid IP address we find
              for IP in "$SERVER_IP_COL4" "$SERVER_IP_COL5" "$SERVER_IP_COL6" "$SERVER_IP_COL7"; do
                if [[ "$IP" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
                  SERVER_IP="$IP"
                  break
                fi
              done
              
              if [[ -z "$SERVER_IP" ]]; then
                echo "‚ùå Could not extract IP address from server info"
                exit 1
              fi
              
              echo "‚úÖ Using existing server: $SERVER_IP (ID: $SERVER_ID)"
              echo "server_ip=$SERVER_IP" >> $GITHUB_OUTPUT
              echo "server_id=$SERVER_ID" >> $GITHUB_OUTPUT
              exit 0
            fi
          fi
          
          # Create new server
          SERVER_LABEL="${{ env.SERVICE_NAME }}"
          echo "üÜï Creating new server: $SERVER_LABEL"
          
          # Generate SSH key for this deployment
          echo "üîë Generating SSH key for server access..."
          ssh-keygen -t rsa -b 4096 -f ~/.ssh/linode_deployment_key -N "" -C "github-actions-${{ env.SERVICE_NAME }}"
          
          # Get the public key content for server authorization
          SSH_PUBLIC_KEY=$(cat ~/.ssh/linode_deployment_key.pub)
          echo "üîë SSH Public Key: $SSH_PUBLIC_KEY"
          
          # Store the private key (base64 encoded for safe storage)
          SSH_PRIVATE_KEY=$(base64 -w 0 ~/.ssh/linode_deployment_key)
          echo "ssh_private_key=$SSH_PRIVATE_KEY" >> $GITHUB_OUTPUT
          
          echo "üöÄ Creating server with SSH key authentication..."
          RESULT=$(linode-cli linodes create \
            --type "${{ env.SERVER_TYPE }}" \
            --region "${{ env.TARGET_REGION }}" \
            --image "linode/arch" \
            --label "$SERVER_LABEL" \
            --root_pass "${{ secrets.SERVICE_ROOT_PASSWORD }}" \
            --authorized_keys "$SSH_PUBLIC_KEY" \
            --backups_enabled=${{ inputs.enable_backups || 'false' }} \
            --text --no-headers)
          
          SERVER_ID=$(echo "$RESULT" | cut -f1)
          
          # Wait for server to be running
          echo "‚è≥ Waiting for server to be ready..."
          ATTEMPT=0
          while true; do
            # Get server info and check status
            SERVER_INFO=$(linode-cli linodes view "$SERVER_ID" --text --no-headers)
            
            # Debug: show the full output on first few attempts
            if [[ $ATTEMPT -lt 3 ]]; then
              echo "üîç Debug - Server info columns:"
              echo "$SERVER_INFO"
            fi
            
            # Status is in column 6 (ID|Label|Region|Type|Image|Status|IP|Backups)
            STATUS=$(echo "$SERVER_INFO" | cut -f6)
            
            echo "Attempt $((++ATTEMPT)): Status='$STATUS'"
            
            # Check if server is running
            if [[ "$STATUS" == "running" ]]; then
              echo "‚úÖ Server is running!"
              break
            fi
            
            # Don't wait forever for server status
            if [[ $ATTEMPT -gt 15 ]]; then
              echo "‚ö†Ô∏è Server status check timeout - proceeding to SSH test"
              break
            fi
            
            sleep 5  # Check more frequently
          done
          
          # Get server IP
          SERVER_INFO=$(linode-cli linodes view "$SERVER_ID" --text --no-headers)
          echo "üîç Debug - Server view output:"
          echo "$SERVER_INFO"
          
          # Try different columns for IP address
          SERVER_IP_COL4=$(echo "$SERVER_INFO" | cut -f4)
          SERVER_IP_COL5=$(echo "$SERVER_INFO" | cut -f5)
          SERVER_IP_COL6=$(echo "$SERVER_INFO" | cut -f6)
          SERVER_IP_COL7=$(echo "$SERVER_INFO" | cut -f7)
          
          echo "IP candidates: Col4='$SERVER_IP_COL4', Col5='$SERVER_IP_COL5', Col6='$SERVER_IP_COL6', Col7='$SERVER_IP_COL7'"
          
          # Use the first valid IP address we find
          for IP in "$SERVER_IP_COL4" "$SERVER_IP_COL5" "$SERVER_IP_COL6" "$SERVER_IP_COL7"; do
            if [[ "$IP" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
              SERVER_IP="$IP"
              break
            fi
          done
          
          if [[ -z "$SERVER_IP" ]]; then
            echo "‚ùå Could not extract IP address from server info"
            exit 1
          fi
          
          echo "‚úÖ Server ready: $SERVER_IP (ID: $SERVER_ID)"
          
          echo "server_ip=$SERVER_IP" >> $GITHUB_OUTPUT
          echo "server_id=$SERVER_ID" >> $GITHUB_OUTPUT

      - name: ‚è≥ Wait for SSH Access
        run: |
          echo "‚è≥ Waiting for SSH access to ${{ steps.create-server.outputs.server_ip }}..."
          
          SSH_READY=false
          
          # First, test basic connectivity
          echo "üîç Testing basic connectivity to port 22..."
          for i in {1..10}; do
            if timeout 5 nc -zv ${{ steps.create-server.outputs.server_ip }} 22 2>/dev/null; then
              echo "‚úÖ Port 22 is reachable on attempt $i"
              break
            fi
            echo "Port 22 not ready, waiting 10 seconds..."
            sleep 10
          done
          
          # Test SSH with detailed error output
          echo "üîë Testing SSH connection with private key..."
          
          for i in {1..15}; do
            echo "Attempt $i/15: Testing SSH connection..."
            
            # Use the generated private key for authentication
            SSH_OUTPUT=$(timeout 10 ssh -i ~/.ssh/linode_deployment_key -v -o StrictHostKeyChecking=no -o ConnectTimeout=5 -o ConnectionAttempts=1 \
               root@${{ steps.create-server.outputs.server_ip }} "echo 'SSH ready'" 2>&1 || echo "SSH_FAILED")
            
            if echo "$SSH_OUTPUT" | grep -q "SSH ready"; then
              echo "‚úÖ SSH ready after $i attempts"
              SSH_READY=true
              break
            else
              echo "SSH failed. Last few lines of output:"
              echo "$SSH_OUTPUT" | tail -3
            fi
            
            echo "Waiting 15 seconds before next attempt..."
            sleep 15
          done
          
          if [[ "$SSH_READY" != "true" ]]; then
            echo "‚ùå SSH failed to become ready after 30 attempts (5 minutes)"
            echo "üîç Debugging SSH connection..."
            
            # Try to get more info about why SSH is failing
            echo "Testing basic connectivity..."
            timeout 5 nc -zv ${{ steps.create-server.outputs.server_ip }} 22 || echo "Port 22 not reachable"
            
            exit 1
          fi

      - name: üèóÔ∏è Stage 1 - Pre-Reboot Setup
        id: stage1-setup
        run: |
          echo "üèóÔ∏è Stage 1: Pre-reboot foundation setup..."
          
          # Check if service has its own stage1 script
          if [ -f "scripts/stage1-setup.sh" ]; then
            echo "‚úÖ Using service-specific stage1 script: scripts/stage1-setup.sh"
            cp scripts/stage1-setup.sh stage1-setup.sh
            
            # Inject environment variables into the script
            sed -i 's/\$ACTIONS_USER_PASSWORD/${{ secrets.ACTIONS_USER_PASSWORD }}/g' stage1-setup.sh
            sed -i 's/\$TAILSCALE_AUTH_KEY/${{ secrets.TAILSCALE_AUTH_KEY }}/g' stage1-setup.sh
          else
            echo "‚ÑπÔ∏è No service-specific stage1 script found, using generated script"
          
          cat > stage1-setup.sh << 'EOF'
          #!/bin/bash
          set -euo pipefail
          
          echo "üîÑ Updating system..."
          # Update package databases first
          pacman -Sy --noconfirm
          
          echo "üîß Optimizing package mirrors for better download speeds..."
          # Backup original mirrorlist
          cp /etc/pacman.d/mirrorlist /etc/pacman.d/mirrorlist.backup || true
          
          # Use faster mirrors and optimize pacman configuration
          {
            echo "## United States"
            echo "Server = https://america.mirror.pkgbuild.com/\$repo/os/\$arch"
            echo "Server = https://mirror.arizona.edu/archlinux/\$repo/os/\$arch"
            echo "Server = https://mirrors.ocf.berkeley.edu/archlinux/\$repo/os/\$arch"
            echo "Server = https://mirror.cs.pitt.edu/archlinux/\$repo/os/\$arch"
            echo "Server = https://mirrors.kernel.org/archlinux/\$repo/os/\$arch"
            echo ""
            echo "## Global CDN"
            echo "Server = https://geo.mirror.pkgbuild.com/\$repo/os/\$arch"
          } > /etc/pacman.d/mirrorlist
          
          # Optimize pacman for faster downloads
          sed -i 's/#ParallelDownloads = 5/ParallelDownloads = 10/' /etc/pacman.conf || true
          
          # Handle NVIDIA firmware conflicts with comprehensive approach
          echo "üîß Removing conflicting NVIDIA firmware files..."
          rm -rf /usr/lib/firmware/nvidia/ad103* 2>/dev/null || true
          rm -rf /usr/lib/firmware/nvidia/ad104* 2>/dev/null || true  
          rm -rf /usr/lib/firmware/nvidia/ad106* 2>/dev/null || true
          rm -rf /usr/lib/firmware/nvidia/ad107* 2>/dev/null || true
          
          # Remove symlinks and directories that cause conflicts
          find /usr/lib/firmware/nvidia -type l -delete 2>/dev/null || true
          find /usr/lib/firmware/nvidia -name "*.zst" -delete 2>/dev/null || true
          
          # Force upgrade with multiple overwrite patterns and retry logic
          echo "üîÑ Performing system upgrade with retry logic..."
          UPGRADE_SUCCESS=false
          for attempt in {1..3}; do
            echo "Upgrade attempt $attempt/3..."
            if pacman -Su --noconfirm --overwrite='*' --overwrite='/usr/lib/firmware/nvidia/*' 2>/dev/null; then
              UPGRADE_SUCCESS=true
              break
            else
              echo "‚ö†Ô∏è Upgrade attempt $attempt failed, trying alternative approach..."
              # Clean up and try again
              rm -rf /usr/lib/firmware/nvidia || true
              rm -f /var/lib/pacman/db.lck || true
              sleep 5
            fi
          done
          
          if [[ "$UPGRADE_SUCCESS" != "true" ]]; then
            echo "‚ö†Ô∏è System upgrade failed after 3 attempts, proceeding with package installation..."
          else
            echo "‚úÖ System upgrade completed successfully"
          fi
          
          echo "üì¶ Installing core packages with retry logic..."
          # Install essential packages first (most important ones) - using modern Docker with Compose plugin
          CORE_PACKAGES="curl wget git docker docker-compose tailscale fail2ban sudo rsync"
          
          echo "üîÑ Installing essential packages: $CORE_PACKAGES"
          INSTALL_SUCCESS=false
          for attempt in {1..3}; do
            echo "Package install attempt $attempt/3..."
            if timeout 300 pacman -S --noconfirm $CORE_PACKAGES; then
              INSTALL_SUCCESS=true
              echo "‚úÖ Essential packages installed successfully"
              break
            else
              echo "‚ö†Ô∏è Package install attempt $attempt failed, retrying..."
              # Clear any locks and try again
              rm -f /var/lib/pacman/db.lck || true
              sleep 10
            fi
          done
          
          if [[ "$INSTALL_SUCCESS" != "true" ]]; then
            echo "‚ùå Failed to install essential packages after 3 attempts"
            echo "üîÑ Trying to install packages individually..."
            
            # Try installing packages one by one
            for pkg in $CORE_PACKAGES; do
              echo "Installing $pkg..."
              timeout 120 pacman -S --noconfirm "$pkg" || echo "‚ö†Ô∏è Failed to install $pkg, continuing..."
            done
          fi
          
          echo "üê≥ Ensuring modern Docker Compose is available..."
          # Install Docker Compose plugin for modern 'docker compose' command
          if ! docker compose version &>/dev/null; then
            echo "üîß Installing Docker Compose plugin..."
            
            # Method 1: Try installing from AUR if available
            if command -v yay &>/dev/null || command -v paru &>/dev/null; then
              echo "üì¶ Installing docker-compose plugin via AUR helper..."
              if command -v yay &>/dev/null; then
                yay -S --noconfirm docker-compose-plugin || echo "‚ö†Ô∏è AUR installation failed"
              elif command -v paru &>/dev/null; then
                paru -S --noconfirm docker-compose-plugin || echo "‚ö†Ô∏è AUR installation failed"
              fi
            fi
            
            # Method 2: Manual installation if AUR failed
            if ! docker compose version &>/dev/null; then
              echo "üîß Installing Docker Compose plugin manually..."
              
              # Create docker plugins directory
              mkdir -p /usr/local/lib/docker/cli-plugins
              
              # Download latest Docker Compose plugin
              COMPOSE_VERSION=$(curl -s https://api.github.com/repos/docker/compose/releases/latest | grep 'tag_name' | cut -d'"' -f4 | sed 's/v//')
              echo "üì• Downloading Docker Compose v$COMPOSE_VERSION..."
              
              curl -SL "https://github.com/docker/compose/releases/download/v$COMPOSE_VERSION/docker-compose-linux-x86_64" \
                -o /usr/local/lib/docker/cli-plugins/docker-compose
              
              chmod +x /usr/local/lib/docker/cli-plugins/docker-compose
              
              # Verify installation
              if /usr/local/lib/docker/cli-plugins/docker-compose version &>/dev/null; then
                echo "‚úÖ Docker Compose plugin installed successfully"
              else
                echo "‚ö†Ô∏è Docker Compose plugin installation may have issues"
              fi
            fi
          else
            echo "‚úÖ Docker Compose plugin already available"
          fi
          
          # Try to install base-devel (development tools) - optional
          echo "üì¶ Installing development tools (optional)..."
          timeout 240 pacman -S --noconfirm base-devel || {
            echo "‚ö†Ô∏è Failed to install base-devel, continuing without development tools..."
          }
          
          echo "‚ÑπÔ∏è Skipping Netdata installation - using Docker-based monitoring"
          # Netdata is now handled via Docker compose in the application deployment
          
          echo "üë• Creating users..."
          useradd -m -s /bin/bash jordan || true
          echo "jordan:${{ secrets.JORDAN_PASSWORD }}" | chpasswd
          usermod -aG wheel,docker jordan
          
          useradd -m -s /bin/bash actions_user || true
          echo "actions_user:${{ secrets.ACTIONS_USER_PASSWORD }}" | chpasswd
          usermod -aG wheel,docker actions_user
          
          useradd -m -s /bin/bash ${{ env.SERVICE_NAME }}_user || true
          usermod -aG docker ${{ env.SERVICE_NAME }}_user
          # Set a password for SSH access (temporary, will be secured via Tailscale)
          echo "${{ env.SERVICE_NAME }}_user:${{ secrets.ACTIONS_USER_PASSWORD }}" | chpasswd
          
          # Enable SSH access for service user
          mkdir -p /home/${{ env.SERVICE_NAME }}_user/.ssh
          chmod 700 /home/${{ env.SERVICE_NAME }}_user/.ssh
          chown ${{ env.SERVICE_NAME }}_user:${{ env.SERVICE_NAME }}_user /home/${{ env.SERVICE_NAME }}_user/.ssh
          
          # Enable password authentication for post-deployment access
          sed -i 's/#PasswordAuthentication yes/PasswordAuthentication yes/' /etc/ssh/sshd_config
          sed -i 's/PasswordAuthentication no/PasswordAuthentication yes/' /etc/ssh/sshd_config
          
          echo "üè∑Ô∏è Setting hostname in Stage 1 (before Tailscale auth)..."
          # Set hostname to service name for better identification - MUST be done in Stage 1
          hostnamectl set-hostname "${{ env.SERVICE_NAME }}"
          echo "‚úÖ Hostname set to: ${{ env.SERVICE_NAME }}"
          
          echo "‚öôÔ∏è Enabling services for post-reboot..."
          systemctl enable docker
          systemctl enable tailscaled
          
          # Enable Netdata only if it was successfully installed
          # Netdata is now handled via Docker - skipping service enable
          echo "‚ÑπÔ∏è Netdata monitoring handled via Docker - system service skipped"
          
          echo "ÔøΩ Creating post-reboot script..."
          cat > /usr/local/bin/stage2-post-reboot.sh << 'STAGE2EOF'
          #!/bin/bash
          set -euo pipefail
          
          echo "üöÄ Stage 2: Post-reboot setup starting..."
          
          echo "üê≥ Starting Docker..."
          
          echo "üì¶ Installing firewall packages after reboot..."
          # Install iptables and ufw after kernel update and reboot to avoid conflicts
          pacman -S --noconfirm ufw iptables-nft || {
            echo "üîÑ Resolving iptables conflicts..."
            # Remove conflicting iptables package first
            pacman -Rdd --noconfirm iptables 2>/dev/null || true
            pacman -S --noconfirm iptables-nft ufw
          }
          
          echo "ÔøΩ Configuring firewall before starting services..."
          # Configure firewall first, before starting Docker
          ufw --force reset
          ufw default deny incoming
          ufw default allow outgoing
          ufw allow ssh
          
          # Initialize iptables chains that Docker expects
          echo "üîß Initializing iptables chains for Docker..."
          iptables -t nat -N DOCKER 2>/dev/null || true
          iptables -t filter -N DOCKER 2>/dev/null || true
          iptables -t filter -N DOCKER-ISOLATION-STAGE-1 2>/dev/null || true
          iptables -t filter -N DOCKER-ISOLATION-STAGE-2 2>/dev/null || true
          iptables -t filter -N DOCKER-USER 2>/dev/null || true
          
          # Add basic Docker chains if they don't exist
          iptables -t nat -C PREROUTING -m addrtype --dst-type LOCAL -j DOCKER 2>/dev/null || \
            iptables -t nat -I PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
          iptables -t nat -C OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER 2>/dev/null || \
            iptables -t nat -I OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER
          iptables -t filter -C FORWARD -j DOCKER-USER 2>/dev/null || \
            iptables -t filter -I FORWARD -j DOCKER-USER
          iptables -t filter -C FORWARD -j DOCKER-ISOLATION-STAGE-1 2>/dev/null || \
            iptables -t filter -I FORWARD -j DOCKER-ISOLATION-STAGE-1
          iptables -t filter -C DOCKER-USER -j RETURN 2>/dev/null || \
            iptables -t filter -A DOCKER-USER -j RETURN
          
          echo "ÔøΩüê≥ Starting Docker service..."
          systemctl start docker
          
          # Wait for Docker to be ready
          echo "‚è≥ Waiting for Docker to be ready..."
          for i in {1..10}; do
            if docker info >/dev/null 2>&1; then
              echo "‚úÖ Docker is ready"
              break
            fi
            echo "Attempt $i/10: Waiting for Docker..."
            sleep 5
          done
          
          echo "üîó Starting and authenticating Tailscale..."
          systemctl start tailscaled
          
          # Wait for tailscaled to be ready
          echo "‚è≥ Waiting for tailscaled daemon to start..."
          for i in {1..10}; do
            if systemctl is-active tailscaled >/dev/null 2>&1; then
              echo "‚úÖ Tailscaled daemon is active"
              break
            fi
            echo "Attempt $i/10: Waiting for tailscaled..."
            sleep 3
          done
          
          # Validate auth key format before attempting connection
          AUTH_KEY="${{ secrets.TAILSCALE_AUTH_KEY }}"
          if [[ -z "$AUTH_KEY" ]]; then
            echo "‚ùå TAILSCALE_AUTH_KEY is empty"
            exit 1
          fi
          
          if [[ ! "$AUTH_KEY" =~ ^tskey- ]]; then
            echo "‚ö†Ô∏è Warning: Auth key doesn't start with 'tskey-' - this may not be a valid key"
          fi
          
          echo "üîó Authenticating with Tailscale..."
          # Multiple authentication attempts with different strategies
          TAILSCALE_CONNECTED=false
          
          # Attempt 1: Standard connection
          echo "üîÑ Attempt 1: Standard Tailscale connection..."
          if tailscale up --authkey="$AUTH_KEY" --hostname="${{ env.SERVICE_NAME }}" --accept-routes --timeout=180s; then
            TAILSCALE_CONNECTED=true
            echo "‚úÖ Tailscale connected on first attempt"
          else
            echo "‚ö†Ô∏è First attempt failed, trying alternative methods..."
            
            # Attempt 2: Reset and reconnect
            echo "üîÑ Attempt 2: Reset and reconnect..."
            tailscale logout 2>/dev/null || true
            sleep 5
            
            if tailscale up --authkey="$AUTH_KEY" --hostname="${{ env.SERVICE_NAME }}" --accept-routes --advertise-tags=tag:server --timeout=180s; then
              TAILSCALE_CONNECTED=true
              echo "‚úÖ Tailscale connected on second attempt"
            else
              echo "‚ö†Ô∏è Second attempt failed, trying without hostname..."
              
              # Attempt 3: Without custom hostname
              echo "üîÑ Attempt 3: Connection without custom hostname..."
              if tailscale up --authkey="$AUTH_KEY" --accept-routes --timeout=180s; then
                TAILSCALE_CONNECTED=true
                echo "‚úÖ Tailscale connected without custom hostname"
              else
                echo "‚ùå All Tailscale connection attempts failed"
                echo "üîç Tailscale status:"
                tailscale status 2>&1 || echo "Status command failed"
                echo "üîç Tailscaled logs:"
                journalctl -u tailscaled --no-pager -l --since='5 minutes ago' | tail -20 || echo "No logs available"
              fi
            fi
          fi
          
          # Wait for Tailscale to be ready and get IP
          if [[ "$TAILSCALE_CONNECTED" == "true" ]]; then
            echo "‚è≥ Waiting for Tailscale network to be ready..."
            TAILSCALE_IP="pending"
            
            for i in {1..30}; do
              if tailscale status | grep -q "Logged in"; then
                # Try to get IP address
                CURRENT_IP=$(tailscale ip -4 2>/dev/null || echo "")
                if [[ -n "$CURRENT_IP" && "$CURRENT_IP" != "" ]]; then
                  TAILSCALE_IP="$CURRENT_IP"
                  echo "‚úÖ Tailscale fully connected - IP: $TAILSCALE_IP"
                  break
                fi
              fi
              echo "Attempt $i/30: Waiting for Tailscale IP assignment..."
              sleep 10
            done
            
            echo "$TAILSCALE_IP" > /tmp/tailscale_ip
            
            if [[ "$TAILSCALE_IP" == "pending" ]]; then
              echo "‚ö†Ô∏è Tailscale connected but IP not assigned yet - this may resolve shortly"
            fi
          else
            echo "‚ùå Tailscale connection failed - proceeding without VPN"
            echo "pending" > /tmp/tailscale_ip
          fi
          
          echo "üî• Completing firewall configuration with Tailscale rules..."
          # Add Tailscale-specific rules now that Tailscale is connected
          ufw allow in on tailscale0
          ufw --force enable
          
          echo "üîê Configuring SSH for service access..."
          # Allow password authentication for Tailscale network only
          sed -i 's/#PasswordAuthentication yes/PasswordAuthentication yes/' /etc/ssh/sshd_config
          sed -i 's/PasswordAuthentication no/PasswordAuthentication yes/' /etc/ssh/sshd_config
          # Restart SSH service to apply changes
          systemctl restart sshd
          
          # Verify service user can be accessed
          echo "üîç Verifying service user configuration..."
          id ${{ env.SERVICE_NAME }}_user || echo "‚ö†Ô∏è Service user not found"
          ls -la /home/${{ env.SERVICE_NAME }}_user/.ssh 2>/dev/null || echo "‚ÑπÔ∏è SSH directory not found for service user"
          
          echo "üìä Starting monitoring services..."
          echo "‚ÑπÔ∏è Netdata monitoring handled via Docker - system service skipped"
          
          echo "‚úÖ Stage 2 complete - server ready for service deployment"
          STAGE2EOF
          
          chmod +x /usr/local/bin/stage2-post-reboot.sh
          
          echo "üîÑ Creating systemd service for post-reboot setup..."
          cat > /etc/systemd/system/stage2-setup.service << 'SERVICEEOF'
          [Unit]
          Description=Stage 2 Post-Reboot Setup
          After=network-online.target
          Wants=network-online.target
          
          [Service]
          Type=oneshot
          ExecStart=/usr/local/bin/stage2-post-reboot.sh
          RemainAfterExit=yes
          StandardOutput=journal
          StandardError=journal
          
          [Install]
          WantedBy=multi-user.target
          SERVICEEOF
          
          systemctl enable stage2-setup.service
          
          echo "‚úÖ Stage 1 complete - system ready for reboot"
          echo "NEEDS_REBOOT" > /tmp/stage1_status
          EOF
          fi
          
          scp -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no stage1-setup.sh root@${{ steps.create-server.outputs.server_ip }}:/tmp/
          ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "chmod +x /tmp/stage1-setup.sh && /tmp/stage1-setup.sh"
          
          STAGE1_STATUS=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "cat /tmp/stage1_status" || echo "unknown")
          echo "stage1_status=$STAGE1_STATUS" >> $GITHUB_OUTPUT

      - name: üîÑ Reboot Server for Kernel Updates
        if: steps.stage1-setup.outputs.stage1_status == 'NEEDS_REBOOT'
        run: |
          echo "üîÑ Rebooting server for kernel updates and service initialization..."
          ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "reboot" || true
          
          echo "‚è≥ Waiting for server to come back online..."
          sleep 30
          
          # Wait for SSH to be available again
          for i in {1..20}; do
            if ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no -o ConnectTimeout=10 root@${{ steps.create-server.outputs.server_ip }} "echo 'SSH ready after reboot'"; then
              echo "‚úÖ Server is back online after reboot"
              break
            fi
            echo "Attempt $i/20: Waiting for server to come back online..."
            sleep 15
          done

      - name: üèóÔ∏è Stage 2 - Post-Reboot Verification
        id: stage2-setup
        run: |
          echo "üèóÔ∏è Stage 2: Verifying post-reboot setup..."
          
          # Wait for SSH to be available after reboot (servers take time to reboot)
          echo "‚è≥ Waiting for server to come back online after reboot..."
          SSH_READY=false
          
          # Give server more time to reboot and be ready
          sleep 30  # Initial wait for reboot to complete
          
          for i in {1..20}; do
            echo "Attempt $i/20: Testing SSH connection after reboot..."
            
            # Test basic connectivity first
            if timeout 5 nc -zv ${{ steps.create-server.outputs.server_ip }} 22 2>/dev/null; then
              # Now test SSH authentication
              if timeout 10 ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no -o ConnectTimeout=5 \
                 root@${{ steps.create-server.outputs.server_ip }} "echo 'SSH ready after reboot'" 2>/dev/null; then
                echo "‚úÖ SSH ready after reboot (attempt $i)"
                SSH_READY=true
                break
              else
                echo "SSH connection failed, retrying..."
              fi
            else
              echo "Port 22 not ready, server may still be rebooting..."
            fi
            
            sleep 15  # Wait longer between attempts for reboot
          done
          
          if [[ "$SSH_READY" != "true" ]]; then
            echo "‚ùå SSH failed to become ready after reboot"
            echo "üîç Attempting one final connection attempt with debug info..."
            timeout 10 ssh -i ~/.ssh/linode_deployment_key -v -o StrictHostKeyChecking=no \
              root@${{ steps.create-server.outputs.server_ip }} "echo 'Final attempt'" || true
            exit 1
          fi
          
          # Wait for stage2 service to complete - should be fast (30-60 seconds)
          echo "‚è≥ Waiting for stage2-setup service to complete (optimized timing)..."
          STAGE2_COMPLETED=false
          
          # Check more frequently and for less time since stage2 is fast
          for i in {1..8}; do
            SERVICE_STATUS=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "systemctl is-active stage2-setup.service 2>/dev/null || echo 'inactive'")
            SERVICE_EXIT_STATUS=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "systemctl show stage2-setup.service --property=ExecMainStatus --value 2>/dev/null || echo 'unknown'")
            
            echo "Attempt $i/8: Service status='$SERVICE_STATUS', Exit status='$SERVICE_EXIT_STATUS'"
            
            # For oneshot services: inactive + exit status 0 = completed successfully
            if [[ "$SERVICE_STATUS" == "inactive" && "$SERVICE_EXIT_STATUS" == "0" ]]; then
              echo "‚úÖ Stage 2 setup service completed successfully"
              STAGE2_COMPLETED=true
              break
            fi
            
            # Still running/activating - wait a bit
            if [[ "$SERVICE_STATUS" == "activating" || "$SERVICE_STATUS" == "active" ]]; then
              echo "Service still running, waiting..."
              sleep 5
              continue
            fi
            
            # If it failed, show logs and break
            if [[ "$SERVICE_EXIT_STATUS" != "0" && "$SERVICE_EXIT_STATUS" != "unknown" && "$SERVICE_EXIT_STATUS" != "" ]]; then
              echo "‚ö†Ô∏è Stage 2 service failed (exit status: $SERVICE_EXIT_STATUS), checking logs..."
              ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "journalctl -u stage2-setup.service --no-pager -l --since='1 minute ago'" || true
              break
            fi
            
            sleep 5
          done
          
          # Quick verification that essential services are working
          echo "üîç Quick verification of essential services..."
          
          # Check Docker (most important for deployment)
          if ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "systemctl is-active docker" >/dev/null 2>&1; then
            echo "‚úÖ Docker is active"
          else
            echo "‚ö†Ô∏è Docker is not active, attempting to start..."
            ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "systemctl start docker && sleep 3"
          fi
          
          # Check Tailscale (important for VPN access)
          if ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "tailscale status --peers=false" >/dev/null 2>&1; then
            echo "‚úÖ Tailscale is connected"
          else
            echo "‚ö†Ô∏è Tailscale may still be connecting..."
          fi
          
          # Get Tailscale IP (multiple methods)
          TAILSCALE_IP=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "tailscale ip -4 2>/dev/null || cat /tmp/tailscale_ip 2>/dev/null || echo 'pending'")
          echo "üîó Tailscale IP: $TAILSCALE_IP"
          echo "tailscale_ip=$TAILSCALE_IP" >> $GITHUB_OUTPUT
          
          # Final status
          if [[ "$STAGE2_COMPLETED" == "true" ]]; then
            echo "‚úÖ Stage 2 verification complete - server ready for service deployment"
          else
            echo "‚ö†Ô∏è Stage 2 service may still be running, but proceeding with deployment"
          fi

  # ============================================================================
  # Service Deployment
  # ============================================================================
  deploy-service:
    name: üö¢ Deploy Service
    runs-on: ubuntu-latest
    timeout-minutes: 45
    needs: [preflight-checks, setup-infrastructure]
    if: needs.preflight-checks.outputs.should_deploy == 'true'
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üö¢ Deploy Service
        run: |
          echo "üö¢ Deploying ${{ env.SERVICE_NAME }}..."
          
          SERVER_IP="${{ needs.setup-infrastructure.outputs.server_ip }}"
          
          # Install sshpass for password authentication
          sudo apt-get update && sudo apt-get install -y sshpass >/dev/null 2>&1 || true
          
          # Create deployment script
          if [[ -f "services/${{ env.SERVICE_NAME }}/deploy.sh" ]]; then
            cp "services/${{ env.SERVICE_NAME }}/deploy.sh" deploy-script.sh
          else
            cat > deploy-script.sh << 'EOF'
          #!/bin/bash
          set -euo pipefail
          
          echo "üö¢ Deploying ${{ env.SERVICE_NAME }}..."
          
          # Setup service directory
          SERVICE_DIR="/home/${{ env.SERVICE_NAME }}_user/${{ env.SERVICE_NAME }}"
          
          if [[ -d "$SERVICE_DIR" ]]; then
            echo "Updating existing service..."
            cd "$SERVICE_DIR"
            git pull origin main || git pull origin master || echo "Git pull failed, continuing..."
          else
            echo "Cloning service repository..."
            git clone "https://github.com/${{ github.repository_owner }}/${{ env.SERVICE_NAME }}.git" "$SERVICE_DIR" || {
              echo "Git clone failed, creating service directory manually..."
              mkdir -p "$SERVICE_DIR"
            }
            chown -R ${{ env.SERVICE_NAME }}_user:${{ env.SERVICE_NAME }}_user "$SERVICE_DIR"
          fi
          
          cd "$SERVICE_DIR"
          
          # Special handling for nginx service (SSL setup)
          if [[ "${{ env.SERVICE_NAME }}" == "nginx" ]]; then
            echo "üîê Setting up SSL certificate management for nginx..."
            
            # Install SSL management system
            if [[ -f "scripts/install-ssl-systemd.sh" ]]; then
              chmod +x scripts/*.sh
              ./scripts/install-ssl-systemd.sh install
              
              # Configure environment for SSL
              cat >> /opt/nginx/.env << SSL_ENV
          DOMAIN_NAME=${{ env.FULL_DOMAIN }}
          LETSENCRYPT_EMAIL=admin@${{ inputs.domain_suffix || '7gram.xyz' }}
          SSL_ENV
              
              # Add Cloudflare credentials if available
              if [[ -n "${{ secrets.CLOUDFLARE_EMAIL || '' }}" ]]; then
                echo "CLOUDFLARE_EMAIL=${{ secrets.CLOUDFLARE_EMAIL }}" >> /opt/nginx/.env
                echo "CLOUDFLARE_API_TOKEN=${{ secrets.CLOUDFLARE_API_TOKEN }}" >> /opt/nginx/.env
              fi
              
              # Run initial SSL setup
              nginx-ssl setup || echo "‚ö†Ô∏è SSL setup completed with warnings"
            else
              echo "‚ö†Ô∏è SSL management scripts not found, continuing without SSL automation"
            fi
          fi
          
          # Special handling for FKS service (SSL setup)
          if [[ "${{ env.SERVICE_NAME }}" == "fks" ]]; then
            echo "üîê Setting up SSL certificate management for FKS..."
            
            # Install SSL management system
            if [[ -f "scripts/install-ssl-systemd.sh" ]]; then
              chmod +x scripts/*.sh
              ./scripts/install-ssl-systemd.sh install
              
              # Configure environment for SSL
              cat >> /opt/fks/.env << SSL_ENV
          DOMAIN_NAME=fkstrading.xyz
          LETSENCRYPT_EMAIL=admin@7gram.xyz
          SSL_ENV
              
              # Add Cloudflare credentials if available
              if [[ -n "${{ secrets.CLOUDFLARE_EMAIL || '' }}" ]]; then
                echo "CLOUDFLARE_EMAIL=${{ secrets.CLOUDFLARE_EMAIL }}" >> /opt/fks/.env
                echo "CLOUDFLARE_API_TOKEN=${{ secrets.CLOUDFLARE_API_TOKEN }}" >> /opt/fks/.env
              fi
              
              # Run initial SSL setup
              fks-ssl setup || echo "‚ö†Ô∏è FKS SSL setup completed with warnings"
            else
              echo "‚ö†Ô∏è FKS SSL management scripts not found, continuing without SSL automation"
            fi
          fi
          
          # Special handling for ATS service (SSL setup)
          if [[ "${{ env.SERVICE_NAME }}" == "ats" ]]; then
            echo "üîê Setting up SSL certificate management for ATS..."
            
            # Create ATS directory and initial environment file
            mkdir -p /opt/ats
            touch /opt/ats/.env
            
            # Install SSL management system
            if [[ -f "scripts/install-ssl-systemd.sh" ]]; then
              chmod +x scripts/*.sh
              ./scripts/install-ssl-systemd.sh install
              
              # Configure environment for SSL
              cat >> /opt/ats/.env << SSL_ENV
          DOMAIN_NAME=ats.7gram.xyz
          LETSENCRYPT_EMAIL=admin@7gram.xyz
          SSL_ENV
              
              # Add Cloudflare credentials if available
              if [[ -n "${{ secrets.CLOUDFLARE_EMAIL || '' }}" ]]; then
                echo "CLOUDFLARE_EMAIL=${{ secrets.CLOUDFLARE_EMAIL }}" >> /opt/ats/.env
                echo "CLOUDFLARE_API_TOKEN=${{ secrets.CLOUDFLARE_API_TOKEN }}" >> /opt/ats/.env
              fi
              
              # Run initial SSL setup
              ats-ssl setup || echo "‚ö†Ô∏è ATS SSL setup completed with warnings"
            else
              echo "‚ö†Ô∏è ATS SSL management scripts not found, continuing without SSL automation"
            fi
          fi
          
          # Deploy based on what's available
          if [[ -f "docker-compose.yml" ]]; then
            echo "üê≥ Starting Docker Compose services..."
            
            # Detect which Docker Compose command to use
            if docker compose version &> /dev/null 2>&1; then
              COMPOSE_CMD="docker compose"
              echo "‚úÖ Using modern Docker Compose (docker compose)"
            elif command -v docker-compose &> /dev/null; then
              COMPOSE_CMD="docker-compose"
              echo "‚úÖ Using legacy Docker Compose (docker-compose)"
            else
              echo "‚ùå No Docker Compose found! Installing manually..."
              
              # Emergency Docker Compose installation
              curl -SL "https://github.com/docker/compose/releases/latest/download/docker-compose-linux-x86_64" \
                -o /usr/local/bin/docker-compose
              chmod +x /usr/local/bin/docker-compose
              
              if command -v docker-compose &> /dev/null; then
                COMPOSE_CMD="docker-compose"
                echo "‚úÖ Emergency Docker Compose installation successful"
              else
                echo "‚ùå Failed to install Docker Compose"
                exit 1
              fi
            fi
            
            echo "üê≥ Using compose command: $COMPOSE_CMD"
            
            # Ensure Docker daemon is accessible and service user has permissions
            echo "üîß Setting up Docker permissions..."
            
            # Add service user to docker group (ensure it's effective)
            usermod -aG docker ${{ env.SERVICE_NAME }}_user 2>/dev/null || true
            
            # Create a docker group if it doesn't exist
            groupadd -f docker
            
            # Ensure docker socket has proper permissions
            chown root:docker /var/run/docker.sock 2>/dev/null || true
            chmod 660 /var/run/docker.sock 2>/dev/null || true
            
            # Restart Docker service to ensure clean state
            systemctl restart docker
            sleep 5
            
            # Test Docker access
            if ! docker info >/dev/null 2>&1; then
                echo "‚ùå Docker daemon is not accessible"
                exit 1
            fi
            
            # Change to service directory
            cd "$SERVICE_DIR"
            
            # Run Docker Compose commands as root (since we're already root in the script)
            echo "üê≥ Stopping existing services..."
            $COMPOSE_CMD down --remove-orphans 2>/dev/null || true
            
            echo "üê≥ Pulling latest images..."
            $COMPOSE_CMD pull --ignore-pull-failures 2>/dev/null || echo "Pull failed, using local images"
            
            echo "üê≥ Starting services..."
            $COMPOSE_CMD up -d
            
            # Verify services started
            echo "üîç Checking service status..."
            $COMPOSE_CMD ps
            
            # Fix ownership of any created files to service user
            echo "üîß Fixing file ownership..."
            chown -R ${{ env.SERVICE_NAME }}_user:${{ env.SERVICE_NAME }}_user "$SERVICE_DIR" 2>/dev/null || true
            
            # Special post-deployment steps for services with SSL
            if [[ "${{ env.SERVICE_NAME }}" == "nginx" ]]; then
              echo "üîç Verifying nginx SSL setup..."
              sleep 10  # Wait for nginx to start
              
              # Test HTTP endpoint
              curl -f http://localhost/health || echo "‚ö†Ô∏è HTTP health check failed"
              
              # Test HTTPS endpoint (allow self-signed)
              curl -k -f https://localhost/health || echo "‚ö†Ô∏è HTTPS health check failed"
              
              # Show SSL certificate status
              nginx-ssl status || echo "‚ö†Ô∏è Could not get SSL status"
            elif [[ "${{ env.SERVICE_NAME }}" == "fks" ]]; then
              echo "üîç Verifying FKS SSL setup..."
              sleep 15  # Wait for FKS services to start
              
              # Test HTTPS endpoints (allow self-signed)
              curl -k -f https://fkstrading.xyz/health || echo "‚ö†Ô∏è FKS web health check failed"
              curl -k -f https://api.fkstrading.xyz/health || echo "‚ö†Ô∏è FKS API health check failed"
              
              # Show SSL certificate status
              fks-ssl status || echo "‚ö†Ô∏è Could not get FKS SSL status"
            elif [[ "${{ env.SERVICE_NAME }}" == "ats" ]]; then
              echo "üîç Verifying ATS SSL setup..."
              sleep 15  # Wait for ATS services to start
              
              # Test HTTPS endpoint (allow self-signed)
              curl -k -f https://ats.7gram.xyz/health || echo "‚ö†Ô∏è ATS health check failed"
              
              # Test game server connectivity
              curl -f http://ats.7gram.xyz:27015 2>/dev/null || echo "‚ÑπÔ∏è  Game server port not HTTP accessible (normal)"
              
              # Show SSL certificate status
              ats-ssl status || echo "‚ö†Ô∏è Could not get ATS SSL status"
            fi
          elif [[ -f "start.sh" ]]; then
            echo "üöÄ Running start script..."
            chmod +x start.sh
            sudo -u ${{ env.SERVICE_NAME }}_user ./start.sh
          else
            echo "‚ö†Ô∏è No deployment method found (docker-compose.yml or start.sh)"
          fi
          
          echo "‚úÖ Service deployment complete"
          EOF
          fi
          
          # Run deployment using password authentication (more reliable for this stage)
          export SSHPASS="${{ secrets.SERVICE_ROOT_PASSWORD }}"
          sshpass -e scp -o StrictHostKeyChecking=no deploy-script.sh root@$SERVER_IP:/tmp/
          sshpass -e ssh -o StrictHostKeyChecking=no root@$SERVER_IP "chmod +x /tmp/deploy-script.sh && /tmp/deploy-script.sh"

      - name: üîç Setup Monitoring
        if: inputs.enable_monitoring
        run: |
          echo "üîç Setting up monitoring..."
          
          SERVER_IP="${{ needs.setup-infrastructure.outputs.server_ip }}"
          
          cat > monitoring-setup.sh << 'MONITORING_EOF'
          #!/bin/bash
          set -euo pipefail
          
          echo "üîç Checking for Netdata monitoring availability..."
          
          # Check if Netdata is installed
          if ! command -v netdata >/dev/null 2>&1 && ! systemctl list-unit-files | grep -q netdata; then
            echo "‚ÑπÔ∏è Netdata is not installed - monitoring setup skipped"
            echo "üí° Tip: Netdata can be installed later for monitoring capabilities"
            exit 0
          fi
          
          echo "üìä Setting up Netdata monitoring..."
          
          # Enable and start Netdata if available
          if systemctl list-unit-files | grep -q netdata; then
            echo "üîÑ Enabling and starting Netdata service..."
            systemctl enable netdata || echo "‚ö†Ô∏è Failed to enable Netdata"
            systemctl start netdata || echo "‚ö†Ô∏è Failed to start Netdata"
            
            # Wait for Netdata to start
            sleep 10
            
            # Check if Netdata is actually running
            if ! systemctl is-active netdata >/dev/null 2>&1; then
              echo "‚ö†Ô∏è Netdata service failed to start properly"
              echo "üìä Monitoring setup incomplete - check service logs later"
              exit 0
            fi
          else
            echo "‚ö†Ô∏è Netdata service not found - monitoring setup skipped"
            exit 0
          fi
          
          # Configure Netdata to bind to all interfaces
          NETDATA_CONF="/etc/netdata/netdata.conf"
          if [[ -f "$NETDATA_CONF" ]]; then
            echo "Configuring Netdata to allow external connections..."
            sed -i 's/^.*bind socket to IP.*=.*$/\tbind socket to IP = 0.0.0.0/' "$NETDATA_CONF"
          else
            echo "Creating basic Netdata configuration..."
            mkdir -p /etc/netdata
            echo "[global]" > "$NETDATA_CONF"
            echo "        bind socket to IP = 0.0.0.0" >> "$NETDATA_CONF"
            echo "        default port = 19999" >> "$NETDATA_CONF"
            echo "" >> "$NETDATA_CONF"
            echo "[web]" >> "$NETDATA_CONF"
            echo "        allow connections from = *" >> "$NETDATA_CONF"
          fi
          
          # Configure firewall
          echo "Opening firewall for Netdata on Tailscale..."
          ufw allow in on tailscale0 to any port 19999
          
          # Restart Netdata with new config
          systemctl restart netdata
          sleep 5
          
          # Test if Netdata is responding
          echo "Testing Netdata connectivity..."
          if curl -f http://localhost:19999/api/v1/info 2>/dev/null >/dev/null; then
            echo "‚úÖ Netdata is responding on port 19999"
          else
            echo "‚ö†Ô∏è Netdata may not be responding on port 19999"
          fi
          
          # Claim to Netdata Cloud if credentials provided
          if [[ -n "${{ secrets.NETDATA_CLAIM_TOKEN }}" && -n "${{ secrets.NETDATA_CLAIM_ROOM }}" ]]; then
            echo "üîó Claiming Netdata to cloud..."
            
            # Multiple methods to find and run claim script
            CLAIM_SCRIPT=""
            
            # Method 1: Check common locations for claim script
            for script_path in "/usr/sbin/netdata-claim.sh" "/opt/netdata/bin/netdata-claim.sh" "/usr/libexec/netdata/netdata-claim.sh" "/usr/lib/netdata/netdata-claim.sh"; do
              if [[ -f "$script_path" ]]; then
                CLAIM_SCRIPT="$script_path"
                echo "Found claim script at: $script_path"
                break
              fi
            done
            
            # Method 2: Search for the script
            if [[ -z "$CLAIM_SCRIPT" ]]; then
              CLAIM_SCRIPT=$(find /usr /opt -name "netdata-claim.sh" 2>/dev/null | head -1)
              if [[ -n "$CLAIM_SCRIPT" ]]; then
                echo "Found claim script via search: $CLAIM_SCRIPT"
              fi
            fi
            
            # Method 3: Check if it's in PATH
            if [[ -z "$CLAIM_SCRIPT" ]] && command -v netdata-claim.sh >/dev/null 2>&1; then
              CLAIM_SCRIPT="netdata-claim.sh"
              echo "Found claim script in PATH"
            fi
            
            # Method 4: Download claim script directly if not found
            if [[ -z "$CLAIM_SCRIPT" ]]; then
              echo "Claim script not found locally, downloading..."
              wget -O /tmp/netdata-claim.sh https://raw.githubusercontent.com/netdata/netdata/master/claim/netdata-claim.sh
              chmod +x /tmp/netdata-claim.sh
              CLAIM_SCRIPT="/tmp/netdata-claim.sh"
            fi
            
            # Attempt to claim
            if [[ -n "$CLAIM_SCRIPT" ]]; then
              echo "Attempting to claim with script: $CLAIM_SCRIPT"
              "$CLAIM_SCRIPT" -token="${{ secrets.NETDATA_CLAIM_TOKEN }}" \
                -rooms="${{ secrets.NETDATA_CLAIM_ROOM }}" \
                -url=https://app.netdata.cloud \
                -hostname="${{ env.SERVICE_NAME }}" || {
                echo "‚ö†Ô∏è Netdata cloud claim failed with script - trying alternative method..."
                
                # Alternative method: Manual claiming via API
                echo "Trying manual claim via Netdata API..."
                curl -X POST "http://localhost:19999/api/v1/registry" \
                  -H "Content-Type: application/json" \
                  -d '{
                    "action": "claim",
                    "token": "${{ secrets.NETDATA_CLAIM_TOKEN }}",
                    "rooms": "${{ secrets.NETDATA_CLAIM_ROOM }}",
                    "url": "https://app.netdata.cloud",
                    "hostname": "${{ env.SERVICE_NAME }}"
                  }' || echo "Manual claim also failed"
              }
              
              # Restart Netdata after claiming
              systemctl restart netdata
              sleep 5
              
              echo "‚úÖ Netdata claim process completed"
            else
              echo "‚ö†Ô∏è Could not find or download claim script - skipping cloud integration"
            fi
          else
            echo "‚ÑπÔ∏è No Netdata cloud credentials provided - running locally only"
          fi
          
          echo "‚úÖ Netdata monitoring setup complete"
          MONITORING_EOF
          
          export SSHPASS="${{ secrets.SERVICE_ROOT_PASSWORD }}"
          sshpass -e scp -o StrictHostKeyChecking=no monitoring-setup.sh root@$SERVER_IP:/tmp/
          sshpass -e ssh -o StrictHostKeyChecking=no root@$SERVER_IP "chmod +x /tmp/monitoring-setup.sh && /tmp/monitoring-setup.sh"

      - name: üåê Update DNS Records with Tailscale IP
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ZONE_ID: ${{ secrets.CLOUDFLARE_ZONE_ID }}
          TAILSCALE_IP: ${{ needs.setup-infrastructure.outputs.tailscale_ip }}
        if: env.CLOUDFLARE_API_TOKEN != '' && env.CLOUDFLARE_ZONE_ID != '' && env.TAILSCALE_IP != ''
        run: |
          echo "üåê Updating DNS records to use Tailscale IP instead of public IP..."
          
          # Install dependencies
          sudo apt-get update && sudo apt-get install -y curl jq >/dev/null 2>&1 || true
          
          # Set variables
          TAILSCALE_IP="${{ needs.setup-infrastructure.outputs.tailscale_ip }}"
          SERVICE_NAME="${{ env.SERVICE_NAME }}"
          DOMAIN_NAME="${SERVICE_NAME}.7gram.xyz"
          
          echo "üîç Service: $SERVICE_NAME"
          echo "üîó Tailscale IP: $TAILSCALE_IP"
          echo "üåê Domain: $DOMAIN_NAME"
          
          # Validate inputs
          if [[ "$TAILSCALE_IP" == "pending" || -z "$TAILSCALE_IP" ]]; then
            echo "‚ö†Ô∏è Tailscale IP not available, skipping DNS update"
            exit 0
          fi
          
          # Test Cloudflare API connectivity
          echo "üîß Testing Cloudflare API connectivity..."
          API_TEST_RESPONSE=$(curl -s -X GET "https://api.cloudflare.com/client/v4/zones/$CLOUDFLARE_ZONE_ID" \
            -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
            -H "Content-Type: application/json")
          
          API_SUCCESS=$(echo "$API_TEST_RESPONSE" | jq -r '.success')
          if [[ "$API_SUCCESS" != "true" ]]; then
            echo "‚ùå Cloudflare API test failed:"
            echo "$API_TEST_RESPONSE" | jq -r '.errors[]?.message // "Unknown error"'
            exit 1
          fi
          
          ZONE_NAME=$(echo "$API_TEST_RESPONSE" | jq -r '.result.name')
          echo "‚úÖ API connection successful - Zone: $ZONE_NAME"
          
          # Check for existing DNS record
          echo "üîç Checking for existing DNS record: $DOMAIN_NAME"
          EXISTING_RESPONSE=$(curl -s -X GET \
            "https://api.cloudflare.com/client/v4/zones/$CLOUDFLARE_ZONE_ID/dns_records?name=$DOMAIN_NAME&type=A" \
            -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
            -H "Content-Type: application/json")
          
          RECORD_ID=$(echo "$EXISTING_RESPONSE" | jq -r '.result[0].id // empty')
          CURRENT_IP=$(echo "$EXISTING_RESPONSE" | jq -r '.result[0].content // empty')
          
          echo "üîç Current record ID: $RECORD_ID"
          echo "üîç Current IP: $CURRENT_IP"
          
          # Update or create DNS record with Tailscale IP
          if [[ -n "$RECORD_ID" && "$RECORD_ID" != "null" ]]; then
            # Update existing record
            echo "üìù Updating existing DNS record: $DOMAIN_NAME ‚Üí $TAILSCALE_IP"
            UPDATE_RESPONSE=$(curl -s -X PUT \
              "https://api.cloudflare.com/client/v4/zones/$CLOUDFLARE_ZONE_ID/dns_records/$RECORD_ID" \
              -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
              -H "Content-Type: application/json" \
              --data "{
                \"type\": \"A\",
                \"name\": \"$DOMAIN_NAME\",
                \"content\": \"$TAILSCALE_IP\",
                \"ttl\": 120,
                \"proxied\": false,
                \"comment\": \"Updated by GitHub Actions - Tailscale IP\"
              }")
          else
            # Create new record
            echo "‚ûï Creating new DNS record: $DOMAIN_NAME ‚Üí $TAILSCALE_IP"
            UPDATE_RESPONSE=$(curl -s -X POST \
              "https://api.cloudflare.com/client/v4/zones/$CLOUDFLARE_ZONE_ID/dns_records" \
              -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
              -H "Content-Type: application/json" \
              --data "{
                \"type\": \"A\",
                \"name\": \"$DOMAIN_NAME\",
                \"content\": \"$TAILSCALE_IP\",
                \"ttl\": 120,
                \"proxied\": false,
                \"comment\": \"Created by GitHub Actions - Tailscale IP\"
              }")
          fi
          
          # Check result
          UPDATE_SUCCESS=$(echo "$UPDATE_RESPONSE" | jq -r '.success')
          if [[ "$UPDATE_SUCCESS" == "true" ]]; then
            NEW_RECORD_ID=$(echo "$UPDATE_RESPONSE" | jq -r '.result.id')
            echo "‚úÖ DNS record updated successfully!"
            echo "   üîó Domain: $DOMAIN_NAME"
            echo "   üåê Tailscale IP: $TAILSCALE_IP"
            echo "   üÜî Record ID: $NEW_RECORD_ID"
            echo "   ‚è±Ô∏è TTL: 120 seconds (fast propagation)"
            echo ""
            echo "üéØ Access your service via Tailscale VPN:"
            echo "   ‚Ä¢ Direct: http://$TAILSCALE_IP"
            echo "   ‚Ä¢ Domain: http://$DOMAIN_NAME (after DNS propagation)"
            echo ""
            echo "‚ö†Ô∏è Note: This domain only resolves within the Tailscale network for security"
          else
            echo "‚ùå DNS record update failed:"
            echo "$UPDATE_RESPONSE" | jq -r '.errors[]?.message // "Unknown error"'
            exit 1
          fi

  # ============================================================================
  # Health Checks
  # ============================================================================
  health-check:
    name: üè• Health Check
    runs-on: ubuntu-latest
    needs: [preflight-checks, setup-infrastructure, deploy-service]
    if: always() && (needs.deploy-service.result == 'success' || needs.preflight-checks.outputs.should_health_check == 'true')
    
    steps:
      - name: üè• Perform Health Checks
        run: |
          echo "üè• Running health checks..."
          
          SERVER_IP="${{ needs.setup-infrastructure.outputs.server_ip }}"
          
          if [[ -n "$SERVER_IP" ]]; then
            echo "Testing SSH connectivity..."
            ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no -o ConnectTimeout=10 root@$SERVER_IP "echo 'SSH OK'"
            
            echo "Checking services..."
            ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@$SERVER_IP "systemctl is-active docker"
            ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@$SERVER_IP "tailscale status --peers=false"
            ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@$SERVER_IP "docker ps"
            
            echo "‚úÖ Health checks passed"
          else
            echo "‚ö†Ô∏è No server IP available for health checks"
          fi

  # ============================================================================
  # Notifications
  # ============================================================================
  notify:
    name: üì¢ Notify
    runs-on: ubuntu-latest
    needs: [preflight-checks, deploy-service, destroy-service, health-check]
    if: always()
    
    steps:
      - name: üì¢ Send Notification
        env:
          DISCORD_WEBHOOK: ${{ secrets.DISCORD_WEBHOOK }}
        if: env.DISCORD_WEBHOOK != ''
        run: |
          echo "üì¢ Sending notification..."
          
          # Determine overall status
          if [[ "${{ needs.deploy-service.result }}" == "success" || "${{ needs.destroy-service.result }}" == "success" ]]; then
            STATUS="‚úÖ SUCCESS"
            COLOR="3066993"
          else
            STATUS="‚ùå FAILED"
            COLOR="15158332"
          fi
          
          ACTION_EMOJI=""
          case "${{ env.ACTION_TYPE }}" in
            "deploy") ACTION_EMOJI="üöÄ" ;;
            "destroy") ACTION_EMOJI="üóëÔ∏è" ;;
            "health-check") ACTION_EMOJI="üè•" ;;
            "restart") ACTION_EMOJI="üîÑ" ;;
          esac
          
          curl -H "Content-Type: application/json" \
            -d "{
              \"embeds\": [{
                \"title\": \"$ACTION_EMOJI $STATUS: ${{ env.SERVICE_NAME }} ${{ env.ACTION_TYPE }}\",
                \"description\": \"Service: ${{ env.SERVICE_NAME }}\\nAction: ${{ env.ACTION_TYPE }}\\nMode: ${{ env.DEPLOYMENT_MODE }}\\nTests Skipped: ${{ env.SKIP_TESTS }}\\nDocker Build Skipped: ${{ env.SKIP_DOCKER_BUILD }}\\nServer Overwritten: ${{ env.OVERWRITE_SERVER }}\",
                \"color\": $COLOR,
                \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%S.000Z)\"
              }]
            }" \
            "$DISCORD_WEBHOOK"
